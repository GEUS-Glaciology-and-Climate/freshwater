#+Latex_Class: copernicus
#+AUTHOR: 
#+LaTeX_CLASS_OPTIONS: [essd, manuscript]
#+Options: toc:nil ^:t {}:t

:BEGIN_header:
# #+LATEX_HEADER_EXTRA: \usepackage{showlabels}

#+PROPERTY: header-args :eval no :noweb yes :comments both
#+PROPERTY: header-args:xml+ :eval no
#+PROPERTY: header-args:bash+ :eval no-export :noweb yes :comments both
#+PROPERTY: header-args:bash+ :session (concat "*" (file-name-sans-extension (buffer-name)) "-shell*")
#+PROPERTY: header-args:bash+ :tangle-mode (identity #o544) :shebang #!/usr/bin/env bash
#+PROPERTY: header-args:jupyter-python+ :session freshwater
#+PROPERTY: header-args:jupyter-python+ :eval no-export :noweb yes :comments both :kernel freshwater
#+PROPERTY: header-args:elisp+ :eval no-export :noweb yes
#+PROPERTY: header-args:python+ :eval no-export :noweb yes

#+PROPERTY: header-args:bash+ :eval no-export
#+PROPERTY: header-args:jupyter-python+ :eval no-export

#+EXCLUDE_TAGS: noexport
:END:

# WARNING: infinite recursion if not ":eval no"
#+header: :eval no
#+name: workflow-update
#+BEGIN_SRC emacs-lisp :results none :eval no :results none :exports none
(progn
  (require 'notifications)

  ;; remove #+results: blocks
  (org-babel-map-src-blocks nil (if (org-babel-where-is-src-block-result) 
				    (org-babel-insert-result "" '("replace"))))
  (save-buffer) ;; can now inspect "missing" results w/ git wdiff
  (org-babel-execute-buffer) ;; this make take a few whiles
  (save-buffer)
  (notifications-notify
   :title "Review with 'git wdiff'"
   :body "Note: :async results may not be finished"
   :timeout 5000
   :transient t))
#+END_SRC

#+RESULTS: workflow-update

#+BEGIN_EXPORT LaTeX
\title{Greenland liquid water discharge from 1940 through December 2024}
\Author[1]{Kenneth D.}{Mankoff}
\Author[2]{Brice}{Noël}
\Author[3]{Xavier}{Fettweis}
\Author[1]{Andreas P.}{Ahlstrøm}
\Author[1]{William}{Colgan}
\Author[4]{Ken}{Kondo}
\Author[5]{Kirsty}{Langley}
\Author[4]{Shin}{Sugiyama}
\Author[1]{Dirk}{van As}
\Author[1]{Robert S.}{Fausto}
\affil[1]{Department of Glaciology and Climate, Geological Survey of Denmark and Greenland (GEUS), Copenhagen, Denmark}
\affil[2]{Institute for Marine and Atmospheric Research, Utrecht University, The Netherlands}
\affil[3]{SPHERES research unit, Department of Geography, University of Liège, Liège, Belgium}
\affil[4]{Institute of Low Temperature Science, Hokkaido University, Japan}
\affil[5]{Asiaq-Greenland Survey, Nuuk, Greenland}
\correspondence{Ken Mankoff (kdm@geus.dk)}
\runningtitle{Greenland liquid water discharge}
\runningauthor{K. D. Mankoff \textit{et al.}}

\received{}
\pubdiscuss{}
\revised{}
\accepted{}
\published{}
%% These dates will be inserted by ACPD
\firstpage{1}
\maketitle

\newcommand{\textcite}[1]{\citet{#1}}
\newcommand{\autocite}[1]{\citep{#1}}
#+END_EXPORT

#+BEGIN_abstract
Greenland runoff, from ice mass loss and rainfall, is increasing. That runoff, as discharge, impacts the physical, chemical, and biological properties of the adjacent fjords. However, where and when the discharge occurs is not readily available in an open database. Here we provide data sets of high-resolution Greenland hydrologic outlets, basins, and streams, as well as a daily 1940 through December 2024 time series of Greenland liquid water discharge for each outlet. The data include src_bash{cat ./freshwater/ice/basins.csv | grep -v "^cat" |wc -l} {{{results(=23898=)}}} ice marginal outlets and upstream basins, and src_bash{cat ./freshwater/land/basins.csv | grep -v "^cat" |wc -l} {{{results(=29430=)}}} land coast outlets and upstream basins, derived from the 100 m ArcticDEM and 150 m BedMachine. At each outlet there are daily discharge data for src_jupyter-python[:eval yes :session export]{import xarray as xr; ds = xr.open_mfdataset("./freshwater/land/discharge/*.nc", combine='nested', concat_dim='time'); (ds.time.max() - ds.time.min()).values.astype('timedelta64[D]').tolist().days+1} {{{results(=31047=)}}} days - ice sheet runoff routed subglacially to ice margin outlets, and land runoff routed to coast outlets - from two regional climate models (RCMs; MAR and RACMO).
Our sensitivity study of how outlet location changes for every inland cell based on subglacial routing assumptions, shows that most inland cells where runoff occurs are not highly sensitive to those routing assumptions, and outflow location does not move far. We compare RCM results with 10 gauges from streams with discharge rates spanning 4 orders of magnitude. Results show that for daily discharge at the individual basin scale the 5 to 95 % prediction interval between modeled discharge and observations generally falls within plus or minus a factor of 5 (half an order of magnitude, or +500%/-80%). Results from this study are available at
doi:10.22008/promice/freshwater citep:GEUS_freshwater_paper and code is available at https://github.com/GEUS-Glaciology-and-Climate/freshwater citep:github_freshwater.
#+END_abstract

* Table of contents                               :toc_2:noexport:
- [[#about-this-document][About this document]]
  - [[#workflow][Workflow]]
- [[#new-in-this-version][New in this version]]
- [[#introduction][Introduction]]
- [[#input-and-validation-data][Input and validation data]]
  - [[#static-data][Static data]]
  - [[#rcm-time-series][RCM time series]]
  - [[#river-discharge-observations][River discharge observations]]
- [[#methods][Methods]]
  - [[#terminology][Terminology]]
  - [[#streams-outlets-and-basins][Streams, outlets, and basins]]
  - [[#discharge-and-rcm-coverage][Discharge and RCM coverage]]
  - [[#validation][Validation]]
- [[#product-evaluation-and-assessment][Product evaluation and assessment]]
  - [[#main-characteristics][Main characteristics]]
  - [[#comparison-with-previous-similar-work][Comparison with previous similar work]]
  - [[#validation-against-observations][Validation against observations]]
  - [[#uncertainty][Uncertainty]]
  - [[#other-sources-of-freshwater][Other sources of freshwater]]
  - [[#summary][Summary]]
- [[#product-description][Product description]]
  - [[#streams][Streams]]
  - [[#outlets][Outlets]]
  - [[#basins][Basins]]
  - [[#discharge][Discharge]]
  - [[#database-access-software][Database access software]]
- [[#conclusions][Conclusions]]
- [[#data-and-code-availability][Data and code availability]]
- [[#algorithms][Algorithms]]
  - [[#streams-outlets-and-basins-1][Streams, outlets, and basins]]
  - [[#model-output-routing][Model output routing]]
  - [[#makefile][Makefile]]
- [[#data][Data]]
  - [[#provenance][Provenance]]
  - [[#import-data][Import Data]]
- [[#quality-control][Quality control]]
  - [[#streams-outlets-and-basins-2][Streams, Outlets, and Basins]]
  - [[#outputs][Outputs]]
- [[#supplemental-material][Supplemental material]]
  - [[#coverage][Coverage]]
- [[#figures][Figures]]
  - [[#overview][Overview]]
  - [[#basin-changes-with-changing-k][Basin changes with changing k]]
  - [[#bulk-observation-vs-rcm-scatter-plots][Bulk observation vs. RCM scatter plots]]
  - [[#modified-tukey-plot-for-all-observations][Modified Tukey plot for all observations]]
  - [[#bamber-2018][Bamber 2018]]
  - [[#observations-vs-rcm-map--ts--scatter][Observations vs. RCM, map + ts + scatter]]
  - [[#watson-river][Watson River]]
  - [[#watson-adjustments][Watson Adjustments]]
  - [[#leverett-glacier][Leverett Glacier]]
  - [[#kiattuut-sermiat][Kiattuut Sermiat]]
  - [[#kingigtorssuaq][Kingigtorssuaq]]
  - [[#oriartorfik][Oriartorfik]]
  - [[#teqinngalip][Teqinngalip]]
  - [[#kobbefjord][Kobbefjord]]
  - [[#røde-elv][Røde Elv]]
  - [[#zackenberg][Zackenberg]]
  - [[#qaanaaq][Qaanaaq]]
  - [[#elevation-histogram][Elevation histogram]]
- [[#readme][README]]
- [[#appendix][Appendix]]
  - [[#software][Software]]
- [[#misc-journal-sections][Misc journal sections]]
- [[#references][References]]
- [[#meta][Meta]]
  - [[#software-1][Software]]
- [[#latex-setup][LaTeX setup]]

* About this document                                   :noexport:

This document is an Emacs Org Mode plain-text file with code and text embedded. If you are viewing:

+ A DOC, Google Doc, or PDF file, then it was generated by exporting from Org. Not all of the Org parts (code, results, comments, etc.) were exported. The Org source file is available upon request, and may be embedded in the PDF. Most non-Apple PDF viewers provide easy access to embedded or attached files.
 
+ A webpage somewhere, then this is a subset of the code and text that the website render has decided to display to you through the browser. You can choose to view the raw source and/or download it and view it locally on your computer.

+ A file with a =org= extension in something other than Emacs, then you are seeing the canonical version and the full source, but without any syntax highlighting, document structure, or the ability to execute the code blocks.

+ An =Org= file within Emacs, then this is the canonical version. You should be able to fully interact and reproduce the contents of this document, although it may require 3rd-party applications (Python, etc.) a similar Emacs configuration, and the data files. This is available upon request.

** Workflow

To recreate this work

+ Open this file in Emacs Org Mode.
+ check that you have the necessary software dependencies installed. See section: [[*Code][Code]].
+ Download and set up the necessary data files as per the [[*Data][Data]] section
+ Tangle the embedded code blocks.
  + Execute =C-c C-v C-t= to run the (org-babel-tangle) function
+ Run =make=
  + This should probably be run in an external terminal because it takes hours to days...
+ Update Babel result blocks throughout the document by
  + Cleaning all result blocks with =C-u C-c C-v k= or (org-babel-remove-result-one-or-many t), then
  + Executing all blocks (without =:eval no=) using =C-c C-v C-b= or (org-babel-execute-buffer)

This is captured programatically by [[workflow-update]]

* New in this version
:PROPERTIES:
:ID: sec_new_this_version
:END:

The discussion of quality control and land runoff with depth < 0 as invalid has been updated. Land runoff with depth << 0 is possible and occurs when land-source runoff enters the subglacial system and discharges subglacially at depth from a marine terminating glacier. This occurs often when runoff is sourced from nunatuks. This scenario also generates land outlets that exist outside of land basins.

Various input data products have been upgraded. BedMachine has been upgraded from v3 to v5. MAR has been upgraded from version 3.11 to 3.12, and the simulation period has been extended from 1979 through September 2019, to 1940 through December 2024. The RACMO simulation period has been extended from 1958 through September 2019 to 1958 through December 2022. Prior to 1990, the RACMO data is unchanged (6-hourly ERA-Interim forcing). From 1990 onward, we now use 3-hourly ERA5 forcing. Both the MAR and RACMO domain boundaries have been corrected, fixing a small alignment error in the initial version.

Additional metadata now includes the citet:mouginot_2019_data basins and regions and the citet:zwally_2012_data sector nearest to each outlet, and shortest distance between the outlet and the basin, region, or sector boundary. This should be used with caution - some peripheral ice cap outlets may be assigned to the ice sheet, or land-terminating outlets may be nearest to an ice basin that does not overlap with hydrological basin. The distance can be used as a filter. We also include the nearest named glacier from citet:bjork_2015, and distance to the citet:bjork_2015 point. We also include the nearest citet:mankoff_2020_solid gate and distance to gate. Because citet:mankoff_2020_solid is a continually updating product, and gate locations and IDs may change in the future, we note here that we use gates V3 (file: https://doi.org/10.22008/promice/data/ice_discharge/gates/v02/GSEWLR) that are associated with discharge V55. The gate IDs used here are also valid with many previous ice discharge versions, and likely to be valid with many following ice discharge versions.

* Introduction                                            :ignore:

\introduction

Over the past decades, liquid runoff from Greenland has increased citep:mernild_2012,bamber_2018_freshwater,trusel_2018,perner_2019 contributing to mass decrease citep:sasgen_2020. When that runoff leaves the ice sheet and discharges into fjords and coastal seas, it influences a wide range of physical citep:straneo_2011,an_2012,mortensen_2013,bendtsen_2015,cowton_2015,mankoff_2016,fried_2019,cowton_2019,beckmann_2019, chemical citep:kanna_2018,balmonte_2019, and biological citep:kamenos_2012,kanna_2018,balmonte_2019 systems citep:catania_2020. The scales of the impacts range from instantaneous at the ice--ocean boundary to decadal in the distal ocean citep:gillard_2016. The influence of freshwater on multiple domains and disciplines citep:catania_2020 is the reason several past studies have estimated runoff and discharge at various temporal and spatial scales (e.g., citet:mernild_2008,mernild_2009,mernild_2010,langen_2015,ahlstrom_2017,citterio_2017,van-as_2018,bamber_2018_freshwater,perner_2019,slater_2019).

To date no product provides discharge estimates at high spatial resolution (~100 m; resolving individual streams), daily temporal resolution, for all of Greenland, covering a broad time span (1940 through 2024), from multiple regional climate models (RCMs), and with a simple database access software to support downstream users. Here we present these data. In the following description and methods, we document the inputs, assumptions, methodologies, and results we use to estimate Greenland discharge from 1940 through December 2024.

Freshwater discharge from Greenland primarily takes three forms: solid ice from calving at marine-terminating glaciers; submarine meltwater from ice-ocean boundary melting at marine-terminating glaciers; and liquid runoff from melted inland surface ice, rain, and condensation. A recent paper by citet:mankoff_2020_ice targets the solid ice discharge plus submarine melt budget by estimating the ice flow rate across gates 5 km upstream from all fast-flowing marine-terminating glaciers in Greenland. Complementing that paper, this paper targets Greenland's point-source liquid water discharge budget by partitioning RCM runoff estimates to all ice margin and coastal outlets. The sum of these data and citet:mankoff_2020_ice is an estimate of the majority of freshwater (in both liquid and solid form) volume flow rates into Greenland fjords. Those two terms comprise the bulk but not all freshwater - they exclude precipitation directly onto the fjord or ocean surface, as well as relatively minor contributions from evaporation and condensation, sea ice formation and melt, or subglacial basal melting. 


* Input and validation data
** Static data

The static products (streams, outlets, and basins (Fig. [[fig:overview]])) are derived from an ice sheet surface digital elevation model (DEM), an ice sheet bed DEM, an ice sheet mask, the land surface DEM, and an ocean mask. For the surface DEM, we use ArcticDEM v7 100 m citep:ArcticDEM. Subglacial routing uses ArcticDEM and ice thickness from BedMachine v5 citep:NSIDC_BedMachine_GL_v5,morlighem_2017. Both DEMs are referenced to the WGS84 ellipsoid. For the ice mask we use the Programme for Monitoring of the Greenland Ice Sheet (PROMICE) ice extent citep:citterio_2013. For the ocean mask we use the Making Earth System Data Records for Use in Research Environments (MEaSUREs) Greenland Ice Mapping Project (GIMP) Land Ice and Ocean Classification Mask, Version 1 citep:NSIDC_0714,howat_2014.

** RCM time series

The time series product (daily discharge) is derived from daily runoff estimates from RCM calculations over the land and ice areas of Greenland. We use the Modèle Atmosphérique Régional (MAR; citet:fettweis_2017) and the Regional Atmospheric Climate Model (RACMO; citet:noel_2019). Runoff, \(R\), is defined by

#+NAME: eq:runoff
\begin{equation}
R = ME + RA - RT - RF.
\end{equation}

In Eq. \ref{eq:runoff}, \(ME\) is melt, \(RA\) is rainfall, \(RT\) is retention, and \(RF\) is refreezing. In RACMO, retention occurs only when firn is present (not with bare ice). MAR does have a delay for bare ice runoff. Neither have a delay for land runoff. Both RCM outputs were provided regridded to the same 1 km grid using an offline statistical downscaling technique based on the local vertical runoff gradient applied to the subgrid topography citep:noel_2016,fettweis_2020. MAR (v 3.14; citet:delhasse_2020) ran with 7.5 km resolution and ERA5 6 h forcing. RACMO (v 2.3p2; citet:noel_2018,noel_2019) ran with 5.5 km resolution and ERA-Interim 6-hour forcing. Runoff is assigned an uncertainty of \pm15 % (Sect. \ref{sec:uncertain:RCM}).

** River discharge observations

We use 10 river discharge daily time series to validate the results of this work. The name, location, time coverage, and relevant data and scientific publications associated with each of these observational data are listed in Table [[tbl_obs]].

#+MACRO: HL @@latex:\underline{\textbf{$1}}@@

#+NAME: tbl_obs
#+CAPTION: Table of observation locations, time spans, and associated references. Coordinates are decimal degree W and N.
| Location              |    Long |     Lat |      Time | Data                     | Publication         | Fig(s).                                |
|-----------------------+---------+---------+-----------+--------------------------+---------------------+----------------------------------------|
| Kiattuut Sermiat      |   45.33 |   61.21 |      2013 | citet:hawkings_2016_data | citet:hawkings_2016 | 1 3 4 5 \ref{fig:Ks}                   |
| Kingigtorssuaq (Nuuk) | 51.5801 | 64.1387 | 2008-2018 | citet:GEM_data           |                     | 1 3 4 \ref{fig:K}                      |
| Kobbefjord (Nuuk)     | 51.3810 | 64.1336 | 2006-2017 | citet:GEM_data           |                     | 1 3 4 \ref{fig:Kb}                     |
| Leverett Glacier      |   50.17 |   67.06 | 2009-2012 | citet:tedstone_2017      | citet:hawkings_2015 | 1 3 4 5 \ref{fig:L}                    |
| Oriartorfik (Nuuk)    | 51.4066 | 64.1707 | 2007-2018 | citet:GEM_data           |                     | 1 3 4 \ref{fig:O}                      |
| Qaanaaq               | 69.3030 | 77.4753 | 2017-2018 | citet:qaanaaq_data       | citet:sugiyama_2014 | 1 3 4 5 \ref{fig:Q}                    |
| Røde Elv (Disko)      | 53.4989 | 69.2534 |      2017 | citet:GEM_data           |                     | 1 3 4 5 6 \ref{fig:R}                  |
| Teqinngalip (Nuuk)    | 51.5484 | 64.1586 | 2007-2018 | citet:GEM_data           |                     | 1 3 4 \ref{fig:T}                      |
| Watson River          |   50.68 |   67.01 | 2006-2019 | citet:van-as_2018        | citet:van-as_2018   | 1 3 4 5 \ref{fig:W} \ref{fig:W_adjust} |
| Zackenberg            | 20.5628 | 74.4722 | 1996-2018 | citet:GEM_data           |                     | 1 3 4 5 \ref{fig:Z}                    |

*** Discharge observations table internal use              :noexport:
:PROPERTIES:
:ID:       20200723T082939.595752
:END:

Extract the longitude, latitude, and abbreviation from [[tbl_obs]] and import into GRASS for use for the analysis elsewhere in this document.

+ Extract abbreviation for each location
+ Add Convert (lon,lat) to EPSG:3413 (x,y)

#+NAME: tbl_obs_xy
#+header: :cache no
#+header: :session
#+BEGIN_SRC bash :results table drawer :var mapset="obs" :eval yes :var tbl=tbl_obs
for key in "${!tbl[@]}"; do 	# 
  row=(${tbl[$key]})
  IFS=" " read lon lat time data pub fig <<< ${row[@]}
  IFS=":" read x y z <<< $(echo "${lat} -${lon}" | cs2cs EPSG:4326 EPSG:3413 -f "%0.f" | sed 's/[[:space:]]/:/g')
  echo  ${key/\ */} $x $y
done | sort
#+END_SRC

#+RESULTS: tbl_obs_xy
:results:
| Kiattuut       |  -18335 | -3183360 |
| Kingigtorssuaq | -326372 | -2829354 |
| Kobbefjord     | -316602 | -2831048 |
| Leverett       | -226848 | -2507183 |
| Oriartorfik    | -317396 | -2826710 |
| Qaanaaq        | -560538 | -1241281 |
| Røde           | -335678 | -2246371 |
| Teqinngalip    | -324548 | -2827284 |
| Watson         | -249713 | -2510668 |
| Zackenberg     |  699990 | -1540459 |
:end:

Note - to solve =jupyter-python= issue with =:cache= results, 
+ Manually edit this table
+ add =#+NAME: tbl_obs_xy_cache=
+ Reduce 1st column to 1-letter abbreviation, except
  + Kobbefjord -> Kb
  + Kiattuut Sermiat -> Ks
  + Adjust Leverett to "-216646 | -2504583"
+ Then access via table name and not babel code block name.

#+NAME: tbl_obs_xy_cache
| Ks |  -18335 | -3183360 |
| K  | -326372 | -2829354 |
| Kb | -316602 | -2831048 |
| L  | -216646 | -2504583 |
| O  | -317396 | -2826710 |
| Q  | -560538 | -1241281 |
| R  | -335678 | -2246371 |
| T  | -324548 | -2827284 |
| W  | -249713 | -2510668 |
| Z  |  699990 | -1540459 |

* Methods
** Terminology

We use the following terminology throughout the document:
+ Runoff refers to the unmodified RCM data products -- melted ice, rain, condensation, and evaporation -- that comprise the RCM runoff output variable.
+ Discharge refers to the runoff after it has been processed by this work - routed to and aggregated at the outlets. Depending on context, discharge may also refer to the observed stream discharge (Table \ref{tbl_obs}).
+ Basins refer to the 100 m x 100 m gridded basins derived from a combination of the ArcticDEM product and the mask.
+ Mask refers to the surface classification on that 100 m x 100 m grid and is one of ice, land, or ocean (also called fjord or water). When referring to the surface classification in the RCM, we explicitly state "RCM mask".
+ MAR and RACMO refer to the RCMs, but when comparing discharge estimates between them or to observations, we use MAR and RACMO to refer to our discharge product derived from the MAR and RACMO RCM runoff variables rather than repeatedly explicitly stating "discharged derived from [MAR|RACMO] runoff". The use should be clear from context.

** Streams, outlets, and basins

Streams are calculated from the hydraulic head \(h\) which is the DEM surface for land surface routing, or the subglacial pressure head elevation for subglacial routing. \(h\) is defined as

#+NAME: eq:head
\begin{equation}
h = z_b + k \frac{\rho_i}{\rho_w} (z_s - z_b),
\end{equation}

with \(z_b\) the ice-free land surface and basal topography, \(k\) the flotation fraction, \(\rho_i\) the density of ice (917 kg m^{-3}), \(\rho_w\) the density of water (1000 kg m^{-3}), and \(z_s\) the land surface for both ice-free and ice-covered surfaces. 

Eq. [[eq:head]] comes from citet:shreve_1972, where the hydropotential has units of pascals (Pa), but here it is divided by gravitational acceleration \(g\) times the density of water \(\rho_w\) to convert the units from pascals to meters (Pa to m). We compute \(h\) and from that streams, outlets, basins, and runoff for a range of subglacial pressures, implemented as a range of \(k\) values: 0.8, 0.9, and 1.0. We use these three scenarios to estimate sensitivity of the outlet location for all upstream cells, but otherwise only use results from the \(k = 1.0\) scenario. Eq. [[eq:head]] makes the assumption that when ice is present all water routes subglacially, meaning that water flows from the surface to the bed in the grid cell where it is generated. In reality, internal catchments and moulins likely drain waters to the bed within a few kilometers of their source citep:yang_2016_internally. The difference between some supraglacial flow and immediate subglacial flow is not likely to impact results because discharge is reported only at the outlet locations.

We use the GRASS GIS software citep:neteler_2012,GRASS_GIS_software and the =r.stream.extract= command configured for single-flow direction from eight neighbors (SFD-8) to calculate streams and outlets at the ice edge and coast. Streams are defined only if their upstream contributing area is above a threshold (> 3 km^2), so small basins may have outlets but no streams. The software fills all sinks so that all water flows to the domain edge. We then use the =r.stream.basins= tool citep:jasiewicz_2011 to calculate basins upstream from each outlet. Basins < 1 km^{2} are absorbed into their largest neighbor and the associated outlets are dropped.

*** Outlet sensitivity

The three choices of \(k\) generate three scenarios of basins and outlets, and we use this to show sensitivity of every ice grid cell to these choices. After three \(k\) scenarios, each cell has three possible outlets, where each outlet is an (x,y) coordinate. To show results in a map view, we reduced these six properties (three 2D coordinates) to a single property. For every grid cell in the ice domain we compute the maximum distance between each outlet and the other two (six becomes three), and we then select the maximum (three becomes one). Fig. [[fig:k_basin_change]] displays the maximum distance - a worst-case scenario - of how far the outlet of every inland ice cell may move due to basal routing assumptions.

** Discharge and RCM coverage
:PROPERTIES:
:CUSTOM_ID:  sec:methods:discharge
:END:

RCM runoff is summed over each basin for each day of RCM data and assigned to each outlet for that day. This assumes routing between the runoff and the outlet is instantaneous, so all analyses done here include a 7 d smooth applied to the RCM discharge product (cf. citet:van-as_2017). The released data do not include any smoothing.

The alignments of the RCM and the basins do not always agree. Each 100 m x 100 m ArcticDEM pixel is classified as ice citep:citterio_2013, ocean citep:NSIDC_0714, or land (defined as neither ice nor ocean). However, the classification of the mask cells and the 1 km^{2} RCM domains do not always agree - for example, when a mask cell is classified as ice but the matching RCM cell is land. This disagreement occurs almost everywhere along the ice margin because the 1 km RCM boundary and the 100 m mask boundary rarely perfectly align. The ice margin is where most runoff occurs per unit area due to the highest temperatures at the lowest ice elevations, so small changes in masks in these locations can introduce large changes in RCM outputs.

We adjust for this imprecise overlap and scale the RCM results to the basin area. Where the mask reports ice and a RCM reports land, the RCM land runoff fraction is discarded, and the RCM ice runoff fraction over this basin is adjusted for the uncovered basin cells (and vice versa for basin land and RCM ice). Small basins with no RCM coverage of the same type have no runoff.

Runoff adjustments using this method are underestimated for large basins with large inland high-elevation regions with low runoff, because this method fills in misaligned cells with each day's average discharge, but the misalignment (missing runoff) occurs at the ice sheet edge where maximum runoff occurs. However, given that the basin is large, misalignment is proportionally small, and therefore errors are proportionally small. Conversely, when misalignment is proportionally large (e.g., a basin is only 1 % covered by the same RCM classification), this implies a small basin. Because the basin is small, the covered region (no matter how much smaller) must be nearby and not climatically different. 

RCM inputs are also scaled to adjust for the EPSG:3413 non-equal-area projection. This error is up to 8 % for some grid cells but ranges from - 6 % to + 8 % over Greenland and the cumulative error for the entire ice sheet is < 8 %.

** Validation
:PROPERTIES:
:CUSTOM_ID: sec:graphics
:END:

We validate the modeled outlet discharge against the observations first in bulk and then individually. Bulk comparisons are done with scatter plots (Figs. \ref{fig:scatter_daily} & \ref{fig:scatter_yearsum}) and modified Tukey plots comparing observations vs. the ratio of the RCMs to observations (Fig. \ref{fig:tukey}, based on Tukey mean-difference plots, also known as Bland--Altman plots citep:altman_1983,martin_1986).

We introduce the graphics here as part of the methods to reduce replication in figure captions - we show 10 nearly identical graphics (Figs. \ref{fig:W} and \ref{fig:L} through \ref{fig:Q}) for 10 different observation locations, and each graphic uses the same template of six panels.

For each figure (Figs. \ref{fig:W} and \ref{fig:L} to \ref{fig:Q}), the top panel (a) shows a satellite basemap with the land portion of the basin of interest (if it exists) outlined in dark green, the streams within that basin in light green, the basin outlet as an orange filled diamond, and the stream gauge location as an orange unfilled diamond. Ice basin(s) that drain to the outlet are outlined in thick dark blue if they exist, and all other ice basins are outlined in thin dark blue. Both MAR and RACMO use the same domains. The RCM ice domain is in light blue, and the RCM land domain is not shown, but is outside the light blue ice domain (not including the water). The scale of each map varies, but the basin lines (green and dark blue) are on a 100 m grid, and the RCM grid cells (light blue) are on a 1 km grid.

Panel b shows an example time series - whatever data are available for the last calendar year of the observations.

Panel c shows a scatter plot of observations vs. RCM-derived discharge. This is the same data shown in Fig. \ref{fig:scatter_daily} but subset to just the basin of interest. Color encodes day of year, and a kernel density estimation (KDE) of the discharge highlights where most points occur - not necessarily visible without the KDE because the points overlap (total number of plotted points is printed on the graphic near "n:"). The r^{2} correlation coefficient for each RCM-derived discharge is displayed. The gray band shows the 5 to 95 % prediction interval, and the three solid lines mark the 1:1, 1:5, and 5:1 ratios.

Panel d shows observations vs. the ratio of the RCM to the observations. This is the same data shown in Fig. \ref{fig:tukey}, but subset to just the basin of interest. Color denotes sample density (similar to the KDE in panel c). The horizontal lines mark the mean, 0.05, and 0.95 quantile of the ration between the RCM and the observations. A value of 1 (or 10^{0}) is agreement between observations and the RCM, and a value of 2 or 0.5 is a factor of 2 or a +100/-50 % disagreement. The horizontal split marks the bottom one-third and top two-thirds quantiles of discharge. 

* Product evaluation and assessment
** Main characteristics                                   :ignore:
:PROPERTIES:
:header-args:bash+: :eval no :session
:END:

Results of this work include (1) ice-margin-terminating streams, outlets, and basins; (2) coast-terminating streams, outlets, and basins; (3) discharge at the ice marginal outlets from ice runoff; and (4) discharge at the coastal outlets from land runoff. Discharge products are provided from both the MAR and RACMO RCMs. We note that our subglacial streams represent where the model routes the water and do not indicate actual streams, unlike the land streams that do appear near actual streams when compared to satellite imagery. Even so, these streams routed using simple subglacial theory show remarkable alignment with ice surface streams and lakes visible in satellite imagery. This may support the theory that basal topography exerts a strong control on supraglacial hydrology citep:lampkin_2011,sergienko_2013_glaciological,crozier_2018, or may indicate a poorly represented and smooth bed in BedMachine, and therefore Eq. [[eq:head]] is effectively applying surface routing in these locations.

# read ./tmp/coverage_report

Of the 361,950 km^{2} of basin land cells, the RCMs cover 339,749 km^{2} (~94 %) with their land grid cells, and 22,201 km^{2} (~6 %) of basin grid cells are filled in with our coverage algorithm (Sect. \ref{sec:methods:discharge}; the RCMs have these as ice or ocean). A total of 51,532 km^{2} of RCM land is discarded because the basins classify part or all of these cells as ice or ocean. Of the 1,781,816 km^{2} of basin ice cells, the RCMs cover 1,760,912 km^{2} (~99 %) with their ice cells, and 20,904 km^{2} (~1 %) of basin grid cells are filled in (the RCMs have these as land or ocean). A total of 21,793 km^2 of RCM ice is discarded, because the basins classify part or all of these cells as land or ice (table and data available in at https://github.com/GEUS-Glaciology-and-Climate/freshwater citep:github_freshwater).

Our coverage correction (Sect. \ref{sec:methods:discharge}) adjusts RCM ice runoff values by ~3 %. Discarding RCM ice runoff that does not match the underlying mask ice cells results in a 5 % reduction in discharge. However, applying our coverage algorithm to adjust RCM inputs for regions where basins have ice but the RCMs do not results in an 8 % increase from the reduced discharge (net gain of ~3 %). A similar adjustment occurs for RCM land runoff.

** Comparison with previous similar work

Our static products - streams, outlets, and basins - have been previously estimated. citet:lewis_2009 identified 293 distinct hydrologic ice basins and provided a data set of ice basins and ice margin outlets. Our work, a decade later, has ~2 orders of magnitude more basins and outlets because of the higher resolution of the input data, and includes additional data. We provide ice basins, ice margin outlets, ice streams with metadata, land basins, coastal outlets, and land streams with metadata. citet:lewis_2009 generated basins from a 5 km DEM, compared to the 100 m DEM used here. Routing with a 5 km DEM that does not capture small-scale topography is likely to cause some basins and outlets to drain into an incorrect fjord - we find that some land basins delineated with even the 150 m BedMachine land surface may drain into the incorrect fjord, but we did not find similar errors with the 100 m ArcticDEM product used in this work.

Our time-series product (discharge) also has existing similar products. The most recent of these is from citet:bamber_2018_freshwater, who provide a data product at lower spatial resolution (5 km), lower temporal resolution (monthly), and only coastal discharge, not coastal basins, ice basins, or ice margin outlets and discharge. However, citet:bamber_2018_freshwater surpasses our product in that spatial coverage includes a larger portion of the Arctic including Iceland, Svalbard, and Arctic Canada. Furthermore, by providing data at 5 km spatial and monthly temporal resolution, citet:bamber_2018_freshwater implements the main strategy suggested here to increase the signal-to-noise ratio of the data - averaging discharge in space or time (see Sect. \ref{sec:mitigation}). 

We show both the geospatial and temporal differences between this product and citet:bamber_2018_freshwater for an example location - Disko Island (Fig. [[fig:bamber_2018]]). Spatially our product allows assessment of discharge at interior locations, necessary when comparing with observations that are not at the coast (for example, the Leverett Glacier observations, Fig. [[fig:L]]). Temporally, the MAR and RACMO runoff summed over all of Disko Island and to monthly resolution is similar to the monthly Disko Island discharge of citet:bamber_2018_freshwater, but the daily resolution shows increased variability and individual discharge events (from warm days or rain) not seen in the monthly view.

A similar GIS workflow was presented by citet:pitcher_2016 only focusing on the discharge uncertainty from basal routing assumptions (the \(k\) parameter in Eq \ref{eq:head}). We find these differences to be smaller than the differences between RCMs or between RCM and observations (see Sect. \ref{sec:uncertainty}).

** Validation against observations

\label{sec:validation_obs}

Here we compare our results to all publicly accessible observations we could find or those willing to become open and publicly accessible as part of this work (Table [[tbl_obs]]).

This validation compares observations with discharge at stream gauges derived from RCM runoff estimates, much of it coming from far inland on the ice sheet. Disagreement is expected and does not indicate any specific issues in the RCMs but is instead likely due to our routing algorithm (Sect. \ref{sec:methods:discharge}).

Below we discuss first the validation for all discharge estimates together and then the individual outlets. For the individual outlets we begin by focusing on the problematic results in order of severity -- Watson River (Figs. \ref{fig:W} & \ref{fig:W_adjust}), Leverett Glacier (Fig. \ref{fig:L}), and Kiattuut Sermiat (Fig. \ref{fig:Ks}) -- and show that for two of these three, simple solutions are available, although manual intervention is needed to detect the issue and then adjust results.

*** Bulk validation

#+BEGIN_SRC jupyter-python :exports none
<<load_all_obs>>
print(obs_all.replace(0,np.nan).dropna().shape)
print(obs_noGEM.replace(0,np.nan).dropna().shape)
#+END_SRC

#+RESULTS:
: (15778, 3)
: (5341, 3)


A comparison of every day of observational data with discharge > 0 (15,778 days) and the two RCMs (Fig. [[fig:scatter_daily]]) shows good agreement with r^{2} of 0.45 and 0.88 for discharge derived from MAR and RACMO runoff respectively (hereafter "MAR" and "RACMO"). This comparison covers more than 4 orders of magnitude of modeled and observed discharge. The RACMO vs. observed discharge is within a factor of 5 (e.g., plus or minus half an order of magnitude), although both RCMs report only ~50 % of the observed discharge for the largest volumes at the Watson River outlet (Fig. \ref{fig:W}). The reason for the disagreement at the Watson River outlet is discussed in detail in Sect. \ref{sec:W}. 

The four near-Nuuk GEM basins (Table \ref{tbl_obs}, Sect. \ref{sec:K}) have ice basins but either no or limited coverage in the RCMs. When excluding these basins from the comparison the r^{2} agreement changes to 0.59 and 0.78 for MAR and RACMO respectively, and the 5 to 95 % prediction interval is significantly smaller for MAR (red band in Fig. \ref{fig:scatter_daily}). The largest disagreements throughout this work come from these small basins with no RCM coverage. These disagreements are therefore indicative of differences between the land/ice classification mask used by the RCMs compared with the basin masks used here and not necessarily an insufficient ability of the models to simulate melting (near-surface) climate conditions.

Fig. [[fig:scatter_yearsum]] shows a similar view as Fig. [[fig:scatter_daily]], but here each observational data set and associated daily discharge is summed by year for the days in that year that observations exist (hence units m^{3} and not m^{3} yr$^{-1}$; for example four "L" means there are four calendar years with some observations at the Leverett outlet). Here it is more clear that the Watson River outlet (Sect. \ref{sec:W}) reports ~50 % of the observed discharge, the Kiattuut Sermiat outlet (Sect. \ref{sec:Ks}) overestimates discharge, and the remainder fall within the factor-of-2 lines, except for low discharge at Kingigtorssuaq in the MAR RCM where the RCMs do not cover that small glacier (Sect. \ref{sec:K}).

\label{sec:method:tukey}

Because discharge spans a wide range (~4 orders of magnitude, Fig. \ref{fig:scatter_daily}), a high correlation (r^{2} of 0.88, Fig. \ref{fig:scatter_daily}) may be due primarily to the range which is larger than the error citep:altman_1983,martin_1986. Fig. \ref{fig:tukey} compensates for this by comparing the observations with the ratio of the RCM to the observations. This graphic again excludes the four near-Nuuk GEM basins. From Fig. \ref{fig:tukey}, the top two-thirds of observed discharge has modeled discharge underestimated by a factor of 0.78 (MAR) and 0.73 (RACMO), as well as 5 to 95 % quantile of 0.30 to 2.08. The top two-thirds of observed discharge spans ~2 orders of magnitude (width of horizontal lines, from ~10^{1} to ~10^{3} m^{3} s^{-1}). The ratio of the RCMs to these observations for the top two-thirds has a 5 to 95 % quantile range of ~1 order of magnitude (distance between horizontal lines, from log$_{10}$ 0.3 to log$_{10}$ 2.08 = 0.84). The 5 to 95 % quantile range of the ratio between the RCMs and the observations is therefore half the range of the observations. Put differently, days with high observed discharge may have modeled discharge within \pm0.5 order of magnitude, or plus or minus a factor of 5, or +500/-80 %. The modeled discharge is not likely to move farther than this from the observations, and high discharge remains high.

The bottom third of discharge is where the largest disagreement occurs. The mean model values are near the observed - the ratio of RCM to observed discharge is scaled by 0.67 for MAR (~33 % low) and 1.08 for RACMO (~8 % high), but the 5 to 95 % quantile range of the ratio between RCM and observations is large. Although large uncertainties for low discharge may not seem to matter for some uses (e.g., estimates of total discharge from Greenland, which is dominated by the largest quantities of discharge), it may matter for other uses. The bottom one-third quantile of observed discharge spans 3 orders of magnitude (10^{-2} to ~10^{1}) but the uncertainty of the RCM-to-observations ratio spans ~4 and ~2 orders of magnitude for MAR and RACMO respectively (~10^{-3} to ~2.2x10^{1} MAR; ~10^{-1} to 2.2x10^{1} RACMO). 

*** Basin sizes                                         :noexport:

#+BEGIN_SRC jupyter-python :var obs_xy=tbl_obs_xy_cache :exports none
<<py_init>>

import geopandas as gp
from shapely.geometry import Point

if 'land' not in locals():
    land = (gp.read_file("./freshwater/land_100/outlets.gpkg").set_index("cat"))\
        .merge(gp.read_file("./freshwater/land_100/basins_filled.gpkg").set_index("cat"), left_index=True, right_index=True)\
        .rename(columns={"geometry_x":"outlet", "geometry_y":"basin"})\
        .set_geometry('basin')
    ice = (gp.read_file("./freshwater/ice_100/outlets.gpkg").set_index("cat"))\
        .merge(gp.read_file("./freshwater/ice_100/basins.gpkg").set_index("cat"), left_index=True, right_index=True)\
        .rename(columns={"geometry_x":"outlet", "geometry_y":"basin"})\
        .set_geometry('basin')

gdf = gp.GeoDataFrame(obs_xy, columns=['abbrev','x','y'], crs="EPSG:3413").set_index("abbrev")
gdf['geometry'] = [Point(x,y) for x,y in zip(gdf['x'],gdf['y'])]

df = pd.DataFrame(index=gdf.index, columns=['ice','land'])
for obs in gdf.index:
    basin_land = land[land.contains(gdf.loc[obs].geometry)]
    basin_ice = ice[ice.coast_id == basin_land.index.values[0]]
    # print(obs, basin_ice.shape)

    df.loc[obs, 'ice'] = basin_ice['area'].sum() / 1E6 # m^2 -> km^2
    df.loc[obs, 'land'] = (basin_land['basin'].area/1E6).values[0] - df.loc[obs, 'ice']
    if obs == 'L':
        df.loc[obs,'land'] = 0
    

df['total'] = df['ice'] + df['land']
df['ice %'] = df['ice'] / df['total'] * 100
df['land %'] = df['land'] / df['total'] * 100

df = df[['total','land','land %','ice','ice %']]

df
#+END_SRC

#+RESULTS:
| abbrev |   total |   land |  land % |     ice |   ice % |
|--------+---------+--------+---------+---------+---------|
| Ks     |  693.33 | 391.31 | 56.4392 |  302.02 | 43.5608 |
| K      |    7.56 |   5.64 | 74.6032 |    1.92 | 25.3968 |
| Kb     |   37.52 |  28.71 | 76.5192 |    8.81 | 23.4808 |
| L      | 1360.88 |      0 |       0 | 1360.88 |     100 |
| O      |   16.37 |  14.39 | 87.9047 |    1.98 | 12.0953 |
| Q      |   13.22 |    2.2 | 16.6415 |   11.02 | 83.3585 |
| R      |  100.12 |  72.39 | 72.3032 |   27.73 | 27.6968 |
| T      |   24.85 |  18.89 | 76.0161 |    5.96 | 23.9839 |
| W      | 1881.79 | 520.91 | 27.6816 | 1360.88 | 72.3184 |
| Z      |  487.02 | 377.76 | 77.5656 |  109.26 | 22.4344 |


*** Watson River
:PROPERTIES:
:CUSTOM_ID: sec:W
:END:

#+BEGIN_SRC jupyter-python :exports none :eval no-export
<<py_init>>
<<load_all_obs>>

df = (obs['W']).replace(0, np.nan).dropna()

q = df['obs'].quantile([0.05, 0.33, 0.95])
df_bot = df[df['obs'] < q[0.33]]
df_top = df[df['obs'] >= q[0.33]]

print(df_bot.shape[0], df_top.shape[0])
print(df_bot['obs'].max())
#+END_SRC

#+RESULTS:
: 622 1263
: 131.09

The Watson River discharge basin area is 1882 km^{2}, of which 521 km^{2} (28 %) is land and 1361 km^{2} (72 %) is ice (Fig [[fig:W]]a). The partial (last calendar year) discharge time series shows MAR and RACMO agree well with each other but have a maximum of 500 m^{3} s^{-1}, while observations are up to 4x more (Fig. [[fig:W]]b). Low discharge (both early and late season) is overestimated and high discharge is underestimated, approximately equal for both RCMs (Fig. [[fig:W]]c). The low discharge overestimate ranges from a mean multiple of 1.68 (MAR) and 1.57 (RACMO) to a +95 % quantile ratio of ~70 (MAR) and ~52 (RACMO). The high-discharge underestimate has a mean multiple of ~0.5 for both MAR and RACMO and a 5 to 95 quantile range of between 0.23 to 1.09. 

The Watson River discharge presented here is approximately half of the citet:van-as_2018 discharge for high discharge. The large underestimate for high discharge may be due to either errors in the basin delineation used in this study, errors in the stage--discharge relationship used by citet:van-as_2018, errors in the RCM runoff estimates, or a combination of the above three. All three of these error sources increase with high discharge (and associated melt): basin delineation becomes less certain with inland distance from the ice sheet margin. The river stage--discharge conversion becomes less certain at high stage levels. Runoff calculations become less certain from a snow surface than an ice surface because of, e.g., snow density, subsurface refreezing, and surface darkening.

The complexity of estimating the area of the Watson River catchment is described by citet:monteban_2020, who note that previous studies have used values ranging from 6131 km^{2} citep:mernild_2010_runoff to 12547 km^{2} citep:van-as_2012. Our basin is smaller than the basin used in citet:van-as_2018 and similar to citet:mernild_2018 who attributed the difference between their modeled outflow and observations from citet:van-as_2017 to their decision to use surface rather than subglacial routing, and applied a correction term. We find that our basin does not include a separate basin to the south that is part of the Watson River ice basin in citet:van-as_2018 (from citet:lindback_2015 and citet:lindback_2014). We are able to recreate the citet:van-as_2018 basin but only when using the citet:lindback_2014 bed and the citet:bamber_2013 surface. When using any other combination of bed DEM, surface DEM, or \(k\) values, we are unable to match the citet:lindback_2015 basin. Instead all our basins resemble the basin shown in Fig [[fig:W]]. To solve this, we manually select two large ice basins to the south of the Watson River ice basin. Modeled and observed discharge agree after including these two basins (Fig. [[fig:W_adjust]]), suggesting basin delineation, not stage--discharge or RCM runoff is the primary cause for this disagreement. Furthermore, it is the additional width at lower elevation from the larger basin, not the increased inland high-elevation area, that likely contributes the runoff needed to match the observations, because 85 % of all surface runoff occurs below 1350 m, and almost all below 1850 citet:van-as_2017.

At the Watson River outlet, there is no reason to suspect this product underestimates observed discharge by 50 %. The observations are needed to highlight the disagreement. Once this disagreement is apparent, it is also not clear what to do to reduce the disagreement without the previous efforts by citet:lindback_2015 and citet:lindback_2014. Basin delineation is discussed in more detail in the uncertainty section (Sect. \ref{sec:uncertain:basin}). The other two problematic areas highlighted above (Sect. \ref{sec:validation_obs}) can be detected and improved without observational support.

*** Leverett Glacier
:PROPERTIES:
:CUSTOM_ID: sec:L
:END:

The Leverett Glacier basin area is 1361 km^{2} and 100 % ice (Fig [[fig:L]]a). The partial (last calendar year) discharge time series shows MAR and RACMO agree well with each other and with the observations (Fig. [[fig:L]]b), with no seasonal dependence (Fig [[fig:L]]c). The 5 to 95 % prediction interval for MAR is generally within the 1:5 and 5:1 bands, with a larger spread for RACMO (Fig [[fig:L]]c). High model discharge is 3 % higher than observed (MAR) or 25 % higher than observed (RACMO), and the 5 to 95 quantile range of the ratio is between 0.73 and 1.62 (MAR) and 0.83 and 2.02 (RACMO). Low model discharge is also centered near the observations, but as always larger errors exist for low discharge (Fig [[fig:L]]d).

This basin is problematic because the basin feeding the outlet is small (< 5 km^{2}), but even without the observational record satellite imagery shows a large river discharging from the ice sheet here. Meanwhile, a large (100s of km^{2}) ice basin does discharge just a few 100 m away, but not upstream of this gauge location. We therefore adjust the gauge location onto the ice (equivalent to selecting a different outlet) so that our database access software selects what appears to be the correct basin given the size of the stream in the satellite imagery (Fig. [[fig:L]]). 

The plots shown here use the adjusted gauge location and modeled discharge appears to match the observed discharge. When plotting (not shown) the modeled discharge for the outlet just upstream of the true gauge location, results are clearly incorrect. This issue - small basins at the margin and incorrect outlet location - is persistent throughout this product and discussed in more detail in Sect. \ref{sec:uncertain:basin}.

The Leverett Glacier basin is a subset of the Watson River outlet basin (Sect. \ref{sec:W}). The strong agreement here supports our claim that the Watson River disagreement is not from the RCM runoff or the stage--discharge relationship but more likely due to basin area. The correct Watson River basin should include some basins outside of the Leverett Glacier basin that still drain to the Watson River outlet gauge location.

*** Kiattuut Sermiat
:PROPERTIES:
:CUSTOM_ID: sec:Ks
:END:

#+BEGIN_SRC jupyter-python
<<py_init>>
<<load_all_obs>>

df = obs['Ks']
df['MAR'] = df['MAR_ice'] + df['MAR_ice_upstream']
df['RACMO'] = df['RACMO_ice'] + df['RACMO_ice_upstream']
df = df[['obs','MAR','MAR_land','RACMO','RACMO_land']]

df = df.sum(axis='rows')

df['MAR land %'] = df['MAR_land'] / (df['MAR']+df['MAR_land']) * 100
df['RACMO land %'] = df['RACMO_land'] / (df['RACMO']+df['RACMO_land']) * 100

df
#+END_SRC

#+RESULTS:
: obs             2550.637971
: MAR             4812.990611
: MAR_land        1918.759009
: RACMO           5111.147623
: RACMO_land      1433.019818
: MAR land %        28.503125
: RACMO land %      21.897664
: dtype: float64


The Kiattuut Sermiat discharge basin area is 693 km^{2}, of which 391 km^{2} (56 %) is land and 302 km^{2} (44 %) is ice. The basin area is incorrectly large because the land basin reported and shown includes the entire basin that contains the discharge point, of which some is downstream (Fig [[fig:Ks]]a). However, only ~25 % of runoff comes from the land, and only a small portion of the land basin is downstream of the gauge location, so this is not enough to explain the discharge vs. observation disagreement. The partial (last calendar year) discharge time series shows MAR and RACMO agree well with each other, but are significantly higher than the observations (Fig. [[fig:Ks]]b). Both low and high discharge are overestimated, but the 5 to 95 % quantile range of the ratio are within a factor of 5 (Fig [[fig:Ks]]c), with a mean ratio between 1.71 (RACMO bottom one-third of discharge) to 2.44 (MAR high two-thirds discharge)

The Kiattuut Sermiat gauge is in a problematic location in terms of determining the actual (nontheoretical) upstream contributing area. Similar to the Leverett Glacier gauge location, the issues here can be estimated independent of observational data. Specifically, it is not clear if this stream includes water from the larger glacier to the east and east-northeast that feeds this glacier (Fig. [[fig:Ks]]a) - in our delineation it does not. Furthermore, several glaciers to the north-northwest and detached from the glacier near the stream gauge appear to drain into a lake that then drains under the glacier and then to the stream gauge. This latter issue is observable in any cloud-free satellite imagery and does not need the basin delineations provided here to highlight the complexities of this field site. Nonetheless, RCM discharge estimates are only slightly more than double the observations.

The Kiattuut Sermiat gauge location may have been selected in part due to its accessibility - it is walking distance from the Narsarsuaq Airport. The data may also suit their intended purpose well and there are likely many results that can be derived independent of the area or location of the upstream source water. However, if the location or area of the upstream contributions is important, then gauge location should balance ease of access and maintenance with the ease with which the data can be interpreted in the broader environment.

*** GEM observations near Nuuk

\label{sec:K}
\label{sec:Kb}
\label{sec:O}
\label{sec:T}

# | abbrev |   total |   land |  land % |     ice |   ice % |
# |--------+---------+--------+---------+---------+---------|
# | K      |    7.56 |   5.64 | 74.6032 |    1.92 | 25.3968 |
# | Kb     |   37.52 |  28.71 | 76.5192 |    8.81 | 23.4808 |
# | O      |   16.37 |  14.39 | 87.9047 |    1.98 | 12.0953 |
# | T      |   24.85 |  18.89 | 76.0161 |    5.96 | 23.9839 |

Four Greenland Ecosystem Monitoring (GEM) program stream gauges are located near Nuuk, with similar basin properties. All are small (7.56 to 37.52 km^{2}) and 10 % to 25 % ice in the basin mask, but two of the four (Kingigtorssuaq, Fig. [[fig:K]]; and Oriartorfik, Fig. [[fig:O]]) contain small glaciers contributing to observed discharge but no RCM ice cells cover those glaciers, and the remaining two (Teqinngalip, Fig. [[fig:T]]; and Kobbefjord, Fig. [[fig:Kb]]) have several small glaciers, but only one per basin has RCM ice coverage. 

All four of these basins show some weak agreement. The maximum r^{2} is 0.47 (Fig. [[fig:T]]c) and the minimum is 0.11 (Fig [[fig:K]]c), but we note that the worst agreement comes from a basin with no glaciers in the RCM domain, and that in all cases the mean high discharge agrees well, suggesting high discharge in these small basins with few small glaciers may be due to rain (captured in the RCMs) rather than warm days and melted ice.

*** Remaining observations

\label{sec:R}
\label{sec:Z}
\label{sec:Q}
 
Three additional stream gauges remain: Røde Elv, Zackenberg, and Qaanaaq. 

The Røde Elv basin is situated at the southern edge of Disko Island (Fig. [[fig:bamber_2018]]). It has an area of 100 km^{2}, of which 72 km^{2} is land and 28 km^{2} is ice (Fig [[fig:R]]a). The partial (last calendar year) discharge time series shows MAR, RACMO, and the observations all in approximately the same range but with high variability (Fig. [[fig:R]]b). Of the few samples here (n = 98), most are within the factor-of-5 bands for MAR and a few more are outside the bands for RACMO (Fig. [[fig:R]]c). Mean discharge offset ranges from a ratio of 0.82 (RACMO low) to 1.85 (MAR low), with high-discharge estimates slightly closer to observations - a 48 % and 77 % overestimate for MAR and RACMO respectively (Fig. [[fig:R]]d).

The Zackenberg basin in NE Greenland has an area of 487 km^{2}, of which 378 km^{2} (78 %) is land and 109 km^{2} (22 %) is ice (Fig. [[fig:Z]]a). The partial (last calendar year) discharge time series shows disagreements between MAR and RACMO that generally bound the observations (Fig. [[fig:Z]]b). RACMO-derived discharge is consistently high for low discharge early in the year, but both discharge products fall mostly within the factor-of-5 bands (Fig. [[fig:Z]]c). For high discharge, mean modeled discharge is 9 % high (MAR) and 24 % low (RACMO)  and has a worst-case 5 to 95 % quantile range low by a factor of 0.29 (Fig. [[fig:Z]]d).

The Qaanaaq basin in NW Greenland has an area of 13.2 km^{2}, of which 2.2 km^{2} (17 %) is land and 11 km^{2} (83 %) is ice (Fig. [[fig:Q]]a). The partial (last calendar year) discharge time series shows disagreements between MAR and RACMO that generally bound the observations (Fig [[fig:Q]]b). Of the few samples (n = 82), MAR preferentially overestimates and RACMO underestimates discharge, but both generally within a factor of 5 (Fig [[fig:Q]]c). The mean high-discharge ratio is 1.26 (MAR) and 0.4 (RACMO) from Fig. [[fig:Q]]d.

** Uncertainty
:PROPERTIES:
:CUSTOM_ID: sec:uncertainty
:END:

The volume of data generated here is such that manually examining all of it or editing it to remove artifacts or improve the data would be time and cost prohibitive. A similar warning is provided with the ArcticDEM data used here. However, any ArcticDEM issues interior to a basin do not impact results here that are aggregated by basin and reported at the outlet. ArcticDEM issues that cross basin boundaries should only impact a small part of the basin near the issue.

Uncertainty from RCM inputs and observations are considered external to this work, although they are still discussed (Sects. \ref{sec:uncertain:RCM} and \ref{sec:uncertain:obs}). In this work, we introduce one new source of uncertainty - the routing model, which generates both temporal (runoff delay) and spatial (basin delineation) uncertainty.

*** Temporal uncertainty

The RCMs include a time lag between when water melts in the model and when it leaves a grid cell. RACMO retention occurs only when there is firn cover (no retention when bare ice melts); MAR includes a time delay of up to 10 days that is primarily a function of surface slope citep:zuo_1996,yang_2019. However, neither model includes a subglacial system. Properly addressing time delays with runoff requires addressing storage and release of water across a variety of timescales in a variety of media: firn (e.g., citet:munneke_2014,vandecrux_2019), supraglacial streams and lakes (e.g., citet:zuo_1996,smith_2015,yang_2019), the subglacial system (e.g., citet:rennermalm_2013), possibly terrestrial streams and lakes (e.g., citet:van-as_2018) and a variety of other physical processes that are not within the scope of surface mass balance (SMB) modeling. Runoff delay can be implemented outside the RCMs (e.g., citet:liston_2012,mernild_2018), but for this version of the product we assume that once an RCM classifies meltwater as runoff, it is instantly transported to the outlet. Actual lags between melt and discharge range from hours to years citep:colgan_2011_hydrology,van-as_2017,rennermalm_2013,livingston_2013. 

Data released here include no additional lag beyond the RCM lag, although a 7 d running mean (cf. citet:van-as_2017) is included in all of the results presented here except Fig. [[fig:bamber_2018]], which shows monthly summed data, and Fig. [[fig:scatter_yearsum]], which shows yearly summed data. When increasing the signal to noise by summing by year (Fig. [[fig:scatter_yearsum]] vs. Fig. [[fig:scatter_daily]]), model results more closely match observations.

*** Basin uncertainty
:PROPERTIES:
:CUSTOM_ID: sec:uncertain:basin
:END:

Basin uncertainty is a function of the subglacial routing assumptions (the \(k\) parameter in Eq. [[eq:head]], which in reality varies in both space and time). However, basin uncertainty does not necessary translate to discharge uncertainty. For example, when comparing two \(k\) simulations, a large basin in simulation \(k_0\) may change only its outlet by a few grid cells in \(k_1\). A small micro-basin may appear in \(k_1\) with its outlet in the same grid cell as the large \(k_0\) outlet. The large change in discharge between the two outlets at the same location in \(k_0\) and \(k_1\) is not an appropriate estimate of uncertainty - rather the large basin in \(k_0\) should be compared with the almost entirely overlapping large basin in \(k_1\) with the different outlet. This fluidity of basins and outlets between \(k\) scenarios makes it almost impossible to define, identify, and compare basins between scenarios, unless working manually with individual basins (as we did, for example, at the Leverett Glacier observation location, modeled upstream basin, and adjusted upstream basin; see Sect. \ref{sec:L}). 

Another example has a large basin in simulation \(k_0\) and a similarly large basin in simulation \(k_1\) draining out of the same grid cell, but overlapping only at the outlet grid cell. Upstream the two do not overlap and occupy different regions of the ice sheet. These two basins sharing one outlet (between different \(k\) simulations) could have similar discharge. Put differently, although inland grid cells may change their outlet location by large distances under different routing assumptions (Fig. [[fig:k_basin_change]]), that does not imply upstream basin area changes under different routing assumptions. Large changes in upstream catchment area are possible citep:chu_2016_rerouting, but we note citet:chu_2016_rerouting highlight changes at only a few outlets and under the extreme scenario of \(k = 1.11\) describing an overpressured system. Because \(\rho_w/\rho_i = 1.09\), setting \(k = 1.09\) reduces Eq. \ref{eq:head} to \(h = z_s\) and is equivalent to an overpressured system with surface routing of the water. In a limited examination comparing our results with \(k \in [0.8, 0.9, 1.0]\), we did not detect basins with large changes in upstream area. In addition, all time series graphics show the mean RCM discharge for \(k = 1.0\), but the uncertainty among all three \(k\) values (not shown) is small enough that it is difficult to distinguish the three separate uncertainty bands - the difference between RCMs or between RCMs and observations is much larger than uncertainty from the \(k\) parameter.

The above issues are specific to ice basins. Land basin outlets do not change location, and the range of upstream runoff from different \(k\) simulations to a land outlet provides one metric of uncertainty introduced by the \(k\) parameter. This uncertainty among all three \(k\) values is small at ice margin outlets. It is even smaller at land outlets which act as spatial aggregators and increase the signal-to-noise ratio. 

Below, we discuss the known uncertainties, ranging from least to most uncertain.

The basins presented here are static approximations based on the 100 m DEM of a dynamic system. Land basin boundaries are likely to be more precise and accurate than ice basins because the land surface is better resolved, has larger surface slopes, has negligible subsurface flow, and is less dynamic than the ice surface. Even if basins and outlets seem visually correct from the 100 m product, the basin outline still has uncertainty on the order of hundreds of meters and will therefore include many minor errors and nonphysical properties, such as drainage basin boundaries bisecting lakes. However, all artifacts we did find are significantly smaller than the 1 km^{2} grid of the RCM inputs. We do not show but note that when doing the same work with the 150 m BedMachine land surface DEM, some basins change their outlet locations significantly - draining on the opposite side of a spit or isthmus and into a different fjord than the streams do when observed in satellite imagery. We have not observed these errors in streams and basins derived from the 100 m ArcticDEM in a visual comparison with Google Earth, although they may still exist.

Moving from land basins to subglacial ice basins, the uncertainty increases because subglacial routing is highly dynamic on timescales from minutes to seasons (e.g., citet:werder_2013). This dynamic system may introduce large spatial changes in outflow location (water or basin "piracy", citet:ahlstrom_2002,lindback_2015 and citet:chu_2016_rerouting), but citet:stevens_2018 suggests basins switching outlet locations may not be as common as earlier work suggests, and our sensitivity analysis suggests that near the margin where the majority of runoff occurs, outlet location often changes by less than 10 km under different routing assumptions (Fig. [[fig:k_basin_change]]). The largest (> 100 km) changes in outlet location in Fig. [[fig:k_basin_change]] occur when the continental or ice flow divides move, and one or two of the \(k\) scenario(s) drain cells to an entirely different coast or sector of the ice sheet. Finally, in some locations water is routed supraglacially, not subglacially (c.f. citet:li_2022).

The regions near the domain edges - both the land coast and the ice margin - are covered by many small basins, and in this work basins < 1 km^{2} are absorbed into their largest neighbor (see Methods section). By definition these basins are now hydraulically incorrect. An example can be seen in the Zackenberg basin (Fig. [[fig:Z]]a, southwest corner of the basin), where one small basin on the southern side of a hydraulic divide was absorbed into the large Zackenberg basin that should be defined by and limited to the northern side of the mountain range. 

Near the ice margin quality issues exist. At the margin, many of the small basins (absorbed or not) may be incorrect because the bed uncertainty is larger relative to the ice thickness, and therefore uncertainty has a larger influence on routing. Minor mask misalignments may cause hydraulic jumps (waterfalls) at the margin, or sinks that then need to be filled by the algorithm, and may overflow (i.e., the stream continues onward) somewhere at the sink edge different from the location of the real stream. The solution for individual outlets is to visually examine modeled outlet location, nearby streams in satellite imagery, and the area of upstream catchments, as we did for the Leverett Glacier outlet (Sect \ref{sec:L}). Alternatively, selecting several outlets in an area will likely include the nearby correct outlet. This can be automated and an effective method to aggregate all the micro-ice basins that occur at the domain edge is to select the downstream land basin associated with one ice outlet and then all upstream ice outlets for that land basin.

*** RCM uncertainty
:PROPERTIES:
:CUSTOM_ID: sec:uncertain:RCM
:END:

In addition to the basin delineation issues discussed above, the runoff product from the RCMs also introduces uncertainty into the product generated here. The RCM input products do not provide formal time- or space-varying error estimates, but of course do contain errors because they represent a simplified and discretized reality. RCM uncertainty is shown here with a value of \pm15 %. The MAR uncertainty comes from an evaluation by the Greenland SMB Model Intercomparison Project (GrSMBMIP; citet:fettweis_2020) that examined the uncertainty of modeled SMB for 95 % of the 10767 in situ measurements over the main ice sheet. The mean bias between the model and the measurements was 15 % with a maximum of 1000 mmWE yr^{-1}. GrSMBMIP uses integrated values over several months of SMB, suggesting larger uncertainty of modeled runoff at the daily timescale. The RACMO uncertainty comes from an estimated average 5% runoff bias in RACMO2.3p2 compared to annual cumulative discharge from the Watson River citep:noel_2019. The bias increases to a maximum of 20 % for extreme runoff years (e.g., 2010 and 2012), so here we select 15 %, a value between the reported 5 % and the maximum 20 % that matches the MAR uncertainty. We display \pm15 % uncertainty in the graphics here and suggest this is a minimum value for daily runoff data.

The 15 % RCM uncertainty is represented graphically in the time series plots when comparing to each of the observations. It is not shown in the scatter plots because the log--log scaling and many points make it difficult to display. In the time series plots, we show the mean value from the \(k = 1.0\) scenario and note that discharge from the other two \(k\) scenarios covered approximately the same range. 

*** Observational uncertainty
:PROPERTIES:
:CUSTOM_ID: sec:uncertain:obs
:END:

When comparing against observations, additional uncertainty is introduced because the stage--discharge relationship is neither completely precise nor accurate. We use published observation uncertainty when it exists. Only two observational data sets come with uncertainty: Watson River and Qaanaaq. Similar to the RCM uncertainty, they are displayed in the time series but not in the scatter plots.

*** Mitigating uncertainties
:PROPERTIES:
:CUSTOM_ID: sec:mitigation
:END:

Traditional uncertainty propagation is further complicated because it is not clear to what extent the three uncertainties (observational, RCM, and routing model) should be treated as independent from each other - all three uncertainties are likely to show some correlation with elevation, slope, air temperature, or other shared properties or processes.

Many of the uncertainties discussed here can be mitigated by increasing the signal-to-noise ratio of the product. Because we provide a high spatial and temporal resolution product, this is equivalent to many signals, each of which has some uncertainty (noise). Averaging results spatially or temporally, if possible for a downstream use of this product, will increase the signal-to-noise ratio and reduce uncertainty. 

For example, because we provide basins for the entire ice sheet, total discharge is not subject to basin uncertainty. Any error in the delineation of one basin must necessarily be corrected by the inclusion (if underestimate) or exclusion (if overestimate) of a neighboring basin, although neighboring basins may introduce their own errors. Therefore, summing basins reduces the error introduced by basin outline uncertainty and should be done if a downstream product does not need an estimate of discharge from a single outlet. This feature is built-in to coastal outlet discharge, which is not as sensitive to our routing algorithm as ice margin outlet discharge because most coast outlets include a range of upstream ice margin outlets (e.g., Fig. [[fig:W]] vs. [[fig:L]]). Conversely, at the ice margin, outlet location and discharge volume is more uncertain than at the land coast. However, most runoff is generated near the ice margin, and as runoff approaches the margin, there are fewer opportunities to change outlet location (Fig. [[fig:k_basin_change]]).

Our coverage algorithm (Sect \ref{sec:methods:discharge}) only fills in glaciated regions that have at least some RCM coverage. When working with basins that have glaciated areas and no RCM coverage as in the case for all four of the GEM outlets near Nuuk, discharge could be approximated by estimating discharge from the nearest covered glaciated area with a similar climatic environment.

Temporally, errors introduced by this study's assumption of instantaneous discharge can be reduced by summing or averaging discharge over larger time periods, or applying a lag function to the time series as done here and in citet:van-as_2017. Although a given volume of water may remain in storage long term, if one assumes that storage is in roughly steady state, then long-term storage shown by, for example, dye trace studies, can be ignored - the volume with the dye may be stored, but a similar volume should be discharged in its place.

*** Quality control
:PROPERTIES:
:CUSTOM_ID: sec:QC
:END:

The scale of the data are such that manual editing to remove artifacts is time and cost prohibitive. Here we provide one example of incorrect metadata. The elevation of each outlet is included as metadata by looking up the bed elevation in the BedMachine data set at the location of each outlet. Errors in BedMachine or in the outlet location (defined by the GIMP ocean mask) introduce errors in outlet elevation. 

A large basin in NW Greenland has metadata outlet elevation > 0 (gray in Fig. [[fig:overview]]) but appears to be marine terminating when viewed in satellite imagery. Elsewhere the land- vs. marine-terminating color coding in Fig. [[fig:overview]] appears to be mostly correct, but this view only provides information about the sign of the elevation and not the magnitude (i.e., if the reported depth is correct). Ice outlets can occur above, at, or below 0 m. It is easier to validate the land-terminating basins, which should in theory all have an outlet elevation of \le 0 m. That is not the case (Fig. [[fig:elev]]). Outlets at 0 m are coastal outlets. Outlets < 0 m occur when land-source runoff enters the subglacial system and discharges at depth from a marine terminating glacier, but we expect these outlets to be << 0 m, not near 0 m. This edge case also produces land outlets that exist outside of land basins. It is possible for land outlets to be correctly assigned an elevation > 0 m, if a land basin outlet occurs at a waterfall off a cliff (as might occur the edges of Petermann fjord) or due to DEM discretization of steep cells. However, most of the land outlets near but not at 0 m are likely due to mask misalignment placing a section of coastline in a  fjord (negative land elevation) or inland (positive land elevation), or discretization issues in BedMachine. The bulk of land discharge (75 %) occurs within 0 \pm10 m elevation and 90 % within 0 \pm30 m elevation (Fig. [[fig:elev]]).

** Other sources of freshwater

The liquid water discharge product provided here is only one source of freshwater that leaves the ice sheet and affects fjords and coastal seas. The other primary freshwater source is iceberg calving and submarine melt at the ice/ocean boundary of marine-terminating glaciers. A companion to the liquid water discharge product introduced here is provided by citet:mankoff_2019_ice,mankoff_2020_ice, which estimates solid ice volume flow rates across gates near marine-terminating glaciers. That downstream ice enters fjords as either calving icebergs or liquid water from submarine melting.

Both this product and citet:mankoff_2020_ice provide liquid or solid freshwater volume flow rates at outlets (this product) or grounding lines citep:mankoff_2020_ice, but actual freshwater discharge into a fjord occurs at a more complicated range of locations. Solid ice melts throughout the fjord and beyond (e.g., citet:enderlin_2016,moon_2017), and the freshwater discharge presented here may enter at the reported depth (Sect. \ref{sec:QC}) but rapidly rises up the ice front and eventually flows into the fjord at some isopycnal (see citet:mankoff_2016). The eventual downstream location of the fresh water is not addressed in this work.

Freshwater inputs directly to the water surface are also not included in this product. The flux (per square meter) to the water surface should be similar to the flux to the non-ice-covered land surface - assuming the orographic effects on precipitation produce similar fluxes to the near-land water surface.

Finally, basal melt from 1) geothermal heating (e.g., citet:fahnestock_2001) 2) frictional heating (e.g., citet:echelmeyer_1990) and 3) viscous heat dissipation from runoff (e.g., citet:mankoff_2017) contributes additional discharge (see for example citet:johannesson_2020) to the surface melt. Geothermal and frictional heating are approximately in steady state and contribute freshwater throughout the winter months.

** Summary

Of the 20 comparisons between the two RCMs and the 10 observations we note the following.

+ In general this product shows good agreement between observations and the modeled discharge from the RCM runoff routed to the outlets, when comparing across multiple basins, especially when ignoring small basins with small glaciers that are not included in the RCMs (Fig. \ref{fig:scatter_daily}). The agreement is not as good when estimating the discharge variability within individual basins. From this, the product is more appropriately used to estimate the magnitude of the discharge from any individual basin, and perhaps provide some idea of the statistical variability, but not necessarily the precise amount of discharge for any specific day, because routing delays are neglected.

+ The majority of the 20 comparisons have the 5 to 95 % prediction interval between scales of 1:5 and 5:1. From this, the model results match observations within plus or minus a factor of 5, or half an order of magnitude. Put differently, the daily RCM values for single or few basins have an uncertainty of +500 % or -80 %.

+ The uncertainty of +500%/-80% is for "raw" data: daily discharge for one or few basins with a simple temporal smooth. When averaging spatially or temporally over larger areas or longer times, uncertainty decreases (Sect. \ref{sec:uncertainty}). For example, when moving from daily data (Fig. [[fig:scatter_daily]]) to annual sums (Fig. [[fig:scatter_yearsum]]), the uncertainty is reduced to +100%/-50%.

+ The two RCMs agree best with each other for the three observations dominated by large ice domains (Watson River, Sect. \ref{sec:W} & Fig. \ref{fig:W}); Leverett Glacier, Sect. \ref{sec:L} & Fig. \ref{fig:L} which is a subset of the Watson River basin; and Kiattuut Sermiat, Sect. \ref{sec:Ks} & Fig. \ref{fig:Ks}). RCMs agree best with observations for ice-dominated basins with well-resolved bed topography in BedMachine (i.e., correct basins modeled in this work) - here only Leverett Glacier (Sect. \ref{sec:L} & Fig. \ref{fig:L}) meets this criterion.

+ Runoff errors increase with low discharge (panels 'd' in Figs. \ref{fig:W}, \ref{fig:L} to \ref{fig:Q}).

+ For land basins, subglacial routing errors no longer exist, basins are well defined, and errors are due to neglecting runoff delays or the RCM estimates of runoff.

+ For ice basins, errors are dominated by basin uncertainty. Errors between similar-sized and neighboring basins are likely to offset and may even cancel each other. Even so, a conservative treatment might consider errors between basins as random and reduce by the sum of the squares when summing discharge from multiple similar-sized and neighboring basins.

* Product description

These data contain a static map of Greenland's hydrological outlets, basins, and streams and a times-series of discharge from each outlet.

The output data are provided in the following formats:

** Streams                                                :ignore:

the stream data are provided as a GeoPackage standard GIS product and a metadata CSV that includes the stream type (start or intermediate segment), network, stream along-flow length, stream straight length, sinuosity, source elevation, outlet elevation, and a variety of stream indices such as the Strahler, Horton, Shreve, Hack, and other parameters citep:jasiewicz_2011. We note that the subglacial streams are unvalidated with respect to actual subglacial conduits, and they should be used with caution.

** Outlets                                                :ignore:

The outlet data are also provided as a GeoPackage and CSV, each of which include the outlet ID (linked to the basin ID), the longitude, latitude, EPSG:3413 x and y, and the outlet elevation. The outlet elevation is the BedMachine bed elevation at the outlet location, and users should be aware of quality issues identified in Sect. \ref{sec:QC}. The ice outlet metadata includes the ID, longitude, latitude, x, and y of the downstream land outlet, if one exists.

** Basins                                                 :ignore:

The basin product GeoPackage includes the geospatial region that defines the basin. The metadata CSV includes the basin ID (linked to the outlet ID), and the area of each basin.

** Discharge                                              :ignore:

The time series discharge product is provided as four NetCDF files per year, one for each domain (ice margin and land coast) and one for each RCM (MAR and RACMO). The NetCDF files contain an unlimited time dimension, usually containing 365 or 366 d; much of the same metadata as the outlets CSV file, including the outlet (also known as station) ID, the latitude, longitude, and elevation of the outlet; and a runoff variable with dimensions (station, time) and units of cubic meters per second (m^{3} s^{-1}).


** Database access software

The data can be accessed with custom code from the raw data files. However, to support downstream users we provide a tool to access the outlets, basins, and discharge for any region of interest (ROI). The ROI can be a point, a list describing a polygon, or a file, with units in longitude and latitude (EPSG:4326) or meters (EPSG:3413). If the ROI includes any land basins, an option can be set to include all upstream ice basins and outlets, if they exist. The script can be called from the command line (CLI) and returns CSV formatted tables or within Python and returns standard Python data structures (from the =GeoPandas= or =xarray= package).

For example, to query for discharge at one point (50.5 °W, 67.2 °N), the following command is issued: 

~python ./discharge.py --base ./freshwater --roi=-50.5,67.2 --discharge~, 

where =discharge.py= is the provided script, =./freshwater= is the folder containing the downloaded data, and =--discharge= tells the program to return RCM discharge (as opposed to =--outlets= which would return basin and outlet information). The program documentation and usage examples are available at https://github.com/GEUS-Glaciology-and-Climate/freshwater citep:github_freshwater.

Because the =--upstream= option is not set, the =--discharge= option is set, and the point is over land, the results of this command are a time series for the MAR and RACMO land discharge for the basin containing this point. A small subset (the first 10 days of June 2012) is shown as an example:

#+BEGIN_SRC bash :results verbatim :exports results :results table
conda activate freshwater
python ./discharge.py --base ./freshwater --roi=-50.5,67.2 --discharge --quiet | grep -A9 '2012-06-01' | tr ',' '|'
#+END_SRC

#+RESULTS:
|       time |  MAR_land | RACMO_land |
|------------+-----------+------------|
| 2012-06-01 |  0.043025 |   0.382903 |
| 2012-06-02 |   5.5e-05 |   0.095672 |
| 2012-06-03 |     5e-05 |   0.009784 |
| 2012-06-04 |     9e-06 |  -0.007501 |
| 2012-06-05 |  0.008212 |   0.007498 |
| 2012-06-06 | 28.601947 |   0.607345 |
| 2012-06-07 |  0.333926 |    0.05691 |
| 2012-06-08 |  0.489437 |   0.204384 |
| 2012-06-09 |  0.038816 |   0.167325 |
| 2012-06-10 |   5.1e-05 |   0.011415 |

If the =upstream= option is set, two additional columns are added: one for each of the two RCM ice domains. A maximum of six columns may be returned: 2 RCMs \times (1 land + 1 ice + 1 upstream ice domain), because results are summed across all outlets within each domain when the script is called from the command line (summing is not done when the script is accessed from within Python).

If the =--outlets= option is set instead of the =--discharge= option, then results are a table of outlets. For example, moving 10 ° east over the ice, 

~python ./discharge.py --base ./freshwater --roi=-40.5,67.2 --outlets~ 

results in the following.

#+BEGIN_SRC bash :results verbatim :exports results :results table
conda activate freshwater
python ./discharge.py --base ./freshwater --roi=-40.5,67.2 --outlets --quiet | tr ',' '|'
#+END_SRC

#+RESULTS:
| index |     id |     lon |    lat |      x |        y | elev | domain | upstream | coast_id | ... |
|-------+--------+---------+--------+--------+----------+------+--------+----------+----------+-----|
|     0 | 118180 | -38.071 |  66.33 | 313650 | -2580750 |  -78 | land   | False    |       -1 | ... |
|     1 |  67133 |  -38.11 | 66.333 | 311850 | -2580650 |  -58 | ice    | False    |   118180 | ... |

If the script is accessed from within Python, then the =discharge= option returns an =xarray= =Dataset= of discharge, without aggregating by outlet, and the =outlets= option returns a =GeoPandas= =GeoDataFrame=, and includes the geospatial location of all outlets and outline of all basins, and can be saved to GIS-standard file formats for further analysis.


* Conclusions                                             :ignore:
\conclusions

We provide a 100 m spatial resolution data set of streams, outlets, and basins, and a 1 day temporal resolution data set of discharge through those outlets for the entire ice sheet area from 1940 through December 2024. Access to this database is made simple for nonspecialists with a Python script. Comparing the two RCM-derived discharge products to 10 gauged streams shows the uncertainty is approximately plus or minus a factor of 5, or half an order of magnitude, or +500%/-80%, when comparing daily discharge for single or few basins. 

Because of the high spatial (individual basins) and temporal (daily) resolution, larger uncertainty exists than when working over larger areas or time steps. These larger areas and times can be achieved through spatial and temporal aggregating or by implementing a lag function.

This liquid freshwater volumetric flow rate product is complemented by a solid ice discharge product citep:mankoff_2020_ice. Combined, these provide an estimate of the majority of freshwater (total solid ice and liquid) flow rates from the Greenland Ice Sheet into fjords and coastal seas, at high temporal resolution and process-level spatial resolution (i.e., glacier terminus for solid ice discharge, stream for liquid discharge). 

This estimate of freshwater volume flow rate into Greenland fjords aims to support further studies of the impact of freshwater on ocean physical, chemical, and biological properties; fjord nutrient, sediment, and ecosystems; and larger societal impacts of freshwater on the fjord and surrounding environments. 


* Data and code availability                              :ignore:
#+LATEX: \codedataavailability{

The data from this work are available at doi:10.22008/promice/freshwater citep:GEUS_freshwater_paper.

The code and a website for postpublication updates are available at https://github.com/GEUS-Glaciology-and-Climate/freshwater citep:github_freshwater where we document changes to this work and use the GitHub Issues feature to collect suggested improvements, document those improvements as they are implemented, and document problems that made it through review. This version of the document is generated with git commit version \input{|"git describe --always --dirty='*'"}.

#+LATEX: }

* Algorithms                                            :noexport:
:PROPERTIES:
:header-args:bash+: :eval no
:header-args:jupyter-python+: :eval no
:END:
** Streams, outlets, and basins

The hydrological basins are defined based on a range of subglacial flow routing regimes.

The head gradient is defined as:
| Location | Description                       |
|----------+-----------------------------------|
| Sea      | Undefined                         |
| Land     | ArcticDEM 100 m                   |
| Ice      | ArcticDEM + k * 0.917 * thickness |


=thickness= is from BedMachine.
=k= is equal to one of 0.7, 0.8, 0.9, 1.0, or 1.09, where 1.09 ~ \(\rho_w/\rho_i\), or surface routing.
=bed= is ArcticDEM surface - BedMachine thickness.

#+NAME: head
#+BEGIN_SRC bash :results verbatim
log_info "Calculating subglacial head with k: ${k} (${domain})"
r.mapcalc "head = if(mask_o_l_i@ArcticDEM == 1, null(), 0) + if(mask_o_l_i@ArcticDEM == 2, z_s@ArcticDEM, 0) + if(mask_o_l_i@ArcticDEM == 3, (z_s@ArcticDEM - thickness@BedMachine) + ${k} * 0.917 * thickness@BedMachine)"
#+END_SRC

Then, we calculate the streams, outlets, and basins based on the head

#+NAME: sob
#+BEGIN_SRC bash :results verbatim
<<streams>>
<<outlets>>
<<basins>>
#+END_SRC

Putting it all together, we want to calculate streams, outlets, and basins to the ice edge (domain = ice), and once to the coast (domain=land). See Section [[#domains][Domains]] for implementation. This is the top-level [[./sob.sh]] code that implements the streams, outlets, and basins routing and exports the results to disk.

+ NOTE :: We only run the land domain 1x. The upstream basins are a function of subglacial pressure, but the exposed portion of the land basins are independent from subglacial pressure. I run ice_100, although any could be run because there is no ice overburden on land.

+ Note :: land domain run first, because ice domains need info from land domain (downstream land outlet)

#+BEGIN_SRC bash :results verbatim :tangle sob.sh
<<init>>

for domain in land ice; do
  for k_pct in 100 90 80; do

    # when land, only 100
    [[ ${domain} == land ]] && [[ ${k_pct} != 100 ]] && break 

    k=$(echo "scale=2; ${k_pct}/100" | bc -l)

    log_info "Setting domain to ${domain}_${k_pct}"
    g.mapset -c ${domain}_${k_pct}
    <<mask_domain>>
    <<head>>
    <<sob>>

    <<adjust_basins>>

    <<metadata>>

    <<export>>
  done
done	
#+END_SRC

Below, we'll build out the code defined above.

**** Streams

After calculating the head, we use 3rd party tools to get the flow direction and streams

#+NAME: streams
#+BEGIN_SRC bash :results verbatim
THRESH=300
log_warn "Using threshold: ${THRESH}"
log_info "r.stream.extract..."

r.stream.extract elevation=head threshold=${THRESH} memory=16384 direction=dir stream_raster=streams stream_vector=streams
#+END_SRC

**** Outlets

+ The flow direction =dir= is negative where flow leaves the domain. These are the outlets.
+ Encode each outlet with a unique id

#+NAME: outlets
#+BEGIN_SRC bash :results verbatim
log_info "Calculating outlets"
r.mapcalc "outlets_1 = if(dir < 0, 1, null())"
r.out.xyz input=outlets_1 | \
    cat -n | \
    tr '\t' '|' | \
    cut -d"|" -f1-3 | \
    v.in.ascii input=- output=outlets_uniq separator=pipe \
        columns="x int, y int, cat int" x=2 y=3 cat=1
#+END_SRC

**** Basins

Using =r.stream.basins=, we can get basins for every outlet.

#+NAME: basins
#+BEGIN_SRC bash :results verbatim
log_info "r.stream.basins..."

r.stream.basins -m direction=dir points=outlets_uniq basins=basins_uniq memory=16384 --verbose

<<absorb_small_basins>>
#+END_SRC

**** Domains
:PROPERTIES:
:ID:       f498d03c-0eac-4428-8118-b347f76b094a
:CUSTOM_ID: domains
:END:

+ For the ice domain, the domain boundary is the ice/land edge.
+ For the land domain, the domain boundary is the land/fjord edge.

#+NAME: mask_domain
#+BEGIN_SRC bash :results verbatim
g.region -dp

log_info "Masking domain to ${domain}"
[[ ${domain} == "ice" ]] && r.mask raster=mask_o_l_i@ArcticDEM maskcats=3 --o # mask to ice
[[ ${domain} == "land" ]] && r.mask raster=mask_o_l_i@ArcticDEM maskcats="2 3" --o # mask to land & ice

<<mask_small_areas>>

#+END_SRC

**** Adjust Basins

I make the following basin adjustments:

+ Ice basins have nunatuks masked out. They needed to be classified as "ice" for the routing algorithm, otherwise SOBs occur inland, not routed to the ice margin, but the "basin" raster used for masking RCM data should not include the nunatuk area.

+ Land basins have nunatuks and inland "land islands in the ice" included in the land basin. No outlets occur here, but the land area and basin ID match the associated outlet.

#+NAME: adjust_basins
#+BEGIN_SRC bash :results verbatim
if [[ ${domain} == "ice" ]]; then
  log_info "Adjusting ice basins..."

  g.rename raster=basins,basins_filled vector=basins,basins_filled
  r.mapcalc "basins = basins_filled * mask_ice_holes@Citterio_2013"
  r.to.vect -v input=basins output=basins type=area
  v.db.dropcolumn map=basins column="label"
fi

if [[ ${domain} == "land" ]]; then
  log_info "Adjusting land basins..."

  g.rename raster=basins,basins_filled vector=basins,basins_filled
  r.mapcalc "basins = basins_filled * not_ice@Citterio_2013"
  r.to.vect -v input=basins output=basins type=area
  v.db.dropcolumn map=basins column="label"
fi
#+END_SRC


**** Metadata

#+NAME: metadata
#+BEGIN_SRC bash :results verbatim
<<add_metadata>>
<<add_stream_indices>>
#+END_SRC

***** Add Metadata

+ streams [2/2]
  + [X] stream indices
  + [X] stream length
+ basin [2/2]
  + [X] area
  + [X] ice - has some ice contribution
+ outlet [5/5]
  + [X] acc value - no, can use area
  + [X] BedMachine z_b
  + [X] lon, lat
  + [X] EPSG 3413 x, y
  + [X] link margin outlets to coast outlet

#+NAME: add_metadata
#+BEGIN_SRC bash :results verbatim
log_info "Adding metadata..."

###
### streams
###
# v.db.addcolumn map=streams column="length DOUBLE"
v.to.db map=streams option=length column=length

###
### outlets
###
v.db.addcolumn map=outlets column="lon DOUBLE PRECISION"
v.db.addcolumn map=outlets column="lat DOUBLE PRECISION"
v.db.addcolumn map=outlets column="x INT"
v.db.addcolumn map=outlets column="y INT"
# v.db.addcolumn map=outlets column="cells INT"
v.db.addcolumn map=outlets column="elev INT"

# r.mask -r

v.what.rast map=outlets raster=x@PERMANENT column=x
v.what.rast map=outlets raster=y@PERMANENT column=y
v.what.rast map=outlets raster=z_b@BedMachine column=elev

# probably a more efficient way to get lon,lat column from x,y...
mkdir -p tmp
db.select -c sql='select x,y,cat from outlets' | m.proj -od input=- | tr '|' ',' > ./tmp/lonlat.csv
db.in.ogr input=./tmp/lonlat.csv output=lonlat
db.select table=lonlat|head
v.db.join map=outlets column=cat other_table=lonlat other_column=field_3
v.db.update map=outlets column=lon query_column=field_1
v.db.update map=outlets column=lat query_column=field_2
v.db.dropcolumn map=outlets columns=field_1,field_2,field_3
db.select table=outlets | head

# distance from outlet ice or coast
if [[ ${domain} == "ice" ]]; then # processing ice domain.
   # Find which coast basin we're inside of
   ice_domain=$(g.mapset -p)
   land_domain=land_100

   v.db.addcolumn map=outlets column="coast_id int"
   v.what.rast map=outlets type=point raster=basins_filled@${land_domain} column=coast_id

   v.db.addcolumn map=outlets column="coast_lon double"
   v.db.addcolumn map=outlets column="coast_lat double"
   v.db.addcolumn map=outlets column="coast_x int"
   v.db.addcolumn map=outlets column="coast_y int"
  
   g.copy vector=outlets@${land_domain},oland
   db.execute sql='UPDATE outlets SET coast_lon=(SELECT lon from oland WHERE outlets.coast_id=oland.cat)'
   db.execute sql='UPDATE outlets SET coast_lat=(SELECT lat from oland WHERE outlets.coast_id=oland.cat)'
   db.execute sql='UPDATE outlets SET coast_x=(SELECT x from oland WHERE outlets.coast_id=oland.cat)'
   db.execute sql='UPDATE outlets SET coast_y=(SELECT y from oland WHERE outlets.coast_id=oland.cat)'
fi


# Nearest upstream Zwally sector or Mouginot basin/region for each hydro outlet
v.db.addcolumn map=outlets columns="Z2012_sector INT"
v.db.addcolumn map=outlets columns="Z2012_sector_dist INT"
v.distance from=outlets to=sectors@Zwally_2012 upload=to_attr column=Z2012_sector to_column=cat_
v.distance from=outlets to=sectors@Zwally_2012 upload=dist column=Z2012_sector_dist

v.db.addcolumn map=outlets columns="M2019_ID INT"
v.db.addcolumn map=outlets columns="M2019_ID_dist INT"
v.db.addcolumn map=outlets columns="M2019_basin CHAR(99)"
v.db.addcolumn map=outlets columns="M2019_region CHAR(99)"
v.distance from=outlets to=basins@Mouginot_2019 upload=to_attr column=M2019_ID to_column=cat output=connection
v.distance from=outlets to=basins@Mouginot_2019 upload=dist column=M2019_ID_dist
v.distance from=outlets to=basins@Mouginot_2019 upload=to_attr column=M2019_basin to_column=NAME
v.distance from=outlets to=basins@Mouginot_2019 upload=to_attr column=M2019_region to_column=SUBREGION1

# Nearest Mankoff 2020 gate and distance to gate
v.db.addcolumn map=outlets columns="M2020_gate INT"
v.db.addcolumn map=outlets columns="M2020_gate_dist INT"
v.distance from=outlets to=gates@Mankoff_2020 upload=to_attr column=M2020_gate to_column=gate
v.distance from=outlets to=gates@Mankoff_2020 upload=dist column=M2020_gate_dist

# Nearest Bjørk 2015d name and distance to point
v.db.addcolumn map=outlets columns="B2015_name CHAR(99)"
v.db.addcolumn map=outlets columns="B2015_dist INT"
v.distance from=outlets to=names@Bjork_2015 upload=to_attr column=B2015_name to_column=Official_n
v.distance from=outlets to=names@Bjork_2015 upload=dist column=B2015_dist


###
### basins
###
# area of basin
v.to.db map=basins option=area column=area
#+END_SRC

***** Stream Indices
#+NAME: add_stream_indices
#+BEGIN_SRC bash :results verbatim
log_info "r.stream.order: BEGIN"
date
time r.stream.order -m stream_rast=streams direction=dir elevation=head accumulation=ones@PERMANENT stream_vect=stream_vect strahler=strahler horton=horton shreve=shreve hack=hack topo=topological memory=16384
date
log_info "r.stream.order: END"

# g.copy vector=streams,foo --o
# g.copy vector=stream_vect,bar --o

for c in $(echo strahler horton shreve hack drwal_old topo_dim); do
    db.execute sql="ALTER TABLE streams ADD COLUMN ${c} INT"
    db.execute sql="UPDATE streams SET ${c}=(SELECT ${c} from stream_vect WHERE stream_vect.cat=streams.cat)"
done

for c in $(echo stright sinosoid cum_length source_elev outlet_elev); do
    db.execute sql="ALTER TABLE streams ADD COLUMN ${c} double"
    db.execute sql="UPDATE streams SET ${c}=(SELECT ${c} from stream_vect WHERE stream_vect.cat=streams.cat)"
done

# # fix typo: sinosoid -> sinusoid; stright -> straight
db.execute sql="ALTER TABLE streams ADD COLUMN sinusoid DOUBLE"
db.execute sql="UPDATE streams SET sinusoid = sinosoid"
# db.execute sql="ALTER TABLE streams DROP COLUMN sinosoid"
v.db.dropcolumn map=streams columns=sinosoid

db.execute sql="ALTER TABLE streams ADD COLUMN straight DOUBLE"
db.execute sql="UPDATE streams SET straight = stright"
# db.execute sql="ALTER TABLE streams DROP COLUMN stright"
v.db.dropcolumn map=streams columns=stright
#+END_SRC


**** Export

#+NAME: export
#+BEGIN_SRC bash :results verbatim
log_info "Exporting..."

MAPSET=$(g.mapset -p)
mkdir -p freshwater/${MAPSET}

# db.select table=streams | tr '|' ',' > ./freshwater/${MAPSET}/streams.csv
# db.select table=outlets | tr '|' ',' > ./freshwater/${MAPSET}/outlets.csv
# db.select table=basins | tr '|' ',' > ./freshwater/${MAPSET}/basins.csv
parallel --bar "db.select table={} | tr '|' ',' > ./freshwater/${MAPSET}/{}.csv" ::: streams outlets basins

# v.out.ogr input=streams output=./freshwater/${MAPSET}/streams.gpkg --o
# v.out.ogr input=outlets output=./freshwater/${MAPSET}/outlets.gpkg --o
# v.out.ogr input=basins output=./freshwater/${MAPSET}/basins.gpkg --o
parallel --bar "v.out.ogr input={} output=./freshwater/${MAPSET}/{}.gpkg --o" ::: streams outlets basins basins_filled
#+END_SRC



*** Helper functions
**** Data Dir

+ I set =DATADIR= as a =bash= environment variable in my login scripts.
+ This is so that Python babel blocks can also easily get that property.

#+NAME: get_DATADIR
#+BEGIN_SRC jupyter-python
import os
DATADIR = os.environ['DATADIR']
#+END_SRC

#+BEGIN_SRC jupyter-python :tangle no
<<get_DATADIR>>
print(DATADIR)
#+END_SRC

**** init
#+NAME: init
#+BEGIN_SRC bash :results verbatim
set -o nounset
set -o pipefail

# set -o errexit

### uncomment the above line to help find errors. When rerunning and
### counting on GRASS failing w/ overwrite issues (speed increase),
### the line above must be commented

red='\033[0;31m'; orange='\033[0;33m'; green='\033[0;32m'; nc='\033[0m' # No Color
log_info() { echo -e "${green}[$(date --iso-8601=seconds)] [INFO] ${@}${nc}"; }
log_warn() { echo -e "${orange}[$(date --iso-8601=seconds)] [WARN] ${@}${nc}"; }
log_err() { echo -e "${red}[$(date --iso-8601=seconds)] [ERR] ${@}${nc}" >&2; }

trap ctrl_c INT # trap ctrl-c and call ctrl_c()
function ctrl_c() {
  MSG_WARN "Caught CTRL-C"
  MSG_WARN "Killing process"
  kill -term $$ # send this program a terminate signal
}

debug() { if [[ debug:- == 1 ]]; then log_warn "debug:"; echo $@; fi; }

<<GRASS_config>>
#+END_SRC

**** GRASS config

https://grass.osgeo.org/grass74/manuals/variables.html

| GRASS_VERBOSE |                                                                |
|---------------+----------------------------------------------------------------|
|            -1 | complete silence (also errors and warnings are discarded)      |
|             0 | only errors and warnings are printed                           |
|             1 | progress and important messages are printed (percent complete) |
|             2 | all module messages are printed                                |
|             3 | additional verbose messages are printed                        |

#+NAME: GRASS_config
#+BEGIN_SRC bash :results verbatim :tangle no
export GRASS_VERBOSE=3
# export GRASS_MESSAGE_FORMAT=silent

if [ -z ${DATADIR+x} ]; then
    echo "DATADIR environment varible is unset."
    echo "Fix with: \"export DATADIR=/path/to/data\""
    exit 255
fi

set -x # print commands to STDOUT before running them
#+END_SRC

**** x and y and ones in PERMANENT mapset

#+NAME: xy_permanent
#+BEGIN_SRC bash :results verbatim
log_info "x, y, ones..."

MAPSET=$(g.mapset -p)
g.mapset PERMANENT
r.mapcalc "x = x()"
r.mapcalc "y = y()"
r.mapcalc "ones = 1"
g.mapset ${MAPSET}
#+END_SRC

**** COMMENT Map projection distortion

#+BEGIN_SRC bash :results verbatim :tangle distortion.sh
<<init>>
log_info "Calculating distortion"
#+END_SRC

#+NAME: distortion
#+BEGIN_SRC bash :results verbatim :tangle distortion.sh
ORIG_MAPSET=$(g.mapset -p)
MAPSET=distortion
g.mapset -c ${MAPSET}

if [[ $(g.list type=raster pattern=err_2D_area) ]]; then
  log_warn "Distortion already calculated"
else
  g.region res=10000 -ap
  v.mkgrid map=grid position=region type=point

  v.out.ascii grid | m.proj input=- -od | cut -d"|" -f1,2 | tr '|' ' ' > ./tmp/distortion_ll.txt
  PROJSTR=$(g.proj -j | grep -v 'crs')
  echo $PROJSTR
  cat ./tmp/distortion_ll.txt \
    | proj -VS ${PROJSTR} \
    | grep Areal \
    | column -t \
    | sed s/\ \ /,/g \
    | cut -d, -f4 \
       > ./tmp/distortion_err.txt

  time paste -d " " <(m.proj -i input=./tmp/distortion_ll.txt separator=space | cut -d" " -f1,2) ./tmp/distortion_err.txt | r.in.xyz input=- output=err_2D_inv_sparse separator=space

  g.region -d
  r.resamp.interp input=err_2D_inv_sparse output=err_2D_inv method=bilinear
  r.mapcalc "err_2D_area = 1/(err_2D_inv)" # convert to multiplier
  r.mapcalc "err_2D_line = 1/(err_2D_inv^0.5)" # convert area error to linear error

g.mapset ${ORIG_MAPSET}
#+END_SRC


**** Mask small areas

Don't process tiny land islands.

+ This is supposed to remove small islands in the ocean
+ It may also remove very small nunatuks

#+NAME: mask_small_areas
#+BEGIN_SRC bash :results verbatim
# remove islands
# frink "90 m^2 * 10 -> hectares" # 8.1
# frink "1 km^2 -> hectares" # 100

# value is in hectares
if [[ ${domain} == "land" ]]; then
  r.reclass.area -d input=MASK output=MASK_nosmall value=100.1 mode=lesser method=rmarea
  r.mask MASK_nosmall --o
fi

#+END_SRC

**** Absorb small basins & drop their outlets

+ Merge small (< 1 km^2) basins with their largest neighbor.
+ Drop associated outlets too.

#+NAME: absorb_small_basins
#+BEGIN_SRC bash :results verbatim
# absorb small basins and outlets
# frink "1.0 km^2 / ((90 * 90) m^2)" # 123.4567
# frink "1.0 km^2 / ((150 * 150) m^2)" # 45
# frink "1.0 km^2 / ((100 * 100) m^2)# #100

# minsize is in cells
r.clump -d input=basins_uniq output=basins_nosmall minsize=101
r.mode base=basins_nosmall cover=basins_uniq output=basins
r.to.vect -v input=basins output=basins type=area
v.db.dropcolumn map=basins column="label"

v.to.rast input=outlets_uniq output=outlets_uniq use=cat
# r.mapcalc "outlets = if(outlets_streams == basins, basins, null())"
r.mapcalc "outlets = if(outlets_uniq == basins, basins, null())"
r.to.vect -v input=outlets output=outlets type=point
v.db.dropcolumn map=outlets column=label
# db.dropcolumn -f table=outlets column=area
#+END_SRC


**** GRASS launch and mapset selector prologue

+ Launches GRASS if not running.
+ Changes to specified mapset if not already in it.

#+NAME: grass_init_mapset
#+BEGIN_SRC bash :results verbatim :results none
[[ -z ${mapset} ]] && mapset=PERMANENT
if [[ ${GRASS_VERSION:-x} == "x" ]]; then
  [[ -d ./G ]] || grass -e -c EPSG:3413 ./G
  [[ -d ./G/${mapset} ]] || grass -e -c ./G/${mapset}
  grass ./G/${mapset}
else
  [[ ${mapset} == $(g.mapset -p) ]] || g.mapset -c ${mapset} --q
fi
#+END_SRC

Example usage:

#+BEGIN_SRC bash :results verbatim :session grass_ex :var mapset="foo" :eval yes
<<grass_init_mapset>>
echo "MAPSET is: " $(g.mapset -p)
#+END_SRC

#+RESULTS:
: 
: GRASS 7.8.3 (G):~/projects/freshwater > > > > > > > GRASS 7.8.3 (G):~/projects/freshwater > MAPSET is:  foo

**** Remove GRASS PS1 prompt noise from Babel output

#+NAME: GRASS_PS1_clean
#+BEGIN_SRC bash :var data="" :session grass_ex :eval no-export :results verbatim
echo ""
echo ""
echo "${data}" | tr '>' '\n' | grep -v -E "^ ?$" | grep -v "GRASS"
#+END_SRC

#+RESULTS: GRASS_PS1_clean
: 
: 

Example Usage:

#+header: :post GRASS_PS1_clean(data=*this*)
#+header: :session grass_ex
#+header: :var mapset="foo"
#+BEGIN_SRC bash :results verbatim
<<grass_init_mapset>>
g.region -p
#+END_SRC


** Model output routing
*** Area correction for EPSG:3413
:PROPERTIES:
:header-args:bash+: :tangle area_error.sh
:END:

+ This correction needs to be applied to any model data.
+ It is easiest and fastest to generate an area correction raster for each of the two models on their exact grid.
+ To do this, we set up model domains in GRASS, estimate the area correction for each cell, write out a NetCDF file of that raster, and then apply that to each day of the model data.

#+BEGIN_SRC bash :results verbatim :noweb yes
<<init>>
log_info "Area Error..."
#+END_SRC

**** MAR
***** Create MAR mapset

MAR now provided on ISMIP6 grid, meaning the lower left cell center is at (-720000m,-3450000m) with nx=1681 and ny=2881 cells in x and y-direction at full km positions (xmin = -720 km, xmax = +960 km, ymin = -3450 km, ymax = -570 km).

#+BEGIN_SRC bash :results verbatim
log_info "Creating MAR mapset..."

g.mapset -c MAR

g.region w=-720000 e=960000 s=-3450000 n=-570000 res=1000 -pa
g.region w=w-500 e=e+500 n=n+500 s=s-500 res=1000 -p
g.region save=MAR
#+END_SRC

***** 2D area error
:PROPERTIES:
:CUSTOM_ID: code:area_error
:END:

+ EPSG:3413 has projection errors of \(\pm\) ~8% in Greenland
+ Method
  + Email: [[mu4e:msgid:m2tvxmd2xr.fsf@gmail.com][Re: {GRASS-user} scale error for each pixel]]
  + Webmail: https://www.mail-archive.com/grass-user@lists.osgeo.org/msg35005.html

#+NAME: area_error
#+BEGIN_SRC bash :results verbatim :tangle no
MAPSET=$(g.mapset -p)
log_info "2D Area Error for ${MAPSET}"

v.mkgrid map=grid position=region type=point

v.out.ascii grid | m.proj input=- -od | cut -d"|" -f1,2 | tr '|' ' ' > ./tmp/distortion_ll_${MAPSET}.txt
PROJSTR=$(g.proj -j | grep -v 'crs')
echo $PROJSTR
cat ./tmp/distortion_ll_${MAPSET}.txt \
  | proj -VS ${PROJSTR} \
  | grep Areal \
  | column -t \
  | sed s/\ \ /,/g \
  | cut -d, -f4 \
    > ./tmp/distortion_err_${MAPSET}.txt

paste -d " " <(m.proj -i input=./tmp/distortion_ll_${MAPSET}.txt separator=space | cut -d" " -f1,2) ./tmp/distortion_err_${MAPSET}.txt | r.in.xyz input=- output=err_2D_inv separator=space

r.mapcalc "err_2D_area = 1/(err_2D_inv)" # convert to multiplier
r.mapcalc "err_2D_line = 1/(err_2D_inv^0.5)" # convert area error to linear error
r.out.gdal --o -c -m input=err_2D_area output=./tmp/err_2D_area_${MAPSET}.nc type=Float32 format=netCDF 
#+END_SRC

#+BEGIN_SRC bash :results verbatim
if [[ "" == $(g.list type=raster pattern=err_2D_area mapset=.) ]]; then
  <<area_error>>
fi
#+END_SRC

**** RACMO
***** Create RACMO mapset
#+BEGIN_SRC bash :results verbatim
log_info "Creating RACMO mapset..."

g.mapset -c RACMO
FILE=${DATADIR}/RACMO/freshwater/Icemask_Topo_Iceclasses_lon_lat_average_1km.nc 
cdo -sinfo ${FILE}
x0=$(ncdump -v x ${FILE} | grep "^ x =" | cut -d" " -f4 | cut -d, -f1)
x1=$(ncdump -v x ${FILE} | tail -n2 | head -n1 | tr ',' '\n' | tail -n1 | cut -d" " -f2)
y0=$(ncdump -v y ${FILE} | grep "^ y =" | cut -d" " -f4 | cut -d, -f1)
y1=$(ncdump -v y ${FILE} | tail -n2 | head -n1 | tr ',' '\n' | tail -n1 | cut -d" " -f2)
g.region w=$x0 e=$x1 s=$y0 n=$y1 res=1000 -p
g.region s=s-500 n=n+500 e=e+500 w=w-500 -p
g.region save=RACMO
#+END_SRC

***** 2D area error
See: [[#code:area_error][2D Area Error]]

#+BEGIN_SRC bash :results verbatim
if [[ "" == $(g.list type=raster pattern=err_2D_area mapset=.) ]]; then
  <<area_error>>
fi
#+END_SRC



*** RCM preprocessing
:PROPERTIES:
:header-args:jupyter-python+: :tangle rcm_preprocess.py
:header-args:jupyter-python+: :shebang #!/usr/bin/env python
:END:

At this point the static work is done - we have basins, streams, and outlets for all of GIS. 

The remaining tasks are to SUM the daily model variables by each basin, and assign results to the outlet for each basin.

Working with the provided NetCDF files directly is possible but accessing them is very slow (in GRASS). I believe this has to do with extracting one variable from a multi-variable file, and/or chunking and compression issues. Given that the code operates day-by-day, that means from 1940 through December 2024 there are src_bash{echo $(( ($(date -d 2024-12-31 +%s) - $(date -d 1940-01-01 +%s)) / 86400 ))} {{{results(=31046=)}}} days, if I can cut access time down by 1 second that save 6.3 hours. In reality, by pre-processing the NetCDF files access time is reduced from 10 seconds to 1 second, saving ~2.5 days of processing time (cutting processing time in half). The cost for this savings is a few dozen lines of code and a few hours of processing.

+ MAR: One RUNOFF variable that contains appropriate runoff for both ice and land
+ RACMO: One RUNOFF variable that contains appropriate runoff for both ice and land

**** Init

#+BEGIN_SRC jupyter-python
import xarray as xr
import numpy as np
import os
import glob
from tqdm import tqdm
from dask.diagnostics import ProgressBar

<<get_DATADIR>>
#+END_SRC


**** MAR notes

From Xavier:

#+BEGIN_QUOTE
RU(CORR) = the (sub grid topography corrected) runoff over the permanent ice part of a pixel. In your case, I suggest you to use RUcorr instead of RU.

RU2 = runoff over the tundra part of a pixel (land runoff).

SF/RF are provided everywhere.

MSK_GIMP = land/sea/ice mask.

Over land you can use RUcorr and RU2 in fct of MSK_GIMP
Over sea, you can use RF+SF
#+END_QUOTE

**** Extract MAR vars
:PROPERTIES:
:ID:       d698cc04-c4d7-4812-a274-fca1a83ee0eb
:END:

+ Use =xarray= citep:hoyer_2017 and =dask= citep:DASK so that we can efficiently process the ~330 GB of data (much larger than RAM).
+ Adjust =chunks= for your RAM. With 32 GB RAM, =time:30= works, and =time:92= crashes.

#+BEGIN_SRC jupyter-python :session MAR :exports both :results raw drawer
area = xr.open_dataset("./tmp/err_2D_area_MAR.nc")

ROOT=DATADIR+"/MAR/3.14-daily-1km"

filelist = np.sort(glob.glob(ROOT+"/MARv3.14-daily-ERA5-????.nc"))
years = [_.split("-")[-1].split(".")[0] for _ in filelist]
for y in years:
    outfile = "./tmp/MAR_runoff_ice_" + y + ".nc"
    if os.path.exists(outfile):
        continue

    infile = ROOT+"/MARv3.14-daily-ERA5-" + y + ".nc"
    print("infile: ", infile, "outfile: ", outfile)
    ds = xr.open_mfdataset(infile, combine='by_coords')
    ds['RUcorr'] = ds['RUcorr'].where((ds['RUcorr'] >= ds['RUcorr'].attrs['actual_range'][0]) &
                                      (ds['RUcorr'] <= ds['RUcorr'].attrs['actual_range'][1]))
    da = (ds['RUcorr'] * (ds['MSK'] >= 2) * area['Band1'].values)   # runoff over ice
    da.variable.attrs = {'units':'mmWE/day','long_name':'Water runoff','standard_name':'Water runoff'}
    ds_sub = da.to_dataset(name='runoff')
    delayed_obj = ds_sub.to_netcdf(outfile, compute=False)
    with ProgressBar(): results = delayed_obj.compute() # takes a few min...
    del(ds); del(da); del(ds_sub); del(delayed_obj)    

for y in years:
    outfile = "./tmp/MAR_runoff_land_" + y + ".nc"
    if os.path.exists(outfile):
        continue

    infile = ROOT+"/MARv3.14-daily-ERA5-" + y + ".nc"
    print("infile: ", infile, "outfile: ", outfile)
    ds = xr.open_mfdataset(infile, combine='by_coords')
    ds['RU2'] = ds['RU2'].where((ds['RU2'] >= ds['RU2'].attrs['actual_range'][0]) &
                                (ds['RU2'] <= ds['RU2'].attrs['actual_range'][1]))
    da = ds['RU2'] * (ds['MSK'] == 1) * area['Band1'].values       # runoff over land
    da.variable.attrs = {'units':'mmWE/day','long_name':'Water runoff','standard_name':'Water runoff'}
    ds_sub = da.to_dataset(name='runoff')
    delayed_obj = ds_sub.to_netcdf(outfile, compute=False)
    with ProgressBar(): results = delayed_obj.compute()
    del(ds); del(da); del(ds_sub); del(delayed_obj)    

#+END_SRC


***** FAIL Test

+ Sum land runoff for one year
+ Sum ice runoff for one year
+ There should be no overlap (and no gaps at the boundaries)

#+BEGIN_SRC bash :results verbatim :tangle no
grass -c ./G/tmp/

g.region MAR@MAR

export GRASS_OVERWRITE=1

d.mon start=wx0
d.erase

### MAR ice
seq=$(seq 365)
parallel --bar 'r.external -o source="netCDF:./tmp/MAR_runoff_ice_2000.nc:runoff" output=ice.{} band={}' ::: ${seq}
parallel --bar 'r.region -c map=ice.{} --q' ::: ${seq}
r.series input=$(g.list type=raster pattern=ice.* separator=,) output=ice method=maximum
r.mapcalc "ice0 = if(ice == 0, null(), ice)"
r.colors -a map=ice0 color=blues

### MAR land
parallel --bar 'r.external -o source="netCDF:./tmp/MAR_runoff_land_2000.nc:runoff" output=land.{} band={}' ::: ${seq}
parallel --bar 'r.region -c map=land.{} --q' ::: ${seq}
r.series input=$(g.list type=raster pattern=land.* separator=,) output=land method=maximum
r.mapcalc "land0 = if(land == 0, null(), land)"
r.colors -a map=land0 color=green

r.mapcalc "test = if(ice0) + if(land0)"
r.info test # should be min=NULL max=NULL showing no overlap. What about gaps?

r.mapcalc "test = if(isnull(ice0), 0, 1) + if(isnull(land0), 0, 2)"
# min = 0, max = 2

#+END_SRC

TODO: Problem: There appears to be no land runoff.

**** RACMO notes

Brice email: [[mu4e:msgid:48FFD1A0-A010-4BBD-84DE-63CD9F7EF67B@uu.nl][Re: All freshwater]]

#+BEGIN_QUOTE
The data consist of:

1 km: ice covered regions

- Daily total precipitation (rain + snow) and runoff in mm w.e. or
  kg/m2 per day covering the whole GrIS and peripheral ice caps (GICS)
  for the year 1979-2017.

- Mask file including: lon/lat, PROMICE mask (3 = GrIS, 1 and 2 =
  GICs) and topography from the GIMP DEM upscaled to 1 km.

The data are statistically downscaled from the output of RACMO2.3p2 (5.5 km) to 1 km resolution.

The projection used is Polar Stereographic North (EPSG:3413) and the resolution is exactly 1 km x 1 km.

5.5 km: tundra region

- Daily runoff and evaporation in mm w.e. or kg/m2 per day at 5.5 km
  for 1979-2017.

Use of the data:

Note that in RACMO2 a positive subl means condensation while negative
subl actually means sublimation.
#+END_QUOTE


**** Extract RACMO vars

***** Ice runoff

+ This data set provided in its current from by Brice.
+ 1 km gridded land runoff on EPSG:3413 grid

#+BEGIN_SRC jupyter-python :session RACMO :exports both :results raw drawer

area = xr.open_dataset("./tmp/err_2D_area_RACMO.nc")

ROOT=DATADIR+"/RACMO/freshwater"

msk = xr.open_dataset(ROOT+"/Icemask_Topo_Iceclasses_lon_lat_average_1km.nc")
msk['landmask'] = (msk['Promicemask'] == 0) & (msk['Topography'] != 0)

filelist = np.sort(glob.glob(ROOT+"/runoff_ice_1km/runoff*.nc"))
years = np.unique([_.split(".")[1].split("_")[0] for _ in filelist])
for i,y in enumerate(tqdm(years)):
    outfile = "./tmp/RACMO_runoff_ice_" + y + ".nc"
    if os.path.exists(outfile):
        continue

    filelist_year = [_ for _ in filelist if str(y) in _]
    print("infile: ", filelist_year, "outfile: ", outfile)
    ds = xr.open_mfdataset(filelist_year, combine='by_coords')
    
    da = (ds['runoffcorr'] * (msk['Promicemask'] != 0) * area['Band1'].values) # ice runoff
    da.variable.attrs = {'units':'mm w.e. per day',
                         'long_name':'Downscaled corrected snowmelt',
                         'standard_name':'Downscaled_corrected_snowmelt'}
    ds_sub = da.to_dataset(name='runoff')
    delayed_obj = ds_sub.to_netcdf(outfile, compute=False,
                                   format="NETCDF4", engine="netcdf4")
    with ProgressBar(): results = delayed_obj.compute()
    del(ds); del(da); del(ds_sub); del(delayed_obj)    

#+END_SRC

***** Land runoff

+ This data set provided at 5.5 km on a rotated pole grid
+ Code to regrid onto 1 km EPSG:3413 was also provided.
  + See =${DATADIR}/RACMO/freshwater/runoff_land_1km_regrid/= folder for details

#+BEGIN_SRC jupyter-python :session RACMO :exports both :results raw drawer

area = xr.open_dataset("./tmp/err_2D_area_RACMO.nc")

ROOT=DATADIR+"/RACMO/freshwater"
ROOT_REGRID = ROOT + "/runoff_land_1km_regrid"
msk = xr.open_dataset(ROOT_REGRID+"/Tundra_Mask_1km.nc")

filelist = np.sort(glob.glob(ROOT_REGRID + "/out/runoff*.nc"))
years = np.unique([_.split(".")[1] for _ in filelist])
for i,y in enumerate(tqdm(years)):
    outfile = "./tmp/RACMO_runoff_land_" + y + ".nc"
    if os.path.exists(outfile):
        continue

    print("infile: ", filelist[i], "outfile: ", outfile)
    ds = xr.open_mfdataset(filelist[i], combine='by_coords')
    ds = ds.drop_vars(['lon','lat'])
    ds = ds.squeeze() # drop height=1
    
    da = ds['runoff'] * msk['Tundra'].values * area['Band1'].values    # runoff over land
    da.variable.attrs = {'units':'mm w.e. per day',
                         'long_name':'Downscaled corrected snowmelt',
                         'standard_name':'Downscaled_corrected_snowmelt'}
    ds_sub = da.to_dataset(name='runoff')

    # RACMO land has time pegged to 'days since 1950-01-01'. Adjust to days-since <this_year> for each file.
    this_year = ds['time'].dt.year.values[0]
    ds_sub['time'].encoding['units'] = f'days since {this_year}-01-01'

    delayed_obj = ds_sub.to_netcdf(outfile, compute=False,
                                   encoding={'runoff':{'dtype':'float32'}},
                                   format="NETCDF4", engine="netcdf4")
    with ProgressBar(): results = delayed_obj.compute()
    del(ds); del(da); del(ds_sub); del(delayed_obj)

#+END_SRC

***** Test
:PROPERTIES:
:header-args:jupyter-python+: :tangle no
:END:

****** SUCCESS Ice and land should not overlap

Domains should be independent.

#+BEGIN_SRC bash :results verbatim :tangle no
grass -c ./G/tmp/

g.region RACMO@RACMO

export GRASS_OVERWRITE=1

d.mon start=wx0
d.erase

### RACMO ice
seq=$(seq 365)
parallel --bar 'r.external -o source="netCDF:./tmp/RACMO_runoff_ice_2000.nc:runoff" output=ice.{} band={}' ::: ${seq}
parallel --bar 'r.region -c map=ice.{} --q' ::: ${seq}
r.series input=$(g.list type=raster pattern=ice.* separator=,) output=ice method=maximum
r.mapcalc "ice0 = if(ice == 0, null(), ice)"
r.colors -a map=ice0 color=blues

### RACMO land
parallel --bar 'r.external -o source="netCDF:./tmp/RACMO_runoff_land_2000.nc:runoff" output=land.{} band={}' ::: ${seq}
parallel --bar 'r.region -c map=land.{} --q' ::: ${seq}
r.series input=$(g.list type=raster pattern=land.* separator=,) output=land method=maximum
r.mapcalc "land0 = if(land == 0, null(), land)"
r.colors -a map=land0 color=green

r.mapcalc "test = if(ice0) + if(land0)"
r.info test # should be min=NULL max=NULL showing no overlap. 

r.mapcalc "test = if(isnull(ice0), 0, 1) + if(isnull(land0), 0, 2)" # What about gaps?
r.info test
# min = 0, max = 2
d.rast test
d.legend test
#+END_SRC

****** SUCCESS Ice runoff should not bleed into land

+ Not an issue when the RCM provides two different domains and a mask (MAR)
+ May be an issue when RCM results are interpolated onto a grid from elsewhere (RACMO)

#+BEGIN_SRC jupyter-python :session RACMO :exports both :results raw drawer
import xarray as xr
import numpy as np
import glob
import os

area = xr.open_dataset("./tmp/err_2D_area_RACMO.nc")

DATADIR='/home/kdm/data'
ROOT=DATADIR+"/RACMO/freshwater"

### ICE

msk = xr.open_dataset(ROOT+"/Icemask_Topo_Iceclasses_lon_lat_average_1km.nc")
msk['landmask'] = (msk['Promicemask'] == 0) & (msk['Topography'] != 0)

filelist = np.sort(glob.glob(ROOT+"1km/runoff*.nc"))
years = np.unique([_.split(".")[1].split("_")[0] for _ in filelist])
i = 42
y = '2000'

filelist_year = [_ for _ in filelist if str(y) in _]
ds = xr.open_mfdataset(filelist_year, combine='by_coords')
    
imshow(ds['runoffcorr'][200,:,:], origin='lower')

### LAND

ROOT_REGRID = ROOT + "/regrid_5.5-to-1km"
msk = xr.open_dataset(ROOT_REGRID+"/Tundra_Mask_1km.nc")

filelist = np.sort(glob.glob(ROOT_REGRID + "/out/runoff*.nc"))
years = np.unique([_.split(".")[2].split(".")[0] for _ in filelist])
i = 3
y = '2000'

ds = xr.open_mfdataset(filelist[i], combine='by_coords')

imshow(msk['Tundra'], origin='lower')
land_runoff = ds.squeeze()['runoff'].max(axis=0).compute()
imshow(land_runoff, origin='lower')
imshow(land_runoff *  msk['Tundra'], origin='lower') # appears that ice runoff "bleeds" into land runoff.
    
#+END_SRC


**** TODO Inputs equal outputs?                               :QC:
+ I expect not - the difference should be due to the area scaling

**** Create test files - one year of MAR and RACMO data       :QC:
#+BEGIN_SRC bash :results verbatim
cdo -v selyear,2000 ./tmp/MAR_runoff_ice.nc ./tmp/MAR_Y2K_tmp.nc
cdo -v yearsum ./tmp/MAR_Y2K_tmp.nc ./tmp/MAR_Y2K.nc

cdo -v selyear,2000 ./tmp/MAR_runoff_land.nc ./tmp/MAR_Y2K_tmp.nc
cdo -v yearsum ./tmp/MAR_Y2K_tmp.nc ./tmp/MAR_Y2K_land.nc

cdo -v selyear,2000 ./tmp/RACMO_runoff_ice.nc ./tmp/RACMO_Y2K_tmp.nc
cdo -v yearsum ./tmp/RACMO_Y2K_tmp.nc ./tmp/RACMO_Y2K.nc

rm ./tmp/{MAR,RACMO}_Y2K_tmp.nc
#+END_SRC

*** Freshwater flow rates from RCMs
:PROPERTIES:
:header-args:bash+: :tangle rcm.sh
:END:

#+BEGIN_SRC bash :results verbatim
<<init>>
#+END_SRC

**** Output info table


Have:
| product | loc        | k         | RCM   | DEM       | variable   |
|---------+------------+-----------+-------+-----------+------------|
| runoff  | ice margin | 80,90,100 | MAR   | ArcticDEM | RUcorr     |
| runoff  | ice margin | 80,90,100 | RACMO | ArcticDEM | runoffcorr |
| runoff  | land coast | 100       | MAR   | ArcticDEM | RUcorr     |
| runoff  | land coast | 100       | RACMO | ArcticDEM | runoffcorr |

Can expand to include:
+ [ ] product :: More products (e.g. precip, condensation, etc.)
+ [ ] location :: Add Fjord Surface. Improve linking ice margin to coast
+ [ ] RCM :: More RCMs? More times (future simulations?) Near-realtime Wx forecast?
+ [ ] DEM :: Multiple DEMs? Higher res ArcticDEM?
+ [X] Other :: Multiple DEM routing schemes (subglacial)

**** SETUP algorithm and prepare data
:PROPERTIES:
:ID:       965c95de-6551-4925-9771-7146ce69d968
:END:

+ The algorithm is designed to capture model data that is over basin ice.
+ This works without extra effort when operating in the ice domain routed to the ice edge, because data outside the domain is masked.
+ However, when working over the ice domain routed to the coast, this includes the land domain. Now 1 km^2 model grid cells that only partially cover an ice basin are included in their entirety.
+ From this, ice runoff routed to the ice edge is not equal to ice runoff routed over land to the coast, but the two should be equal.
+ Therefore, I build a basin mask here
+ Later, we'll apply the smallest version of AND(basin_mask, model_mask) limiting to the smallest ice subset.

#+BEGIN_SRC bash :results verbatim
log_info "Initializing MAR mapset..."

g.mapset MAR

g.region -d # default region, or raster=basins_merged@coast
r.mapcalc "mask_ice_basin = if(basins@ice_100, 1, null())"
r.mapcalc "mask_land_basin = if(not(isnull(basins@land_100)) & isnull(mask_ice_basin), 1, null())"
r.mapcalc "mask_ice_land_basin = if(not(isnull(basins_filled@land_100)), 1, null())"

g.region MAR@MAR -p
r.in.gdal -o input="NetCDF:${DATADIR}/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2000.nc:MSK" output=MSK
r.region map=MSK region=MAR@MAR
r.mapcalc "mask_ice_MAR = if((MSK >= 2) & mask_ice_land_basin, 1, null())"
r.mapcalc "mask_land_MAR = if((MSK == 1) & mask_ice_land_basin, 1, null())"
g.region -d
#+END_SRC

Below is...
+ NON PARALLEL
+ not tangled
+ Run for 5 days
+ Run parallelized version for 5 days
+ Check outputs are the same

Timing Test:
#+BEGIN_SRC bash :results verbatim :tangle no

r.mapcalc "model = 1" # One synthetic day
r.region map=model region=MAR@MAR --q

r.mask -r 
time r.univar -t map=model zones=basins@ice_100 > /dev/null # 10-15 sec
#+END_SRC

# Does the mask change results?
# #+BEGIN_SRC bash :results verbatim :tangle no
# r.external -o source="netCDF:./tmp/MAR_Y2K.nc:runoff" output=model band=1 --o --q
# r.region map=model region=MAR@MAR --q

# r.mask -r
# time r.univar map=model zones=basins@ice_surf > ./tmp/r.univar.nomask
# r.mask mask_ice_basin --o
# time r.univar map=model2 zones=basins@ice_surf > ./tmp/r.univar.mask
# diff ./tmp/r.univar.nomask ./tmp/r.univar.mask
# #+END_SRC

# No it does not. Presumably because the mask matches the zones file. It might make a difference for the land data?

# #+BEGIN_SRC bash :results verbatim :tangle no
# r.external -o source="netCDF:./tmp/MAR_Y2K_land.nc:runoff" output=model band=1 --o --q
# r.region map=model region=MAR@MAR --q

# r.mask -r
# time r.univar map=model zones=basins@ice_surf > ./tmp/r.univar.nomask
# r.mask mask_land_basin --o
# time r.univar map=model2 zones=basins@ice_surf > ./tmp/r.univar.mask
# diff ./tmp/r.univar.nomask ./tmp/r.univar.mask
# #+END_SRC

# Yes, here it does, because without the mask all the land cells over ice are included, but we only want the land cells over land.

#+BEGIN_SRC bash :results verbatim :tangle no
### LOOP VERSION (~11 seconds per day)

rm ./tmp/MAR_ice_runoff.noparallel.bsv
rm ./tmp/MAR_ice_runoff.bsv

for t in $(seq 0 4); do
  date
  tt=$(( $t + 1 )) # T0 is 0-based. r.external is 1-based
  DATESTR=$(date -d"2000-01-01+${t} days" +"%Y-%m-%d")
  r.external -o source="netCDF:./tmp/MAR_runoff_ice_2000.nc:runoff" output=model band=${tt} --o --q
  r.region map=model region=MAR@MAR --q
  r.univar -t map=model zones=basins@ice_100 --q | cut -d"|" -f13 | datamash -t"|" transpose | sed s/^sum/${DATESTR}/ >> ./tmp/MAR_ice_runoff.noparallel.bsv
done
#+END_SRC

Implement above code but in parallel
#+BEGIN_SRC bash :results verbatim
function basin_partition() {
    JOB="$1"         # 0 to ndays-1
    SLOT="$2"        # 0 to ncpus-1
    ZONES="$3"       # basins@land_100, basins@ice_80, etc.
    RCMfilevar=$4    # MAR_runoff_ice_2000.nc:runoff
    REGION=$5        # MAR@MAR
    
    RCMfile=${RCMfilevar/:*/}  # <RCM>_runoff_<domain>_<k>.nc

    r.external -o source="netCDF:tmp/${RCMfilevar}" output=model_${SLOT} band=${JOB} --o --q 2>/dev/null
    r.region map=model_${SLOT} region=${REGION} --q
    DATESTR0=$(ncdump -h tmp/${RCMfile} |grep time:units)
    DATESTR0=${DATESTR0: 27:10}
    DATESTR=$(date -d"${DATESTR0}+$(( ${JOB}-1 )) days" +"%Y-%m-%d")
    r.univar -t map=model_${SLOT} zones=${ZONES} --q 2>/dev/null | cut -d"|" -f13 | datamash -t"|" transpose | sed s/^sum/${DATESTR}/
}
export -f basin_partition

#+END_SRC

DEBUG: Proc 1 day and make sure its same as NON PARALLEL
#+BEGIN_SRC bash :results verbatim :tangle no

seq 5 | parallel --keep-order --bar basin_partition {#} {%} basins@ice_100 "MAR_runoff_ice_1980.nc:runoff" MAR@MAR >> ./tmp/MAR_ice_runoff.bsv # DEBUG

diff -q ./tmp/MAR_ice_runoff.bsv ./tmp/MAR_ice_runoff.noparallel.bsv
head -n1 ./tmp/MAR_ice_runoff.bsv | tr '|' '\n' | wc
tail -n1 ./tmp/MAR_ice_runoff.bsv | tr '|' '\n' | wc
#+END_SRC

We want to calculate
+ ice runoff to ice margin
+ land runoff to coast

All separately. Therefore, easiest to build the ZONES file for r.univar to cover only what we want.

Set up header
#+BEGIN_SRC bash :results verbatim
log_info "Building BSV headers"

# r.external -o source="netCDF:./tmp/MAR_runoff_ice.nc:runoff" output=model band=1 --o --q # load in a sample day
# r.region map=model region=MAR@MAR

r.mapcalc "model = 1" --o # dummy data to build headers
for k_pct in 100 90 80; do
  r.univar -t map=model zones=basins@ice_${k_pct} \
    | sed s/^zone/cat/ \
    | cut -d"|" -f1 \
    | datamash -t"|" transpose \
	       > ./tmp/header_ice_${k_pct}.bsv
done

# land only 100
k_pct=100
r.univar -t map=model zones=basins@land_${k_pct} \
  | sed s/^zone/cat/ \
  | cut -d"|" -f1 \
  | datamash -t"|" transpose \
	     > ./tmp/header_land_${k_pct}.bsv

#+END_SRC

**** MAR ice runoff at ice outlets
:PROPERTIES:
:ID:       20200522T103441.553744
:END:

#+BEGIN_SRC bash :results verbatim

log_info "Using EXTRA GNU parallel options via \${PARALLEL}: ${PARALLEL:-Not set}"

k_pct=100
for y in $(seq 1940 2025); do
  file_base=MAR_runoff_ice_${y}
  infile=${file_base}.nc
  outfile=${file_base}_${k_pct}.bsv

  log_info "Calculating MAR ice runoff at ice outlets: ${outfile}"

  if [[ -e ./dat/${outfile} ]]; then
    log_warn "Output file ${outfile} exists. Skipping..."
  else
    cp ./tmp/header_ice_${k_pct}.bsv ./dat/${outfile}

    T1=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | rev | cut -d, -f1 | rev)
    seq 0 ${T1} \
      | parallel --nice 9 --keep-order --bar basin_partition {#} {%} basins@ice_${k_pct} "${infile}:runoff" MAR@MAR \
		 >> ./dat/${outfile}
  fi
done
#+END_SRC

****** QC: Do outputs match inputs?

I expect outputs to be less than inputs because not every model ice cell is fully sampled, because not every model ice cell has an ice basin under it. Model ice cells over land are not counted.

#+name: MAR_preprocess_in_out_compare 
#+BEGIN_SRC jupyter-python :session QC :exports both :results raw drawer :tangle no :eval no
import pandas as pd
import xarray as xr
import numpy as np

<<get_DATADIR>>
mask = xr.open_dataset(DATADIR+"/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2000.nc")['MSK']

# First day match?   # convert mm/grid cell to m^3
o = pd.read_csv('./dat/runoff_ice2margin_MAR.bsv', sep="|", index_col=0, nrows=1) * 1E-3 * 100 * 100

# first year of input
i = xr.open_dataset('./dat/MAR_runoff_ice.nc').isel(time=0)['runoff'] * 1E-3 * 1000 * 1000 * (mask >= 2)

osum = o.sum().sum()
isum = i.sum().values
print(isum, osum)
print(isum/osum)

# check for first year
o = pd.read_csv('./dat/runoff_ice2margin_MAR.bsv', sep="|", index_col=0, nrows=366) * 1E-3 * 100 * 100
i = xr.open_dataset('./dat/MAR_runoff_ice.nc').isel(time=np.arange(366))['runoff'] * 1E-3 * 1000 * 1000 * (mask >= 2)
osum = o.sum().sum()
isum = i.sum().values
print(isum, osum)
print(isum/osum)
#+END_SRC

#+RESULTS: MAR_preprocess_in_out_compare

+ Inputs are ~4 % larger than outputs over the first year
  + Due to EPSG:3413 scaling?
  + Due to Arctic Canada in this mask?

**** MAR land runoff at coast outlets

#+BEGIN_SRC bash :results verbatim

log_info "Using EXTRA GNU parallel options via \${PARALLEL}: ${PARALLEL:-Not set}"

k_pct=100
for y in $(seq 1940 2025); do
  file_base=MAR_runoff_land_${y}
  infile=${file_base}.nc
  outfile=${file_base}_${k_pct}.bsv

  log_info "Calculating MAR land runoff at land outlets: ${outfile}"

  if [[ -e ./dat/${outfile} ]]; then
    log_warn "Output file ${outfile} exists. Skipping..."
  else
    cp ./tmp/header_land_${k_pct}.bsv ./dat/${outfile}
    
    T1=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | rev | cut -d, -f1 | rev)
    seq 0 ${T1} \
      | parallel --nice 9 --keep-order --bar basin_partition {#} {%} basins@land_${k_pct} "${infile}:runoff" MAR@MAR \
		 >> ./dat/${outfile}
  fi
done
#+END_SRC

**** RACMO (same as MAR)
***** Prepare data
#+BEGIN_SRC bash :results verbatim

g.mapset -c RACMO

g.region -d
r.mapcalc "mask_ice_basin = if(basins@ice_100, 1, null())"
r.mapcalc "mask_land_basin = if(not(isnull(basins@land_100)) & isnull(mask_ice_basin), 1, null())"
r.mapcalc "mask_ice_land_basin = if(not(isnull(basins_filled@land_100)), 1, null())"

g.region RACMO@RACMO -p
FILE=${DATADIR}/RACMO/freshwater/Icemask_Topo_Iceclasses_lon_lat_average_1km.nc 
r.in.gdal -o input="NetCDF:${FILE}:Promicemask" output=mask_ice
r.region map=mask_ice region=RACMO@RACMO
r.mapcalc "mask_ice_RACMO = if((mask_ice != 0) & mask_ice_land_basin, 1, null())"
r.mapcalc "mask_land_RACMO = if((mask_ice == 0) & mask_ice_land_basin, 1, null())"
g.region -d

r.mapcalc "model = 1" # One synthetic day
r.region map=model region=RACMO@RACMO

#+END_SRC

***** Partition RCMs across basins
#+BEGIN_SRC bash :results verbatim
g.mapset RACMO

log_info "Using EXTRA GNU parallel options via \${PARALLEL}: ${PARALLEL:-Not set}"

# ice
k_pct=100
for y in $(seq 1958 2024); do
  file_base=RACMO_runoff_ice_${y}
  infile=${file_base}.nc
  outfile=${file_base}_${k_pct}.bsv

  log_info "Calculating RACMO ice runoff at ice outlets: ${outfile}"

  if [[ -e ./dat/${outfile} ]]; then
    log_warn "Output file ${outfile} exists. Skipping..."
  else
    cp ./tmp/header_ice_${k_pct}.bsv ./dat/${outfile}

    T0=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | cut -d, -f1)
    T1=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | rev | cut -d, -f1 | rev)
    seq ${T0} ${T1} \
      | parallel --nice 9 --keep-order --bar basin_partition {#} {%} basins@ice_${k_pct} "${infile}:runoff" RACMO@RACMO \
                 >> ./dat/${outfile}
  fi
done

# land
k_pct=100
for y in $(seq 1958 2024); do
  file_base=RACMO_runoff_land_${y}
  infile=${file_base}.nc
  outfile=${file_base}_${k_pct}.bsv
  
  log_info "Calculating RACMO land runoff at land outlets: ${outfile}"
  
  if [[ -e ./dat/${outfile} ]]; then
    log_warn "Output file ${outfile} exists. Skipping..."
  else
    cp ./tmp/header_land_${k_pct}.bsv ./dat/${outfile}
    
    T0=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | cut -d, -f1)
    T1=$(ncdump -v time ./tmp/${infile} | grep -A 100000 "^ time =" | tr -dc [0-9,] | rev | cut -d, -f1 | rev)
    seq ${T0} ${T1} \
      | parallel --nice 9 --keep-order --bar basin_partition {#} {%} basins@land_${k_pct} "${infile}:runoff" RACMO@RACMO \
                 >> ./dat/${outfile}
  fi
done

#+END_SRC

**** NOTDONE Precipitation (rain+snow) at fjord surface
#+BEGIN_SRC bash :results verbatim :tangle no
grass -c ./G/fjords
g.region -d res=1000 -a -p
r.mask -r

d.mon start=wx0
d.erase
d.rast shade
d.rast land_shade

# fill everything (Disko bay, Geiki, fjords, etc.)
r.grow -m input=head@coast output=grow radius=50000 old=-1 new=1 --o

# shrink back to just the coastal region
r.grow -m input=grow output=shrink radius=-44000 --o

r.null map=shrink setnull=-1

# fill in cells that are part land/coast
# but might have land at the center at 30 m res
r.grow -m input=shrink output=buffer_coast radius=1001 new=1 --o

d.erase
d.rast shade
d.rast buffer_coast

# for display purposes?
r.to.vect input=buffer_coast output=buffer_coast type=point

# then, r.out.xyz for the model data using buffer_coast as a mask. 
# This should produce "x,y,val" for each time step
#+END_SRC
**** Testing

#+BEGIN_SRC bash :results verbatim :tangle no
grass -c ./G/tmp/

export GRASS_OVERWRITE=1

d.mon start=wx0
d.erase

### ICE

d.rast basins@ice_80
# OR
r.to.vect input=basins@ice_80 output=zones type=area
d.vect zones fill_color=none color=red

### MAR

band=250
r.external -o source="netCDF:./tmp/MAR_runoff_ice_2000.nc:runoff" output=map band=${band} 
r.region map=map region=MAR@MAR --q
r.colors -a map=map color=viridis
d.rast map
d.vect zones fill_color=none color=red

### RACMO

band=200
r.external -o source="netCDF:./tmp/RACMO_runoff_ice_1958.nc:runoff" output=map band=${band} 
r.region map=map region=MAR@MAR --q
r.colors -a map=map color=viridis
d.rast map

### LAND

# r.to.vect input=basins@land_100 output=zones type=area
# d.vect zones fill_color=none color=red
d.rast basins@land_100

# MAR

band=220
r.external -o source="netCDF:./tmp/MAR_runoff_land_1999.nc:runoff" output=map band=${band} 
r.region map=map region=MAR@MAR --q
r.colors -a map=map color=viridis
d.rast map

# RACMO

band=220
r.external -o source="netCDF:./tmp/RACMO_runoff_land_1999.nc:runoff" output=map band=${band} 
r.region map=map region=MAR@MAR --q
r.colors -a map=map color=viridis
d.rast map



# r.to.vect input=map_${band} output=map_${band} type=area
# d.vect map_${band} fill_color=none color=blue


#+END_SRC
*** Calculate and prepare coverage
:PROPERTIES:
:header-args:bash+: :tangle coverage_calc.sh
:END:

**** Calculate
#+BEGIN_SRC bash :results verbatim
<<init>>
#+END_SRC

See [ [[#supplemental:coverage][Coverage]] ]

+ How much of each ice basin is (1) (is not (*)) covered by model ice cells.

#+BEGIN_SRC bash :results verbatim
for k in 80 90 100; do
  mapset=ice_${k}
  g.mapset ${mapset}

  r.mask -r
  r.stats --q -aN input=basins@${mapset},mask_ice_MAR@MAR separator=,  \
	  > ./tmp/coverage_MAR_ice_${k}.csv
  r.stats --q -aN input=basins@${mapset},mask_ice_RACMO@RACMO separator=,  \
	  > ./tmp/coverage_RACMO_ice_${k}.csv
done
#+END_SRC

+ How much of each land basin is (1) (is not (*)) covered by model land cells.

#+BEGIN_SRC bash :results verbatim
k=100
mapset=land_${k}
g.mapset ${mapset}

r.mask -r
r.stats --q -aN input=basins@${mapset},mask_land_MAR@MAR separator=,  \
	> ./tmp/coverage_MAR_land_${k}.csv
r.stats --q -aN input=basins@${mapset},mask_land_RACMO@RACMO separator=,  \
	> ./tmp/coverage_RACMO_land_${k}.csv
#+END_SRC

**** Prepare

Seems the easiest (and fastest) way to apply coverage is to write to NetCDF that is in the same format as the runoff NetCDF files so that they can easily be multiplied together.

#+NAME: coverage_prep1
#+BEGIN_SRC jupyter-python :session coverage_prepare :exports results :results drawer
import pandas as pd
import xarray as xr
import numpy as np

if 'c' not in locals(): c = 'coverage_MAR_ice_100'

df_raw = pd.read_csv('./tmp/' + c + '.csv', index_col=0, names=["c_or_uc", "area"])
df_raw = df_raw.drop(df_raw[df_raw.index == '*'].index)
df_raw.index = df_raw.index.astype(int)

df_c = df_raw[df_raw['c_or_uc'] == '1']\
    .drop(labels='c_or_uc', axis='columns')\
    .rename({'area':'covered'}, axis='columns')

df_uc = df_raw[df_raw['c_or_uc'] == '*']\
    .drop(labels='c_or_uc', axis='columns')\
    .rename({'area':'uncovered'}, axis='columns')

df = df_c.merge(df_uc, how='outer', left_index=True, right_index=True)\
         .sort_index()

df.fillna({'uncovered': 0}, inplace=True)

df['runoff'] = df['covered'] / (df['covered'] + df['uncovered'])

cov = df['runoff']
cov.index.name = 'station'
da = xr.DataArray.from_series(cov)
#+END_SRC

#+RESULTS: coverage_prep1


#+NAME: coverage_prepare
#+BEGIN_SRC jupyter-python :session coverage_prepare :exports results :results drawer :tangle coverage_csv2nc.py
import pandas as pd
import xarray as xr
import numpy as np

for model in ['RACMO', 'MAR']:
    for domain in ['ice', 'land']:
        for k in [80, 90, 100]:
            if (domain == 'land') & (k != 100):
                continue

            c = 'coverage' + '_' + model + '_' + domain + '_' + str(k)

            <<coverage_prep1>>
            da.to_netcdf('./tmp/' + c + '.nc', mode='w')
#+END_SRC

#+RESULTS: coverage_prepare

*** BSV to NC
:PROPERTIES:
:header-args:jupyter-python+: :tangle bsv2netcdf.py
:END:

Convert annual BSV files to annual NetCDF format files

Want to produce CF-compliant and user-friendly NetCDF that will work with nco and panoply. 
+ SEE: https://www.nodc.noaa.gov/data/formats/netcdf/v2.0/ timeSeriesProfile
+ https://www.nodc.noaa.gov/data/formats/netcdf/v2.0/timeSeriesOrthogonal.cdl
+ http://cfconventions.org/cf-conventions/cf-conventions.html#time-series-data

Also modeling after:
+ ~/data/Bamber_2018/FWF17.v3_a.nc
+ See also: https://gis.stackexchange.com/questions/67012/using-netcdf-for-point-time-series-observations

This code:
+ Can be run 1x within Org to produce =ds.nc= for testing purposes
+ Is also included in the tangled =bsv2netcdf.py= script

In the =bsv2netcdf.py= script, pass the input file in, and the output file is determined from the input file name.
Can be run in parallel (for example in the Makefile) with: =parallel --bar "python bsv2netcdf.py {}" ::: $(ls dat/*_runoff_*.bsv)=


#+NAME: bsv2xarray
#+BEGIN_SRC jupyter-python :session freshwater :exports both :results raw drawer :tangle no
import pandas as pd
import xarray as xr
import numpy as np
import datetime
import subprocess
import os

# if "BSVFILE" not in locals(): BSVFILE="./tmp/runoff_ice2margin_MAR.bsv.1979"
#if "BSVFILE" not in locals(): BSVFILE="./tmp/runoff_ice2margin_MAR.bsv.2000"
if "BSVFILE" not in locals(): BSVFILE="./dat/RACMO_runoff_land_1979_100.bsv"

df = pd.read_csv(BSVFILE, index_col=0, delimiter="|")
df.index = pd.to_datetime(df.index)

RCM, var, domain, year, k = os.path.basename(os.path.splitext(BSVFILE)[0]).split("_")

metadir = domain + "_" + k
meta = pd.read_csv("freshwater/" + metadir + "/outlets.csv" , index_col=0).T
meta = meta[df.columns.astype(int)]

ds = xr.Dataset()

ds["station"] = (("station"), df.columns.astype(str).astype(np.int32))
ds["time"] = (("time"), df.index)

ds["station"].attrs["long_name"] = "outlet id"
ds["station"].attrs["cf_role"] = "timeseries_id"

ds["time"].attrs["long_name"] = "time of measurement"
ds["time"].attrs["standard_name"] = "time"
ds["time"].attrs["axis"] = "T"

# gridsize = 100 x 100
CONV = 1E-3 * 100 * 100 / 86400
ds["discharge"] = (("station", "time"), df.values.T*CONV)
ds["discharge"].attrs["long_name"] = RCM + " discharge"
ds["discharge"].attrs["standard_name"] = "water_volume_transport_in_river_channel"
ds["discharge"].attrs["units"] = "m3 s-1"
ds["discharge"].attrs["coordinates"] = "lat lon alt station"
ds["discharge"].attrs['coverage_content_type'] = 'modelResult'

ds["lat"] = (("station"), meta.loc['lat'].astype(np.float32))
ds["lat"].attrs["long_name"] = "latitude"
ds["lat"].attrs["standard_name"] = "latitude"
ds["lat"].attrs["units"] = "degrees_north"
ds["lat"].attrs["axis"] = "Y"

ds["lon"] = (("station"), meta.loc['lon'].astype(np.float32))
ds["lon"].attrs["long_name"] = "longitude"
ds["lon"].attrs["standard_name"] = "longitude"
ds["lon"].attrs["units"] = "degrees_east"
ds["lon"].attrs["axis"] = "X"

ds["alt"] = (("station"), meta.loc['elev'].astype(np.int32))
ds["alt"].attrs["long_name"] = "height_above_mean_sea_level"
ds["alt"].attrs["standard_name"] = "altitude"
ds["alt"].attrs["units"] = "m"
ds["alt"].attrs["positive"] = "up"
ds["alt"].attrs["axis"] = "Z"

ds["Z2012_sector"] = (("station"), meta.loc["Z2012_sector"].replace(np.nan, value=-1).astype(np.int32))
ds["Z2012_sector"].attrs["long_name"] = "Zwally (2012) sector nearest outlet"
ds["Z2012_sector_dist"] = (("station"), meta.loc["Z2012_sector_dist"].replace(np.nan, value=-1).astype(np.int32))
ds["Z2012_sector_dist"].attrs["long_name"] = "Zwally (2012) sector nearest outlet distance"

ds["M2019_ID"] = (("station"), meta.loc["M2019_ID"].replace(np.nan, value=-1).astype(np.int32))
ds["M2019_ID"].attrs["long_name"] = "Mouginot (2019) basin nearest outlet ID"
ds["M2019_ID_dist"] = (("station"), meta.loc["M2019_ID_dist"].replace(np.nan, value=-1).astype(np.int32))
ds["M2019_ID_dist"].attrs["long_name"] = "Mouginot (2019) basin nearest outlet ID distance"
ds["M2019_basin"] = (("station"), meta.loc["M2019_basin"])
ds["M2019_basin"].attrs["long_name"] = "Mouginot (2019) basin nearest outlet name"
ds["M2019_region"] = (("station"), meta.loc["M2019_region"])
ds["M2019_region"].attrs["long_name"] = "Mouginot (2019) region nearest outlet"

ds["M2020_gate"] = (("station"), meta.loc["M2020_gate"].replace(np.nan, value=-1).astype(np.int32))
ds["M2020_gate"].attrs["long_name"] = "Mankoff (2020) gate nearest outlet"
ds["M2020_gate_dist"] = (("station"), meta.loc["M2020_gate_dist"].replace(np.nan, value=-1).astype(np.int32))
ds["M2020_gate_dist"].attrs["long_name"] = "Mankoff (2020) gate nearest outlet distance"

ds["B2015_name"] = (("station"), meta.loc["B2015_name"])
ds["B2015_name"].attrs["long_name"] = "Bjørk (2015) Official Name gate nearest outlet"
ds["B2015_dist"] = (("station"), meta.loc["B2015_dist"].astype(np.int32))
ds["B2015_dist"].attrs["long_name"] = "Bjørk (2015) Official Name point distance"

for var in ["B2015_dist", "M2019_ID", "M2019_ID_dist", "M2020_gate",
            "M2020_gate_dist", "Z2012_sector", "Z2012_sector_dist"]:
    ds[var].attrs["coverage_content_type"] = "auxiliaryInformation"
    ds[var].attrs["units"] = "N/A"

if "ice" in BSVFILE:
    ds["coast_id"] = (("station"), np.int32(meta.loc["coast_id"].astype(np.float32).replace(np.nan, value=-1)))
    ds["coast_id"].attrs["long_name"] = "ID of coastal outlet"
    ds["coast_id"].attrs["units"] = "N/A"
    ds["coast_id"].attrs["coverage_content_type"] = "auxiliaryInformation"

    ds["coast_lat"] = (("station"), meta.loc["coast_lat"].astype(np.float32))
    ds["coast_lat"].attrs["long_name"] = "latitude"
    ds["coast_lat"].attrs["standard_name"] = "latitude"
    ds["coast_lat"].attrs["units"] = "degrees_north"
    ds["coast_lat"].attrs["axis"] = "Y"

    ds["coast_lon"] = (("station"), meta.loc["coast_lon"].astype(np.float32))
    ds["coast_lon"].attrs["long_name"] = "longitude"
    ds["coast_lon"].attrs["standard_name"] = "longitude"
    ds["coast_lon"].attrs["units"] = "degrees_east"
    ds["coast_lon"].attrs["axis"] = "X"

    ds["coast_alt"] = (("station"), meta.loc["elev"].astype(np.float32))
    ds["coast_alt"].attrs["long_name"] = "height_above_mean_sea_level"
    ds["coast_alt"].attrs["standard_name"] = "altitude"
    ds["coast_alt"].attrs["units"] = "m"
    ds["coast_alt"].attrs["positive"] = "up"
    ds["coast_alt"].attrs["axis"] = "Z"

kw = ["GCMDSK:EARTH SCIENCE > CRYOSPHERE > GLACIERS/ICE SHEETS > ICE SHEETS > ICE SHEET MEASUREMENTS",
      "GCMDSK:EARTH SCIENCE > CRYOSPHERE > GLACIERS/ICE SHEETS > GLACIER MASS BALANCE/ICE SHEET MASS BALANCE",
      "GCMDSK:EARTH SCIENCE > CLIMATE INDICATORS > ATMOSPHERIC/OCEAN INDICATORS > FRESH WATER RIVER DISCHARGE",
      "GCMDSK:EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SURFACE WATER > SURFACE WATER PROCESSES/MEASUREMENTS > DISCHARGE/FLOW",
      "GCMDSK:EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SURFACE WATER > SURFACE WATER PROCESSES/MEASUREMENTS > DISCHARGE/FLOW > FLOW VELOCITY"]
ds.attrs["keywords"] = ", ".join(kw)
ds.attrs["keywords_vocabulary"] = "GCMDSK:GCMD Science Keywords:https://gcmd.earthdata.nasa.gov/kms/concepts/concept_scheme/sciencekeywords"

# recommended
import uuid
ds.attrs["id"] = "dk.geus.promice:" + str(uuid.uuid3(uuid.NAMESPACE_DNS, BSVFILE))
ds.attrs["naming_authority"] = "dk.geus.promice"
ds.attrs["history"] = "Generated on " + datetime.datetime.utcnow().isoformat()
ds.attrs["processing_level"] = "Level 3"
ds.attrs["acknowledgement"] = "The Programme for Monitoring of the Greenland Ice Sheet (PROMICE)"
ds.attrs["license"] = "Creative Commons Attribution 4.0 International (CC-BY-4.0) https://creativecommons.org/licenses/by/4.0"
ds.attrs["standard_name_vocabulary"] = "CF Standard Name Table (v77, 19 January 2021)"
ds.attrs["date_created"] = str(datetime.datetime.now().isoformat())
ds.attrs["creator_name"] = "Ken Mankoff"
ds.attrs["creator_email"] = "kdm@geus.dk"
ds.attrs["creator_url"] = "http://promice.org"
ds.attrs["institution"] = "GEUS"
ds.attrs["publisher_name"] = "GEUS"
ds.attrs["publisher_email"] = "info@promice.dk"
ds.attrs["publisher_url"] = "http://promice.dk"
    
ds.attrs["geospatial_bounds"] = "POLYGON((" + \
    f'{ds["lat"].min().values} {ds["lon"].min().values}, ' + \
    f'{ds["lat"].min().values} {ds["lon"].max().values}, ' + \
    f'{ds["lat"].max().values} {ds["lon"].max().values}, ' + \
    f'{ds["lat"].max().values} {ds["lon"].min().values}, ' + \
    f'{ds["lat"].min().values} {ds["lon"].min().values}))'
ds.attrs["geospatial_bounds_crs"] = "EPSG:4326"
# ds.attrs["geospatial_bounds_vertical_crs"] = "EPSG:4979"
ds.attrs["geospatial_lat_min"] = ds["lat"].min().values
ds.attrs["geospatial_lat_max"] = ds["lat"].max().values
ds.attrs["geospatial_lon_min"] = ds["lon"].min().values
ds.attrs["geospatial_lon_max"] = ds["lon"].max().values
ds.attrs["geospatial_vertical_min"] = ds["alt"].min().values
ds.attrs["geospatial_vertical_max"] = ds["alt"].max().values
ds.attrs["geospatial_vertical_positive"] = "up"
ds.attrs["time_coverage_start"] = str(ds["time"][0].values)
ds.attrs["time_coverage_end"] = str(ds["time"][-1].values)
# https://www.digi.com/resources/documentation/digidocs/90001437-13/reference/r_iso_8601_duration_format.htm
ds.attrs["time_coverage_duration"] = pd.Timedelta((ds["time"][-1] - ds["time"][0]).values).isoformat()
ds.attrs["time_coverage_resolution"] = pd.Timedelta((ds["time"][1] - ds["time"][0]).values).isoformat()
    
# suggested
ds.attrs["creator_type"] = "person"
ds.attrs["creator_institution"] = "GEUS"
ds.attrs["publisher_type"] = "institution"
ds.attrs["publisher_institution"] = "GEUS"
ds.attrs["program"] = "PROMICE"
ds.attrs["contributor_name"] = ""
ds.attrs["contributor_role"] = ""
ds.attrs["geospatial_lat_units"] = "degrees_north"
ds.attrs["geospatial_lon_units"] = "degrees_east"
ds.attrs["references"] = "Mankoff, Kenneth D., Noël, Brice, Fettweis, Xavier, Ahlstrøm, Andreas P., Colgan, William, Kondo, Ken, Langley, Kirsty, Sugiyama, Shin, van As, Dirk, Fausto, Robert S.: Greenland liquid water discharge from 1958 through 2019 , Earth System Science Data 12(4), 2811–2841, https://doi.org/10.5194/essd-12-2811-2020, 2020"
    
bib = """@article{mankoff_2020_liquid,
author    = {Mankoff, Kenneth D. and Noël, Brice and Fettweis, Xavier and Ahlstrøm, Andreas P. and
Colgan, William and Kondo, Ken and Langley, Kirsty and Sugiyama, Shin and van As,
Dirk and Fausto, Robert S.},
title     = {{G}reenland liquid water discharge from 1958 through 2019},
journal   = {Earth System Science Data},
year      = 2020,
volume    = 12,
number    = 4,
pages     = {2811–2841},
month     = 11,
ISSN      = {1866-3516},
DOI       = {10.5194/essd-12-2811-2020},
publisher = {Copernicus GmbH}}"""
ds.attrs["references_bib"] = bib
ds.attrs["project"] = "PROMICE"
    
ds.attrs["featureType"] = "timeSeries"
ds.attrs["title"] = "Greenland discharge"
ds.attrs["comment"] = "Greenland discharge"
ds.attrs["summary"] = "Greenland RCM discharge at basin outlets"
ds.attrs["keywords_other"] = "Hydrology; Greenland; Runoff; Discharge; Freshwater"
ds.attrs["Conventions"] = "CF-1.8, ACDD-1.3"
ds.attrs["source"] = "git commit: " + \
    subprocess.check_output(["git", "describe", "--always"]).strip().decode("UTF-8")
ds.attrs["DOI"] = "10.22008/promice/freshwater"
ds.attrs["product_version"] = "2025"
#+END_SRC

#+RESULTS: bsv2xarray

And now noweb weave [[bsv2xarray]] to convert all the BSVs to NetCDF files

#+BEGIN_SRC jupyter-python :session freshwater :exports both :results raw drawer
import numpy as np
import pandas as pd
import xarray as xr
import numpy as np
import sys
import os

f = sys.argv[1]
# f = './dat/MAR_runoff_ice_1979_100.bsv'
    
RCM, var, domain, year, k = os.path.basename(os.path.splitext(f)[0]).split("_")
#MAR runoff ice   2000 100

# Set up output folder and file name
OUTDIR = "./freshwater/" + domain + "_" + k + "/discharge" # ./freshwater_90 or ./freshwater_80
# if k == '100': OUTDIR = "./freshwater/" + domain + "/discharge" # ./freshwater/
if not os.path.exists(OUTDIR):
  os.makedirs(OUTDIR, exist_ok=True)
OUTBASE = RCM + "_" + year
OUTFILE = OUTDIR + "/" + OUTBASE + ".nc"

# Generate xarray structure
BSVFILE=f
<<bsv2xarray>>

# load and apply coverage scaling
cf = "coverage_" + RCM + "_" + domain +"_" + k + ".nc"
c = xr.open_dataset("./tmp/"+cf)
c = c.where(c['runoff'] != 0, np.nan, drop=False)
ds['discharge'].values = ds['discharge']/c['runoff'] # apply coverage

enc = {}
for v in ['discharge','alt','Z2012_sector','M2019_ID','M2020_gate']:
  enc[v] = {'zlib': True, 'complevel': 2}
enc['time'] = {'dtype': 'i4'}
enc['station'] = {'dtype': 'i4'}

ds.to_netcdf(OUTFILE, unlimited_dims='time', encoding=enc, engine='netcdf4', mode='w')
#+END_SRC

#+RESULTS:

*** Combine NetCDF 

Note:
+ ~ln -s ice_100 ice~
+ ~ln -s land_100 land~

#+BEGIN_SRC jupyter-python :tangle netcdf_combine.py
import xarray as xr
import numpy as np

for d in ['ice','land']:
    for r in ['RACMO','MAR']:
        print(d,r)
        ds = xr.open_mfdataset('./freshwater/'+d+'/discharge/'+r+'_*.nc', combine='by_coords')

        # don't include this year which is updated NRT in separate file
        ds = ds.where(ds['time'].dt.year < 2025, drop=True)

        for v in ['Z2012_sector', 'Z2012_sector_dist',
                  'M2019_ID','M2019_ID_dist','M2019_region','M2019_basin',
                  'M2020_gate','M2020_gate_dist',
                  'B2015_name','B2015_dist']:
            ds[v] = ds[v].isel({'time':1}).squeeze()
            
        if d == 'ice':
            for v in ['coast_id','coast_lat','coast_lon','coast_alt']:
                ds[v] = ds[v].isel({'time':1}).squeeze()
            
        for v in ['M2019_basin','M2019_region','B2015_name']:
            ds[v] = ds[v].astype(str)

        for v in ['B2015_dist','M2020_gate_dist','M2020_gate',
                  'M2019_ID_dist','M2019_ID','Z2012_sector_dist']:
            ds[v] = ds[v].astype(np.uint32)
        
        ds.to_netcdf('./freshwater/'+d+'/'+r+'.nc',
                     unlimited_dims='time', 
                     encoding={'discharge': {'zlib': True, 'complevel': 2},
                     #           'Z2012_sector': {'zlib': True, 'complevel': 2},
                     #           'M2019_ID': {'zlib': True, 'complevel': 2},
                     #           #'M2019_basin': {'zlib': True, 'complevel': 2},
                     #           #'M2019_region': {'zlib': True, 'complevel': 2},
                     #           'B2015_name': {'zlib': True, 'complevel': 2},
                     #           'M2020_gate': {'zlib': True, 'complevel': 2},
                               }, 
                     engine='netcdf4', mode='w')
        
#+END_SRC

** Makefile
:PROPERTIES:
:CUSTOM_ID: sec:makefile
:END:

This code, and all code files in this project, are derived products tangled from the =freshwater.org= source file.

#+BEGIN_SRC makefile :tangle Makefile
freshwater.zip: G all
# dist

G:
	grass -e -c EPSG:3413 ./G

all:
	make sob
	make k_basin_change
	make err
	make RCM
	make coverage
	make output

sob:
	# basins, outlets, and streams
	grass ./G/PERMANENT --exec ./import.sh
	grass ./G/PERMANENT --exec ./sob.sh 

k_basin_change:
	# how do basins change under different SOB routing?
	grass ./G/PERMANENT --exec ./k_basin_change.sh

err:
	# 2D EPSG area error
	grass ./G/PERMANENT --exec ./area_error.sh

RCM:
	# RCM
	mkdir -p dat
	python ./rcm_preprocess.py
	grass ./G/PERMANENT --exec ./rcm.sh # partition RCM output to basins

coverage:
	# coverage
	grass ./G/PERMANENT --exec ./coverage_calc.sh
	python coverage_csv2nc.py

output:
	# create end-user data product
	parallel --bar "python bsv2netcdf.py {}" ::: $$(ls dat/*_runoff_*.bsv)
	python netcdf_combine.py

update:
	wget http://ftp.climato.be/fettweis/tmp/ken/1km/MARv3.14-daily-ERA5-2025.nc -O ${DATADIR}/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2025.nc
	rm tmp/MAR_runoff_*_2025.nc
	python ./rcm_preprocess.py
	rm dat/MAR_runoff_*_2025_100.bsv
	grass ./G/PERMANENT --exec ./rcm.sh
	parallel --bar "python bsv2netcdf.py {}" ::: $$(ls dat/*_runoff_*2025*.bsv)

dist: freshwater.zip
	zip -r freshwater.zip freshwater

FORCE: # dummy target

clean_all:
	rm -fR G tmp dat freshwater freshwater.zip

clean_RCM:
	rm -fR G/MAR G/RACMO

clean_sob:
	rm -fR G/land_* G/ice_*
#+END_SRC

* Data                                                  :noexport:
** Provenance                                              :draft:
:PROPERTIES:
:header-args:bash+: :exports both :eval no-export
:END:

+ Show enough information about data files and metadata to aid in reproducibility

*** ArcticDEM

#+NAME: ArcticDEM_provenance
#+BEGIN_SRC bash :results verbatim :exports both
file=${DATADIR}/ArcticDEM/arcticdem_mosaic_100m_v4.1_dem.tif
md5sum ${file}
echo ""
gdalinfo ${file}
#+END_SRC

#+RESULTS: ArcticDEM_provenance
#+begin_example

be66611e17eb925404daa080e690522a  /home/kdm/data/ArcticDEM/arcticdem_mosaic_100m_v4.1_dem.tif

Driver: GTiff/GeoTIFF
Files: /home/kdm/data/ArcticDEM/arcticdem_mosaic_100m_v4.1_dem.tif
Size is 74002, 75002
Coordinate System is:
PROJCRS["WGS 84 / NSIDC Sea Ice Polar Stereographic North",
    BASEGEOGCRS["WGS 84",
        ENSEMBLE["World Geodetic System 1984 ensemble",
            MEMBER["World Geodetic System 1984 (Transit)"],
            MEMBER["World Geodetic System 1984 (G730)"],
            MEMBER["World Geodetic System 1984 (G873)"],
            MEMBER["World Geodetic System 1984 (G1150)"],
            MEMBER["World Geodetic System 1984 (G1674)"],
            MEMBER["World Geodetic System 1984 (G1762)"],
            MEMBER["World Geodetic System 1984 (G2139)"],
            ELLIPSOID["WGS 84",6378137,298.257223563,
                LENGTHUNIT["metre",1]],
            ENSEMBLEACCURACY[2.0]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",4326]],
    CONVERSION["US NSIDC Sea Ice polar stereographic north",
        METHOD["Polar Stereographic (variant B)",
            ID["EPSG",9829]],
        PARAMETER["Latitude of standard parallel",70,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8832]],
        PARAMETER["Longitude of origin",-45,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8833]],
        PARAMETER["False easting",0,
            LENGTHUNIT["metre",1],
            ID["EPSG",8806]],
        PARAMETER["False northing",0,
            LENGTHUNIT["metre",1],
            ID["EPSG",8807]]],
    CS[Cartesian,2],
        AXIS["easting (X)",south,
            MERIDIAN[45,
                ANGLEUNIT["degree",0.0174532925199433]],
            ORDER[1],
            LENGTHUNIT["metre",1]],
        AXIS["northing (Y)",south,
            MERIDIAN[135,
                ANGLEUNIT["degree",0.0174532925199433]],
            ORDER[2],
            LENGTHUNIT["metre",1]],
    USAGE[
        SCOPE["Polar research."],
        AREA["Northern hemisphere - north of 60°N onshore and offshore, including Arctic."],
        BBOX[60,-180,90,180]],
    ID["EPSG",3413]]
Data axis to CRS axis mapping: 1,2
Origin = (-4000100.000000000000000,4100100.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
Image Structure Metadata:
  COMPRESSION=LZW
  INTERLEAVE=BAND
  LAYOUT=COG
  PREDICTOR=3
Corner Coordinates:
Upper Left  (-4000100.000, 4100100.000) (179d17'33.71"E, 40d21'17.26"N)
Lower Left  (-4000100.000,-3400100.000) ( 94d38' 7.22"W, 44d 3'59.59"N)
Upper Right ( 3400100.000, 4100100.000) ( 95d19'55.26"E, 43d27'54.66"N)
Lower Right ( 3400100.000,-3400100.000) (  0d 0' 0.01"E, 47d34'59.22"N)
Center      ( -300000.000,  350000.000) (175d36' 4.66"E, 85d44'47.27"N)
Band 1 Block=512x512 Type=Float32, ColorInterp=Gray
  NoData Value=-9999
  Overviews: 37001x37501, 18500x18750, 9250x9375, 4625x4687, 2312x2343, 1156x1171, 578x585, 289x292
#+end_example

*** Citterio 2013

#+NAME: Citterio_2013_provenance
#+BEGIN_SRC bash :results verbatim :exports both
file=${DATADIR}/Citterio_2013/PROMICE_250_2019-12-04_EPSG4326/PROMICE_250_2019-12-04.shp
md5sum ${file}
#+END_SRC

#+RESULTS: Citterio_2013_provenance
: 
: a69e8f7fa340d8998c69aef539de8c58  /home/kdm/data/Citterio_2013/PROMICE_250_2019-12-04_EPSG4326/PROMICE_250_2019-12-04.shp

*** GIMP_0714

#+NAME: GIMP_0714_provenance
#+BEGIN_SRC bash :results verbatim :exports both
file=${DATADIR}/NSIDC/NSIDC-0714.001/1999.07.01/GimpOceanMask_90m_2000_v1.2.tif
md5sum ${file}
echo ""
gdalinfo ${file}
#+END_SRC

#+RESULTS: GIMP_0714_provenance
#+begin_example
43eafcdade8e1e2ee79d0d0b55430fd1  /home/kdm/data/NSIDC/NSIDC-0714.001/1999.07.01/GimpOceanMask_90m_2000_v1.2.tif

Driver: GTiff/GeoTIFF
Files: /home/kdm/data/NSIDC/NSIDC-0714.001/1999.07.01/GimpOceanMask_90m_2000_v1.2.tif
Size is 16620, 30000
Coordinate System is:
PROJCRS["unnamed",
    BASEGEOGCRS["WGS 84",
        DATUM["World Geodetic System 1984",
            ELLIPSOID["WGS 84",6378137,298.257223563,
                LENGTHUNIT["metre",1]]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",4326]],
    CONVERSION["Polar Stereographic (variant B)",
        METHOD["Polar Stereographic (variant B)",
            ID["EPSG",9829]],
        PARAMETER["Latitude of standard parallel",70,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8832]],
        PARAMETER["Longitude of origin",-45,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8833]],
        PARAMETER["False easting",1,
            LENGTHUNIT["metre",1],
            ID["EPSG",8806]],
        PARAMETER["False northing",1,
            LENGTHUNIT["metre",1],
            ID["EPSG",8807]]],
    CS[Cartesian,2],
        AXIS["(E)",south,
            MERIDIAN[90,
                ANGLEUNIT["degree",0.0174532925199433,
                    ID["EPSG",9122]]],
            ORDER[1],
            LENGTHUNIT["metre",1]],
        AXIS["(N)",south,
            MERIDIAN[180,
                ANGLEUNIT["degree",0.0174532925199433,
                    ID["EPSG",9122]]],
            ORDER[2],
            LENGTHUNIT["metre",1]]]
Data axis to CRS axis mapping: 1,2
Origin = (-640000.000000000000000,-655550.000000000000000)
Pixel Size = (90.000000000000000,-90.000000000000000)
Metadata:
  AREA_OR_POINT=Area
Image Structure Metadata:
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( -640000.000, -655550.000) ( 89d18'44.40"W, 81d33'26.51"N)
Lower Left  ( -640000.000,-3355550.000) ( 55d47'53.80"W, 59d11'57.96"N)
Upper Right (  855800.000, -655550.000) (  7d32'51.02"E, 80d 4'20.46"N)
Lower Right (  855800.000,-3355550.000) ( 30d41'32.31"W, 58d47'45.95"N)
Center      (  107900.000,-2005550.000) ( 41d55'13.60"W, 71d36'44.99"N)
Band 1 Block=16620x1 Type=Int16, ColorInterp=Gray
#+end_example


*** BedMachine v5

#+NAME: BM4_md5sum_ncdump
#+BEGIN_SRC bash :results verbatim :exports both
md5sum ${DATADIR}/Morlighem_2017/BedMachineGreenland-v5.nc
echo ""
ncdump -chs ${DATADIR}/Morlighem_2017/BedMachineGreenland-v5.nc
#+END_SRC

#+RESULTS: BM4_md5sum_ncdump
#+begin_example
7387182a059dd8cad66ce7638eb0d7cd  /home/kdm/data/Morlighem_2017/BedMachineGreenland-v5.nc

netcdf BedMachineGreenland-v5 {
dimensions:
	x = 10218 ;
	y = 18346 ;
variables:
	char mapping ;
		mapping:grid_mapping_name = "polar_stereographic" ;
		mapping:latitude_of_projection_origin = 90. ;
		mapping:standard_parallel = 70. ;
		mapping:straight_vertical_longitude_from_pole = -45. ;
		mapping:false_easting = 0. ;
		mapping:false_northing = 0. ;
		mapping:proj4text = "+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs" ;
		mapping:crs_wkt = "PROJCS[\"WGS 84 / NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3413\"]]" ;
		mapping:_Storage = "contiguous" ;
	int x(x) ;
		x:long_name = "Cartesian x-coordinate" ;
		x:standard_name = "projection_x_coordinate" ;
		x:units = "meter" ;
		x:_Storage = "contiguous" ;
		x:_Endianness = "little" ;
	int y(y) ;
		y:long_name = "Cartesian y-coordinate" ;
		y:standard_name = "projection_y_coordinate" ;
		y:units = "meter" ;
		y:_Storage = "contiguous" ;
		y:_Endianness = "little" ;
	byte mask(y, x) ;
		mask:long_name = "mask (0 = ocean, 1 = ice-free land, 2 = grounded ice, 3 = floating ice, 4 = non-Greenland land)" ;
		mask:grid_mapping = "mapping" ;
		mask:valid_range = 0b, 4b ;
		mask:flag_values = 0b, 1b, 2b, 3b, 4b ;
		mask:flag_meanings = "ocean ice_free_land grounded_ice floating_ice non_greenland_land" ;
		mask:source = "gimpmask v2.0 (https://byrd.osu.edu/research/groups/glacier-dynamics/data/icemask) combined with coastline from Jeremie Mouginot" ;
		mask:_Storage = "contiguous" ;
	float surface(y, x) ;
		surface:long_name = "ice surface elevation" ;
		surface:standard_name = "surface_altitude" ;
		surface:units = "meters" ;
		surface:grid_mapping = "mapping" ;
		surface:source = "gimpdem v2.1 (https://byrd.osu.edu/research/groups/glacier-dynamics/data/gimpdem)" ;
		surface:_Storage = "contiguous" ;
		surface:_Endianness = "little" ;
	float thickness(y, x) ;
		thickness:long_name = "ice thickness" ;
		thickness:standard_name = "land_ice_thickness" ;
		thickness:units = "meters" ;
		thickness:grid_mapping = "mapping" ;
		thickness:source = "Mass conservation (Mathieu Morlighem)" ;
		thickness:_Storage = "contiguous" ;
		thickness:_Endianness = "little" ;
	float bed(y, x) ;
		bed:long_name = "bed topography" ;
		bed:standard_name = "bedrock_altitude" ;
		bed:units = "meters" ;
		bed:grid_mapping = "mapping" ;
		bed:source = "Mass conservation (Mathieu Morlighem)" ;
		bed:_FillValue = -9999.f ;
		bed:_Storage = "contiguous" ;
		bed:_Endianness = "little" ;
	short errbed(y, x) ;
		errbed:long_name = "bed topography/ice thickness error" ;
		errbed:units = "meters" ;
		errbed:grid_mapping = "mapping" ;
		errbed:source = "Mathieu Morlighem" ;
		errbed:_FillValue = -9999s ;
		errbed:_Storage = "chunked" ;
		errbed:_ChunkSizes = 3670, 2044 ;
		errbed:_DeflateLevel = 2 ;
		errbed:_Shuffle = "true" ;
		errbed:_Endianness = "little" ;
	byte source(y, x) ;
		source:long_name = "data source (0 = none, 1 = gimpdem, 2 = Mass conservation, 3 = synthetic, 4 = interpolation, 5 = hydrostatic equilibrium, 6 = kriging, 7 = RTOPO-2, 8 = gravity inversion, 9 = Millan et al. 2021, 10+ = bathymetry data)" ;
		source:grid_mapping = "mapping" ;
		source:valid_range = 0b, 50b ;
		source:flag_values = 0b, 1b, 2b, 3b, 4b, 5b, 6b, 7b, 8b, 9b, 10b, 11b, 12b, 13b, 14b, 15b, 16b, 17b, 18b, 19b, 20b, 21b, 22b, 23b, 24b, 25b, 26b, 27b, 28b, 29b, 30b, 31b, 32b, 33b, 34b, 35b, 36b, 37b, 38b, 39b, 40b, 41b, 42b, 43b, 44b, 45b, 46b, 47b, 48b, 49b, 50b ;
		source:flag_meanings = "none gimpdem mass_conservation synthetic interpolation hydrodstatic_equilibrium kriging RTopo_2 gravity_inversion millan_etal_2021 bathymetry1 bathymetry2 bathymetry3 bathymetry4 bathymetry5 bathymetry6 bathymetry7 bathymetry8 bathymetry9 bathymetry10 bathymetry11 bathymetry12 bathymetry13 bathymetry14 bathymetry15 bathymetry16 bathymetry17 bathymetry18 bathymetry19 bathymetry20 bathymetry21 bathymetry22 bathymetry23 bathymetry24 bathymetry25 bathymetry26 bathymetry27 bathymetry28 bathymetry29 bathymetry30 bathymetry31 bathymetry32 bathymetry33 bathymetry34 bathymetry35 bathymetry36 bathymetry37 bathymetry38 bathymetry39 bathymetry40 bathymetry41" ;
		source:source = "Mathieu Morlighem" ;
		source:_Storage = "contiguous" ;
	byte dataid(y, x) ;
		dataid:long_name = "data id" ;
		dataid:grid_mapping = "mapping" ;
		dataid:valid_range = 1b, 10b ;
		dataid:flag_values = 1b, 2b, 7b, 10b ;
		dataid:flag_meanings = "GIMPdem Radar seismic multibeam" ;
		dataid:source = "Mathieu Morlighem" ;
		dataid:_Storage = "chunked" ;
		dataid:_ChunkSizes = 4587, 2555 ;
		dataid:_DeflateLevel = 1 ;
		dataid:_Shuffle = "true" ;
	short geoid(y, x) ;
		geoid:long_name = "EIGEN-6C4 Geoid - WGS84 Ellipsoid difference" ;
		geoid:standard_name = "geoid_height_above_reference_ellipsoid" ;
		geoid:units = "meters" ;
		geoid:grid_mapping = "mapping" ;
		geoid:geoid = "eigen-6c4 (Forste et al 2014)" ;
		geoid:_Storage = "chunked" ;
		geoid:_ChunkSizes = 3670, 2044 ;
		geoid:_DeflateLevel = 2 ;
		geoid:_Shuffle = "true" ;
		geoid:_Endianness = "little" ;

// global attributes:
		:Conventions = "CF-1.7" ;
		:Title = "BedMachine Greenland" ;
		:Author = "Mathieu Morlighem" ;
		:version = "28-Jul-2022 (v5.5)" ;
		:nx = 10218. ;
		:ny = 18346. ;
		:Projection = "Polar Stereographic North (70N, 45W)" ;
		:proj4 = "+init=epsg:3413" ;
		:sea_water_density\ \(kg\ m-3\) = 1023. ;
		:ice_density\ \(kg\ m-3\) = 917. ;
		:xmin = -652925 ;
		:ymax = -632675 ;
		:spacing = 150 ;
		:no_data = -9999. ;
		:license = "No restrictions on access or use" ;
		:Data_citation = "Morlighem M. et al., (2017), BedMachine v3: Complete bed topography and ocean bathymetry mapping of Greenland from multi-beam echo sounding combined with mass conservation, Geophys. Res. Lett., 44, doi:10.1002/2017GL074954. (http://onlinelibrary.wiley.com/doi/10.1002/2017GL074954/full)" ;
		:_NCProperties = "version=2,netcdf=4.7.4,hdf5=1.8.12" ;
		:_SuperblockVersion = 0 ;
		:_IsNetcdf4 = 0 ;
		:_Format = "netCDF-4 classic model" ;
}
#+end_example

*** MAR
**** File list and md5sums

+ WARNING :: May be stale. Using pre-computed md5sum because it takes so long to calculate.

#+BEGIN_SRC bash :results verbatim :exports both :session
ROOT=${DATADIR}/MAR/3.14-daily-1km
LIST=$(cd ${ROOT}; ls *.nc | { tee >(head -n4 >&3; cat >/dev/null) | tail -n4; } 3>&1  ) # first and last four files
parallel --keep-order md5sum ${ROOT}/{} ::: ${LIST}
#+END_SRC

#+RESULTS:
: 4a23e342d46532a50a0d5fb300c0c705  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-1940.nc
: d946250b2ab7f1a4709d08aab0076194  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-1941.nc
: 355358a1c0b9423ffe61edfe0fbc91e1  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-1942.nc
: bde5ce319521b191211dc2e05609b06d  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-1943.nc
: 272d1b0c0111154832abc303c3e1ff6b  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2022.nc
: 37e36b2593d035d0dc7206adf8369031  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2023.nc
: be5cb657fca51ace0ee135f2021e7a14  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2024.nc
: cb21ced2f209c08461c09a74be9aabd3  /home/kdm/data/MAR/3.14-daily-1km/MARv3.14-daily-ERA5-2025.nc


**** ncdump

#+NAME: MAR_QC_ncdump
#+BEGIN_SRC bash :results verbatim :exports both
ROOT=${DATADIR}/MAR/3.14-daily-1km
ncdump -chs ${ROOT}/MARv3.14-daily-ERA5-2000.nc
#+END_SRC

#+RESULTS: MAR_QC_ncdump
#+begin_example
netcdf MARv3.14-daily-ERA5-2000 {
dimensions:
	y = 2881 ;
	x = 1681 ;
	time = 366 ;
	char1 = 1 ;
variables:
	float LAT(y, x) ;
		LAT:units = "degrees" ;
		LAT:long_name = "Latitude" ;
		LAT:standard_name = "Latitude" ;
		LAT:actual_range = 57.78427f, 84.74171f ;
		LAT:grid_mapping = "crs" ;
		LAT:coordinates = "y, x" ;
		LAT:missing_value = -1.e+19f ;
		LAT:_FillValue = -1.e+19f ;
		LAT:_Storage = "chunked" ;
		LAT:_ChunkSizes = 2881, 1681 ;
		LAT:_Shuffle = "true" ;
		LAT:_DeflateLevel = 6 ;
		LAT:_Endianness = "little" ;
	float LON(y, x) ;
		LON:units = "degrees" ;
		LON:long_name = "Longitude" ;
		LON:standard_name = "Longitude" ;
		LON:actual_range = -96.63251f, 14.30028f ;
		LON:grid_mapping = "crs" ;
		LON:coordinates = "y, x" ;
		LON:missing_value = -1.e+19f ;
		LON:_FillValue = -1.e+19f ;
		LON:_Storage = "chunked" ;
		LON:_ChunkSizes = 2881, 1681 ;
		LON:_Shuffle = "true" ;
		LON:_DeflateLevel = 6 ;
		LON:_Endianness = "little" ;
	float MSK(y, x) ;
		MSK:units = "-" ;
		MSK:long_name = "Land/Ice Mask" ;
		MSK:standard_name = "Land_Ice_Mask" ;
		MSK:actual_range = 0.f, 4.f ;
		MSK:grid_mapping = "crs" ;
		MSK:coordinates = "y, x" ;
		MSK:missing_value = -1.e+19f ;
		MSK:_FillValue = -1.e+19f ;
		MSK:_Storage = "chunked" ;
		MSK:_ChunkSizes = 2881, 1681 ;
		MSK:_Shuffle = "true" ;
		MSK:_DeflateLevel = 6 ;
		MSK:_Endianness = "little" ;
	float MSK_MAR(y, x) ;
		MSK_MAR:units = "-" ;
		MSK_MAR:long_name = "Original MAR 10x10km2 Ice Mask" ;
		MSK_MAR:standard_name = "Original_MAR_10x10km2_Ice_Mask" ;
		MSK_MAR:actual_range = 0.f, 2.f ;
		MSK_MAR:grid_mapping = "crs" ;
		MSK_MAR:coordinates = "y, x" ;
		MSK_MAR:missing_value = -1.e+19f ;
		MSK_MAR:_FillValue = -1.e+19f ;
		MSK_MAR:_Storage = "chunked" ;
		MSK_MAR:_ChunkSizes = 2881, 1681 ;
		MSK_MAR:_Shuffle = "true" ;
		MSK_MAR:_DeflateLevel = 6 ;
		MSK_MAR:_Endianness = "little" ;
	float RU2(time, y, x) ;
		RU2:units = "mmWE/day" ;
		RU2:long_name = "Water run-off (sub-pixel 2)" ;
		RU2:standard_name = "Water_run-off__sub-pixel_2_" ;
		RU2:actual_range = 0.f, 222.4838f ;
		RU2:grid_mapping = "crs" ;
		RU2:coordinates = "time, y, x" ;
		RU2:missing_value = -1.e+19f ;
		RU2:_FillValue = -1.e+19f ;
		RU2:_Storage = "chunked" ;
		RU2:_ChunkSizes = 100, 2881, 1681 ;
		RU2:_Shuffle = "true" ;
		RU2:_DeflateLevel = 6 ;
		RU2:_Endianness = "little" ;
	float RUcorr(time, y, x) ;
		RUcorr:units = "mmWEday" ;
		RUcorr:long_name = "Water run-off (sub-pixel 1)" ;
		RUcorr:standard_name = "Water_run-off__sub-pixel_1_" ;
		RUcorr:actual_range = 0.f, 249.4513f ;
		RUcorr:grid_mapping = "crs" ;
		RUcorr:coordinates = "time, y, x" ;
		RUcorr:missing_value = -1.e+19f ;
		RUcorr:_FillValue = -1.e+19f ;
		RUcorr:_Storage = "chunked" ;
		RUcorr:_ChunkSizes = 100, 2881, 1681 ;
		RUcorr:_Shuffle = "true" ;
		RUcorr:_DeflateLevel = 6 ;
		RUcorr:_Endianness = "little" ;
	float SMBcorr(time, y, x) ;
		SMBcorr:units = "mmWE/day" ;
		SMBcorr:long_name = "Surface Mass Balance (sub-pixel 1)" ;
		SMBcorr:standard_name = "Surface_Mass_Balance__sub-pixel_1_" ;
		SMBcorr:actual_range = -241.9119f, 201.7053f ;
		SMBcorr:grid_mapping = "crs" ;
		SMBcorr:coordinates = "time, y, x" ;
		SMBcorr:missing_value = -1.e+19f ;
		SMBcorr:_FillValue = -1.e+19f ;
		SMBcorr:_Storage = "chunked" ;
		SMBcorr:_ChunkSizes = 100, 2881, 1681 ;
		SMBcorr:_Shuffle = "true" ;
		SMBcorr:_DeflateLevel = 6 ;
		SMBcorr:_Endianness = "little" ;
	float SRF(y, x) ;
		SRF:units = "m" ;
		SRF:long_name = "Surface height" ;
		SRF:standard_name = "Surface_height" ;
		SRF:actual_range = 0.f, 3442.f ;
		SRF:grid_mapping = "crs" ;
		SRF:coordinates = "y, x" ;
		SRF:missing_value = -1.e+19f ;
		SRF:_FillValue = -1.e+19f ;
		SRF:_Storage = "chunked" ;
		SRF:_ChunkSizes = 2881, 1681 ;
		SRF:_Shuffle = "true" ;
		SRF:_DeflateLevel = 6 ;
		SRF:_Endianness = "little" ;
	float SRF_MAR(y, x) ;
		SRF_MAR:units = "m" ;
		SRF_MAR:long_name = "Original MAR 10x10km2 Surface height" ;
		SRF_MAR:standard_name = "Original_MAR_10x10km2_Surface_height" ;
		SRF_MAR:actual_range = 0.f, 3229.96f ;
		SRF_MAR:grid_mapping = "crs" ;
		SRF_MAR:coordinates = "y, x" ;
		SRF_MAR:missing_value = -1.e+19f ;
		SRF_MAR:_FillValue = -1.e+19f ;
		SRF_MAR:_Storage = "chunked" ;
		SRF_MAR:_ChunkSizes = 2881, 1681 ;
		SRF_MAR:_Shuffle = "true" ;
		SRF_MAR:_DeflateLevel = 6 ;
		SRF_MAR:_Endianness = "little" ;
	char crs(char1) ;
		crs:grid_mapping_name = "polar_stereographic" ;
		crs:standard_name = "polar_stereographic" ;
		crs:long_name = "Polar Stereographic (variant B)" ;
		crs:authority = "EPSG:3413" ;
		crs:standard_parallel = 70.f ;
		crs:straight_vertical_longitude_from_pole = -45.f ;
		crs:semi_major_axis = 6378137.f ;
		crs:inverse_flattening = 298.2572f ;
		crs:latitude_of_projection_origin = 90.f ;
		crs:false_easting = 0.f ;
		crs:false_northing = 0.f ;
		crs:_Storage = "chunked" ;
		crs:_ChunkSizes = 1 ;
		crs:_Shuffle = "true" ;
		crs:_DeflateLevel = 6 ;
	float time(time) ;
		time:units = "DAYS since 2000-01-01 12:00:00" ;
		time:long_name = "time" ;
		time:standard_name = "time" ;
		time:_Storage = "chunked" ;
		time:_ChunkSizes = 100 ;
		time:_Shuffle = "true" ;
		time:_DeflateLevel = 6 ;
		time:_Endianness = "little" ;
	float x(x) ;
		x:units = "m" ;
		x:long_name = "x" ;
		x:standard_name = "x" ;
		x:_Storage = "chunked" ;
		x:_ChunkSizes = 1681 ;
		x:_Shuffle = "true" ;
		x:_DeflateLevel = 6 ;
		x:_Endianness = "little" ;
	float y(y) ;
		y:units = "m" ;
		y:long_name = "y" ;
		y:standard_name = "y" ;
		y:_Storage = "chunked" ;
		y:_ChunkSizes = 2881 ;
		y:_Shuffle = "true" ;
		y:_DeflateLevel = 6 ;
		y:_Endianness = "little" ;

// global attributes:
		:title = "Daily MARv3.14 outputs in 2000 interpolated on the 1x1km^2 grid of ISMIP6 using ERA5" ;
		:institution = "ULg (Xavier Fettweis)" ;
		:netcdf = "4.9.2 of Oct 15 2024 12:29:46 $" ;
		:Conventions = "CF-1.6" ;
		:contact = "xavier.fettweis@uliege.be" ;
		:forcing = "ERA5" ;
		:creation_date = "2025-03-09-T151516Z" ;
		:project = "ISMIP6" ;
		:mapping = "ellipsoid=WGS84;false_easting=0;false_northing=0;grid_mapping_name=polar_stereographic,latitude_of_projection_origin=90,standard_parallel=70;straight_vertical_longitude_from_pole=-45" ;
		:description = "Area scaling factor (af) for ISMIP6 Greenland grid. Multiply with 2D data to correct the projection error. af=(1/k)^2, where k is the map scale factor. Calculated after Snyder (1987) by Heiko Goelzer, IMAU, April 2018." ;
		:institute = "University of Liege (Belgium)" ;
		:model = "regional climate model MAR (v3.14.1)" ;
		:date = "Sun Mar  9 03:15:16 PM CET 2025" ;
		:history = "Sun Mar  9 15:15:16 2025: ncks --cnk_dmn time,100 -L 6 MARv3.14-daily-ERA5-2000.nc MARv3.14-daily-ERA5-2000.nc4" ;
		:NCO = "netCDF Operators version 5.2.9 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco, Citation = 10.1016/j.envsoft.2008.03.004)" ;
		:_NCProperties = "version=2,netcdf=4.9.2,hdf5=1.12.3" ;
		:_SuperblockVersion = 2 ;
		:_IsNetcdf4 = 1 ;
		:_Format = "netCDF-4" ;
}
#+end_example

*** RACMO
**** File list and md5sums

+ WARN :: Only check some to save compute time.

#+NAME: RACMO_QC_md5sum
#+BEGIN_SRC bash :results table :exports both
echo 'ice'
(cd ${DATADIR}/RACMO/freshwater/runoff_ice_1km; find . -type f -name "*.nc" | LC_ALL=C sort | head -n8 | parallel --keep-order md5sum)
(cd ${DATADIR}/RACMO/freshwater/runoff_ice_1km; find . -type f -name "*.nc" | LC_ALL=C sort | tail -n8 | parallel --keep-order md5sum)
echo 'land_5.5_km'
(cd ${DATADIR}/RACMO/freshwater/runoff_land_5.5km; find . -type f -name "*.nc" | LC_ALL=C sort | head -n8 | parallel --keep-order md5sum)
(cd ${DATADIR}/RACMO/freshwater/runoff_land_5.5km; find . -type f -name "*.nc" | LC_ALL=C sort | tail -n8 | parallel --keep-order md5sum)
echo 'land_1_km'
(cd ${DATADIR}/RACMO/freshwater/runoff_land_1km_regrid; find . -type f -name "*.nc" | LC_ALL=C sort | head -n8 | parallel --keep-order md5sum)
(cd ${DATADIR}/RACMO/freshwater/runoff_land_1km_regrid; find . -type f -name "*.nc" | LC_ALL=C sort | tail -n8 | parallel --keep-order md5sum)
#+END_SRC

#+RESULTS: RACMO_QC_md5sum
| ice                              |                                                                            |
| 219834ba9f1bc98e0a87ab37ea88863d | ./runoff.1990_AMJ.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| 7bde9226e0651e2cfbb8082424ba5181 | ./runoff.1990_JAS.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| 76d77c3ac9881521825d93c1c43af7d5 | ./runoff.1990_JFM.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| 17dd60fa5964af322624e72d9b58ea7c | ./runoff.1990_OND.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| fcdd6121b4c1c94d1fe5018966deacac | ./runoff.1991_AMJ.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| 48c894ad8d7c95b5521892c18183ea41 | ./runoff.1991_JAS.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| d405a62f91a201e3b7be931c12e1f678 | ./runoff.1991_JFM.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| bcaadbf2e742b533a612417f748dd5f0 | ./runoff.1991_OND.BN_RACMO2.3p2_ERA5_3h_FGRN055.1km.DD.nc                  |
| acf9b55165baf20b613067383ea3d1fc | ./runoff_WJB_int.1988_AMJ.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| 08d48cb9b85912742785fc089a8462bb | ./runoff_WJB_int.1988_JAS.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| 9c26be97b007d967bdcc48c34ad1c3ea | ./runoff_WJB_int.1988_JFM.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| 0673a072bd62d2957f01d5ca6c6cf570 | ./runoff_WJB_int.1988_OND.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| c9d47dea1a7fe5317447734ac19b7faa | ./runoff_WJB_int.1989_AMJ.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| 46b5f01a3dce922eee06f48f415ec9fb | ./runoff_WJB_int.1989_JAS.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| dbfdf673dc82d957b5109b34724db0a6 | ./runoff_WJB_int.1989_JFM.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| af207835fe80b60d58e06b5f6035bf18 | ./runoff_WJB_int.1989_OND.BN_RACMO2.3p2_FGRN055_1km.DD.nc                  |
| land_5.5_km                      |                                                                            |
| f60e7505e75e58133e82d381db5caa43 | ./runoff.1957.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| 7b2de3637a9b79647aa600c8da7d2990 | ./runoff.1958.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| cf60a1b81f84975ee741b483ddedb46c | ./runoff.1959.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| fd74c2d30a0d6589303b8ccbc4679694 | ./runoff.1960.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| d364c5db102ee36981d55e0b46277673 | ./runoff.1961.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| fcb4b8154fce45145ba468c7b0c2a1e6 | ./runoff.1962.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| b87dfb7d13426080a58745d9a917de2b | ./runoff.1963.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| 3d055d1d9c0ddacae46acad23a421a9e | ./runoff.1964.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc                          |
| 32e7fa643ae40f346999e09c1b17a6d5 | ./runoff.2014.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| 1a6d4fdbb8dd14aa5311b3d43954c331 | ./runoff.2015.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| a5f91f7731fb2a7418a7e89e9f67fb43 | ./runoff.2016.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| 90634adf3dd1b9ee409002a29ac3e08f | ./runoff.2017.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| 906751f527cdb51f5448fd324a705a29 | ./runoff.2018.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| 0e481615b966397f0a4c50f48ba1dab9 | ./runoff.2019.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| a813eb69a66bd4c23cf15afcac592420 | ./runoff.2020.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| c5ae487f3ecc5987a17c3c06083ebd5a | ./runoff.2021.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc                  |
| land_1_km                        |                                                                            |
| 879f40c2e9c4598a83458ab93bcd2246 | ./Grid_regular_EPSG3413_1km.nc                                             |
| c2caab22f5dc8b816d26b15b07c6c732 | ./Tundra_Mask_1km.nc                                                       |
| c0c69a24c76cb909ea2ee463d79d10b6 | ./mask.nc                                                                  |
| a3c0a6c3762155ad404fe6be75c49251 | ./out/runoff.1957.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc.1km-bilin.nc         |
| 76d34a54d246b6872d913e7889f66772 | ./out/runoff.1958.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc.1km-bilin.nc         |
| 5f1f04983c6f79fc1d89ccb15ec5946b | ./out/runoff.1959.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc.1km-bilin.nc         |
| b5d9ffdd8b73d22d9b6bc7da5cbc3c0d | ./out/runoff.1960.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc.1km-bilin.nc         |
| dc269d5d295640ed71f033bce1d30489 | ./out/runoff.1961.FGRN055_BN_RACMO2.3p2_FGRN055.DD.nc.1km-bilin.nc         |
| 78000c74d9e9553e5237c20205b6f891 | ./out/runoff.2017.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| ced4b9dd79d5c2e0a612b01bd07d2afd | ./out/runoff.2018.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| 9f520292d3ab4dbf40246bc462cda4e3 | ./out/runoff.2019.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| 59b9237449e3c8dfe1b62e8a330bffbd | ./out/runoff.2020.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| c03ce8c3865abad695537b78e5fcbe13 | ./out/runoff.2021.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| 0d0023a324f077136cf8e69b96440617 | ./out/runoff.2022.FGRN055_BN_RACMO2.3p2_ERA5_3h_FGRN055.DD.nc.1km-bilin.nc |
| c5e011d91b9feb6b7a533b9f146486f8 | ./weights_FGRN055_to_EPSG3413_1km_bilinear.nc                              |
| 8f7bea66a91abcea8f2995a9d36b1132 | ./weights_FGRN055_to_EPSG3413_1km_neareststod.nc                           |

**** ncdump

#+NAME: RACMO_QC_ncdump
#+BEGIN_SRC bash :results verbatim :exports both
ROOT=${DATADIR}/RACMO/freshwater/runoff_ice_1km
ncdump -chs ${ROOT}/runoff_WJB_int.1979_AMJ.BN_RACMO2.3p2_FGRN055_1km.DD.nc
#+END_SRC

#+RESULTS: RACMO_QC_ncdump
#+begin_example

netcdf runoff_WJB_int.1979_AMJ.BN_RACMO2.3p2_FGRN055_1km.DD {
dimensions:
	time = 91 ;
	x = 1496 ;
	y = 2700 ;
variables:
	float time(time) ;
		time:units = "DAYS since 1979-04-01 00:00:00" ;
		time:long_name = "time" ;
		time:standard_name = "time" ;
		time:_Storage = "chunked" ;
		time:_ChunkSizes = 91 ;
		time:_DeflateLevel = 1 ;
		time:_Endianness = "little" ;
		time:_NoFill = "true" ;
	float x(x) ;
		x:units = "km" ;
		x:long_name = "x" ;
		x:standard_name = "x" ;
		x:_Storage = "chunked" ;
		x:_ChunkSizes = 1496 ;
		x:_DeflateLevel = 1 ;
		x:_Endianness = "little" ;
		x:_NoFill = "true" ;
	float y(y) ;
		y:units = "km" ;
		y:long_name = "y" ;
		y:standard_name = "y" ;
		y:_Storage = "chunked" ;
		y:_ChunkSizes = 2700 ;
		y:_DeflateLevel = 1 ;
		y:_Endianness = "little" ;
		y:_NoFill = "true" ;
	float LON(y, x) ;
		LON:units = "km" ;
		LON:long_name = "Easting" ;
		LON:standard_name = "Easting" ;
		LON:actual_range = 0.f, 0.f ;
		LON:missing_value = 0.f, -1.225254e+28f ;
		LON:_Storage = "chunked" ;
		LON:_ChunkSizes = 1350, 748 ;
		LON:_DeflateLevel = 1 ;
		LON:_Endianness = "little" ;
		LON:_NoFill = "true" ;
	float LAT(y, x) ;
		LAT:units = "km" ;
		LAT:long_name = "Northing" ;
		LAT:standard_name = "Northing" ;
		LAT:actual_range = 0.f, 0.f ;
		LAT:missing_value = 0.f, -1.225254e+28f ;
		LAT:_Storage = "chunked" ;
		LAT:_ChunkSizes = 1350, 748 ;
		LAT:_DeflateLevel = 1 ;
		LAT:_Endianness = "little" ;
		LAT:_NoFill = "true" ;
	float runoffcorr(time, y, x) ;
		runoffcorr:units = "mm w.e. per day" ;
		runoffcorr:long_name = "Downscaled corrected snowmelt" ;
		runoffcorr:standard_name = "Downscaled_corrected_snowmelt" ;
		runoffcorr:actual_range = 0.f, 508.326f ;
		runoffcorr:missing_value = -1.e+30f ;
		runoffcorr:_Storage = "chunked" ;
		runoffcorr:_ChunkSizes = 12, 338, 187 ;
		runoffcorr:_DeflateLevel = 1 ;
		runoffcorr:_Endianness = "little" ;
		runoffcorr:_NoFill = "true" ;

// global attributes:
		:title = "Daily runoff field (RACMO2.3p2)" ;
		:institution = "IMAU (Brice Noel)" ;
		:grid = "Map Projection:Polar Stereographic Ellipsoid - Map Reference Latitude: 90.0 - Map Reference Longitude: -39.0 - Map Second Reference Latitude: 71.0 - Map Eccentricity: 0.081819190843 ;wgs84 - Map Equatorial Radius: 6378137.0 ;wgs84 meters - Grid Map Origin Column: 160 - Grid Map Origin Row: -120 - Grid Map Units per Cell: 5000 - Grid Width: 301 - Grid Height: 561" ;
		:history = "libUN (2013.05.22) - Fri Mar 16 18:19:46 2018" ;
" ;
		:_NCProperties = "version=1|netcdflibversion=4.6.0|hdf5libversion=1.10.0" ;
		:_SuperblockVersion = 0 ;
		:_IsNetcdf4 = 0 ;
		:_Format = "netCDF-4 classic model" ;
}
#+end_example



*** Bamber 2018
#+NAME: bamber_2018
#+BEGIN_SRC bash :results verbatim :exports both
FILE=${DATADIR}/Bamber_2018/FWF17.v3_a.nc
md5sum ${FILE}
ncdump -chs ${FILE}
#+END_SRC

#+RESULTS: bamber_2018
#+begin_example

ed9d9bd0580e124146a5503832ced95e  /home/kdm/data/Bamber_2018/FWF17.v3_a.nc
netcdf FWF17.v3_a {
dimensions:
	Y = 785 ;
	X = 752 ;
	TIME = 708 ;
variables:
	double Y(Y) ;
		Y:_FillValue = NaN ;
		Y:units = "meters" ;
		Y:standard_name = "projection_y_coordinate" ;
		Y:point_spacing = "even" ;
		Y:axis = "Y" ;
		Y:_Storage = "contiguous" ;
		Y:_Endianness = "little" ;
	double X(X) ;
		X:_FillValue = NaN ;
		X:units = "meters" ;
		X:standard_name = "projection_x_coordinate" ;
		X:point_spacing = "even" ;
		X:axis = "X" ;
		X:_Storage = "contiguous" ;
		X:_Endianness = "little" ;
	int64 TIME(TIME) ;
		TIME:units = "days since 1958-01-01 00:00:00" ;
		TIME:calendar = "proleptic_gregorian" ;
		TIME:_Storage = "contiguous" ;
		TIME:_Endianness = "little" ;
	short runoff_tundra(TIME, Y, X) ;
		runoff_tundra:_FillValue = -9999s ;
		runoff_tundra:long_name = "Tundra runoff" ;
		runoff_tundra:units = "km3" ;
		runoff_tundra:grid_mapping = "polar_stereographic" ;
		runoff_tundra:description = "WARNING! This variable contains runoff routed from all land tundra (i.e. including CAA, Svalbard, Iceland), whereas the paper only shows tundra runoff from Greenland. To reproduce Greenland-only runoff you must mask the tundra variable with the LSMGr mask provided in order to set all tundra runoff originating outside the Greenland land mass to zero." ;
		runoff_tundra:scale_factor = 0.01 ;
		runoff_tundra:_Storage = "chunked" ;
		runoff_tundra:_ChunkSizes = 118, 131, 126 ;
		runoff_tundra:_DeflateLevel = 4 ;
		runoff_tundra:_Shuffle = "true" ;
		runoff_tundra:_Endianness = "little" ;
	double lon(Y, X) ;
		lon:_FillValue = NaN ;
		lon:grid_mapping = "polar_stereographic" ;
		lon:units = "degrees" ;
		lon:standard_name = "longitude" ;
		lon:_Storage = "contiguous" ;
		lon:_Endianness = "little" ;
	short runoff_ice(TIME, Y, X) ;
		runoff_ice:_FillValue = -9999s ;
		runoff_ice:long_name = "Ice sheet runoff" ;
		runoff_ice:units = "km3" ;
		runoff_ice:grid_mapping = "polar_stereographic" ;
		runoff_ice:scale_factor = 0.01 ;
		runoff_ice:_Storage = "chunked" ;
		runoff_ice:_ChunkSizes = 118, 131, 126 ;
		runoff_ice:_DeflateLevel = 4 ;
		runoff_ice:_Shuffle = "true" ;
		runoff_ice:_Endianness = "little" ;
	double lat(Y, X) ;
		lat:_FillValue = NaN ;
		lat:grid_mapping = "polar_stereographic" ;
		lat:units = "degrees" ;
		lat:standard_name = "latitude" ;
		lat:_Storage = "contiguous" ;
		lat:_Endianness = "little" ;
	byte polar_stereographic ;
		polar_stereographic:grid_mapping_name = "polar_stereographic" ;
		polar_stereographic:scale_factor_at_central_origin = 1. ;
		polar_stereographic:standard_parallel = 70. ;
		polar_stereographic:straight_vertical_longitude_from_pole = -45. ;
		polar_stereographic:false_easting = 0. ;
		polar_stereographic:false_northing = 0. ;
		polar_stereographic:latitude_of_projection_origin = 90. ;
	byte LSMGr(Y, X) ;
		LSMGr:_FillValue = -99b ;
		LSMGr:long_name = "Hole-filled Greenland land mass mask" ;
		LSMGr:units = "none" ;
		LSMGr:grid_mapping = "polar_stereographic" ;
		LSMGr:_Storage = "chunked" ;
		LSMGr:_ChunkSizes = 785, 752 ;
		LSMGr:_DeflateLevel = 4 ;
		LSMGr:_Shuffle = "true" ;
	byte ocean_basins(Y, X) ;
		ocean_basins:_FillValue = -99b ;
		ocean_basins:long_name = "ID number of oceanographic basin which each coastal pixel drains into." ;
		ocean_basins:units = "none" ;
		ocean_basins:grid_mapping = "polar_stereographic" ;
		ocean_basins:basins = ", 26:Labrador Sea, 27:Hudson Strait, 28:Davis Strait, 29:Baffin Bay, 30:Lincoln Sea, 32:Irish Sea and St. George\'s Channel, 33:Inner Seas off the West Coast of Scotland, 55:Gulf of Riga, 56:Baltic Sea, 57:Gulf of Finland, 58:Gulf of Bothnia, 59:White Sea, 76:North Atlantic Ocean, 77:Gulf of St. Lawrence, 80:Celtic Sea, 82:Hudson Bay, 83:The Northwestern Passages, 84:Arctic Ocean, 86:Barentsz Sea, 87:Greenland Sea, 88:North Sea, 96:Kattegat, 98:Skagerrak, 99:Norwegian Sea" ;
		ocean_basins:history = "Basins are as defined by \"Limits of Oceans & Seas, Special Publication No. 23\" published by the IHO in 1953. The dataset was composed by the Flanders Marine Data and Information Centre and downloaded from www.marineregions.org on 6 February 2017. Coastal runoff pixels were allocated an ocean basin to run off into using fwf/allocate_coast_to_basin.py." ;
		ocean_basins:_Storage = "chunked" ;
		ocean_basins:_ChunkSizes = 785, 752 ;
		ocean_basins:_DeflateLevel = 4 ;
		ocean_basins:_Shuffle = "true" ;
	short solid_ice(TIME, Y, X) ;
		solid_ice:_FillValue = -9999s ;
		solid_ice:long_name = "Solid ice discharge" ;
		solid_ice:units = "km3" ;
		solid_ice:grid_mapping = "polar_stereographic" ;
		solid_ice:description = "the monthly discharge data are mean annual values divided by 12." ;
		solid_ice:scale_factor = 0.001 ;
		solid_ice:_Storage = "chunked" ;
		solid_ice:_ChunkSizes = 118, 131, 126 ;
		solid_ice:_DeflateLevel = 4 ;
		solid_ice:_Shuffle = "true" ;
		solid_ice:_Endianness = "little" ;

// global attributes:
		:Conventions = "CF-1.4" ;
		:institution = "University of Bristol (Andrew Tedstone)" ;
		:title = "Monthly freshwater fluxes to the ocean across the Arctic, 1958-2016" ;
		:nx = 752. ;
		:ny = 785. ;
		:xmin = -1777980. ;
		:ymax = -67308. ;
		:spacing = 5000. ;
		:description = "This is the dataset that underlies the paper \"Bamber, J., A. Tedstone, M. King, I. Howat, E. Enderlin, M. van den Broeke and B. Noel (2018) Land ice freshwater budget of the Arctic and North Atlantic Oceans. Part I: Data, methods and results. Journal of Geophysical Research: Oceans.\"" ;
		:_NCProperties = "version=1|netcdflibversion=4.4.1.1|hdf5libversion=1.10.1" ;
		:_SuperblockVersion = 0 ;
		:_IsNetcdf4 = 1 ;
		:_Format = "netCDF-4" ;
}
#+end_example


*** van As 2018
#+NAME: van_As_2018_provenance
#+END_SRC

#+BEGIN_SRC bash :results verbatim :exports both :session
dir=${DATADIR}/van_As_2018
md5sum ${dir}/*
echo ""
head ${dir}/Watson_discharge_day_v03.txt 
echo ""
tail ${dir}/Watson_discharge_day_v03.txt
#+END_SRC

#+RESULTS:
#+begin_example
176d156b2881b7b4c3ed75b2ede522e0  /home/kdm/data/van_As_2018/readme Watson.txt
9bde46206b085e4fb7d8c4c62dc9758e  /home/kdm/data/van_As_2018/Supplemental Data Set.xls
a1b9c2ae0c25e18014a28e873d18b873  /home/kdm/data/van_As_2018/uaar_a_1433799_sm6008.zip
0589c8ac34275f5002ca8cfd5a23b8a6  /home/kdm/data/van_As_2018/Watson_discharge_day_v03.txt
b5bc413b8db8b6944b35f3b5b5a0d0b2  /home/kdm/data/van_As_2018/Watson_discharge_hour_v03.txt
db56b7f1a7848f15b7158238df1943b1  /home/kdm/data/van_As_2018/Watson River discharge reconstruction 1949-2018.txt

 Year MonthOfYear DayOfMonth DayOfYear DayOfCentury WaterFluxDiversOnly(m3/s) Uncertainty(m3/s) WaterFluxDivers&Temperature(m3/s) Uncertainty(m3/s) WaterFluxCumulative(km3) Uncertainty(km3)
 2006    4   10  100 2292 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   11  101 2293 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   12  102 2294 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   13  103 2295 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   14  104 2296 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   15  105 2297 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   16  106 2298 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   17  107 2299 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   18  108 2300 -999.00 -999.00    0.00    0.00    0.00    0.00

 2019   10   18  291 7231 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   19  292 7232 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   20  293 7233 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   21  294 7234 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   22  295 7235 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   23  296 7236 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   24  297 7237 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   25  298 7238 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   26  299 7239 -999.00 -999.00    0.00    0.00    8.33    1.37
 2019   10   27  300 7240 -999.00 -999.00    0.00    0.00    8.33    1.37
#+end_example

#+RESULTS: van_As_2018_provenance
#+begin_example

d0cf2ba4bf7339cfa6ee3f9da74eb894  /home/kdm/data/van_As_2018/Watson_discharge_day_v03.txt
f25d973f65f778d3d935b779774deefe  /home/kdm/data/van_As_2018/Watson_discharge_hour_v03.txt
21cc48d77e497413be0b37dca18263bb  /home/kdm/data/van_As_2018/Watson_discharge.pdf
2ef04fb38fff2ba5b975aa45f516354b  /home/kdm/data/van_As_2018/Watson_discharge_year.txt

Year MonthOfYear DayOfMonth DayOfYear DayOfCentury WaterFluxDiversOnly(m3/s) Uncertainty(m3/s) WaterFluxDivers&Temperature(m3/s) Uncertainty(m3/s) WaterFluxCumulative(km3) Uncertainty(km3)
 2006    4   10  100 2292 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   11  101 2293 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   12  102 2294 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   13  103 2295 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   14  104 2296 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   15  105 2297 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   16  106 2298 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   17  107 2299 -999.00 -999.00    0.00    0.00    0.00    0.00
 2006    4   18  108 2300 -999.00 -999.00    0.00    0.00    0.00    0.00

2017   10   18  291 6501 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   19  292 6502 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   20  293 6503 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   21  294 6504 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   22  295 6505 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   23  296 6506 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   24  297 6507 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   25  298 6508 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   26  299 6509 -999.00 -999.00    0.00    0.00    4.28    0.65
 2017   10   27  300 6510 -999.00 -999.00    0.00    0.00    4.28    0.65
#+end_example

*** Qaanaaq

#+NAME: provenance_Qaanaaq
#+BEGIN_SRC bash :results verbatim
root=~/data.me/qaanaaq
md5sum ${root}/discharge2018.txt
head ${root}/discharge2018.txt
#+END_SRC

#+RESULTS: Provenance_Qaanaaq
#+begin_example

779a8d8c1296df98d41dcb990bf1f19b  /home/kdm/data.me/qaanaaq/discharge2018.txt
Time(UTC),Discharge(m^3/s)
2018/07/05 16:45:00,0.81
2018/07/05 16:50:00,0.8
2018/07/05 16:55:00,0.81
2018/07/05 17:00:00,0.8
2018/07/05 17:05:00,0.81
2018/07/05 17:10:00,0.82
2018/07/05 17:15:00,0.82
2018/07/05 17:20:00,0.82
2018/07/05 17:25:00,0.84
#+end_example

*** Leverett Glacier
#+NAME: provenance_Leverett
#+BEGIN_SRC bash :results verbatim
for f in $(ls ${DATADIR}/Tedstone_2017/leverett_Q_????_UTC.csv); do
  md5sum ${f}
done
echo " "
head -n15 ${f}
#+END_SRC

#+RESULTS: Provenance_Leverett
#+begin_example

> fbd61f2153544e7f47118ea5048c7f72  /home/kdm/data/Tedstone_2017/leverett_Q_2009_UTC.csv
b105d03e1654a8f282e6023d217e4411  /home/kdm/data/Tedstone_2017/leverett_Q_2010_UTC.csv
bf555e42f03590af778e23c63628c94d  /home/kdm/data/Tedstone_2017/leverett_Q_2011_UTC.csv
0af991e890bf8a06df16fff9e5270efd  /home/kdm/data/Tedstone_2017/leverett_Q_2012_UTC.csv

# River discharge, Leverett Glacier, Greenland, 2012
67°03'53.8"N 50°13'01.2"W
School of GeoSciences, University of Edinburgh
email: a.j.tedstone@bristol.ac.uk
column 1: Julian fractional day of year
column 2: river discharge, cubic metres per second
fill value: nan
DOY,Discharge m3 s-1
134.625,0.9
134.6285,1.0
134.6319,1.0
134.6354,1.0
134.6389,0.7
134.6424,1.0
134.6458,1.0
#+end_example


*** GEM
#+NAME: provenance_GEM
#+BEGIN_SRC bash :results verbatim
# ls ${DATADIR}/GEM
md5sum ${DATADIR}/GEM/GEM.csv
echo ""
head ${DATADIR}/GEM/GEM.csv
echo ""
tail ${DATADIR}/GEM/GEM.csv
#+END_SRC

#+RESULTS: provenance_GEM
#+begin_example

c8109aa54bb646dcf773406ce7ceb871  /home/kdm/data/GEM/GEM.csv

Date_Time,Kingigtorssuaq,Kobbefjord,Oriartorfik,Røde_Elv,Teqinngalip,Zackenberg
1996-06-02,,,,,,0.606
1996-06-03,,,,,,1.812
1996-06-04,,,,,,3.024
1996-06-05,,,,,,4.236
1996-06-06,,,,,,5.448
1996-06-07,,,,,,6.660
1996-06-08,,,,,,7.872
1996-06-09,,,,,,9.084
1996-06-10,,,,,,10.298

2018-09-17,0.375,,0.210,,0.710,2.283
2018-09-18,0.337,,0.185,,0.641,
2018-09-19,0.318,,0.170,,,
2018-09-20,0.307,,0.154,,,
2018-09-21,0.287,,0.139,,,
2018-09-22,0.269,,0.127,,,
2018-09-23,0.262,,0.132,,,
2018-09-24,0.248,,0.116,,,
2018-09-25,0.257,,0.106,,,
2018-09-26,0.233,,0.088,,,
#+end_example

*** Narsarsuaq

#+BEGIN_SRC bash
md5sum ${DATADIR}/Hawkings_2016/NarsarsuaqDischarge2013.xlsx
#+END_SRC

#+RESULTS:
: b7d649e6afdc7804353592df37e3a3d8  /home/kdm/data/Hawkings_2016/NarsarsuaqDischarge2013.xlsx

** Import Data
:PROPERTIES:
:header-args:bash+: :tangle import.sh :eval no
:END:

#+BEGIN_SRC bash :results verbatim
<<init>>
#+END_SRC

*** Masks
**** GIMP Ocean Mask
#+NAME: GIMP_0714
#+BEGIN_SRC bash :results verbatim
g.mapset -c GIMP_0714
r.in.gdal -o input=${DATADIR}/NSIDC/NSIDC-0714.001/1999.07.01/GimpOceanMask_90m_2000_v1.2.tif output=mask_ocean_lakes
# ocean mask has some cut-off oceans a.k.a lakes. See for example near -274731,-2747470.
g.region raster=mask_ocean_lakes

# Fill the lakes and treat as land.
r.null map=mask_ocean_lakes setnull=0 # only operate on ocean cells
r.clump input=mask_ocean_lakes output=clumps
main_clump=$(r.stats -c -n clumps sort=desc | head -n1 | cut -d" " -f1)
r.mapcalc "mask_ocean = if(clumps == ${main_clump}, 1, null())"
r.null mask_ocean null=0
#+END_SRC

**** Citterio 2013 Ice Mask
#+NAME: citterio_2013
#+BEGIN_SRC bash :results verbatim
g.mapset -c Citterio_2013

mkdir -p tmp

# fix bad shapefile that deosn't import directly into GRASS.
ogr2ogr -s_srs EPSG:4326 -t_srs EPSG:3413 ./tmp/PROMICE_3413 ${DATADIR}/Citterio_2013/PROMICE_250_2019-12-04_EPSG4326
v.in.ogr input=./tmp/PROMICE_3413 output=mask

g.region raster=mask_ocean@GIMP_0714
v.to.rast input=mask output=mask_ice_holes use=val val=1

# Everything should route to the coast, this means we need to fill in
# all the nunatuks so that there are no interior drainage basns.
r.mapcalc "not_ice = if(isnull(mask_ice_holes), 1, null())"
r.clump input=not_ice output=clumps
main_clump=$(r.stats -c -n clumps sort=desc | head -n1 | cut -d" " -f1) # ocean
r.mapcalc "mask_ice = mask_ice_holes ||| if(clumps != ${main_clump})"
r.null mask_ice null=0
#+END_SRC

*** ArcticDEM
#+BEGIN_SRC bash :results verbatim
log_info "Importing ArcticDEM"
g.mapset -c ArcticDEM

r.external source=${DATADIR}/ArcticDEM/arcticdem_mosaic_100m_v4.1_dem.tif output=arctic_raw # all arctic

g.region raster=mask_ocean@GIMP_0714 align=arctic_raw

g.region save=ArcticDEM
g.mapset PERMANENT
g.region region=ArcticDEM@ArcticDEM
g.region -sp # default location
g.mapset ArcticDEM

r.mapcalc "mask_land = if((mask_ice@Citterio_2013 == 0) && (mask_ocean@GIMP_0714 == 0), 1, 0)"

# set up mask: (o)cean=1 (l)and=2 (i)ce=3
r.mapcalc "mask_o_l_i_4 = (mask_ocean@GIMP_0714 + mask_land*2 + mask_ice@Citterio_2013*3)"
r.mapcalc "mask_o_l_i = if(mask_o_l_i_4 == 4, 1, mask_o_l_i_4)" # cleanup some multi-flagged as ocean.
r.mapcalc "z_s_ocean = arctic_raw" # subset and move from external to internal
r.null map=z_s_ocean null=0
r.mapcalc "z_s = if(mask_o_l_i == 1, null(), z_s_ocean)"

#+END_SRC


*** BedMachine v5
:PROPERTIES:
:CUSTOM_ID: import_BM5
:END:

#+BEGIN_SRC bash :results verbatim
log_info "Importing BedMachine"
g.mapset -c BedMachine

ROOT=${DATADIR}/Morlighem_2017

for var in mask surface thickness bed errbed geoid source; do
  echo $var
  r.in.gdal -o input="NetCDF:${DATADIR}/Morlighem_2017/BedMachineGreenland-v5.nc:"${var} output=${var}
done
g.rename raster=surface,z_s
g.rename raster=bed,z_b

g.region raster=z_s
g.region res=150 -pa
#+END_SRC

*** NSIDC 0713 Basemap
#+BEGIN_SRC bash :results verbatim
log_info "Importing NSIDC 0713"

g.mapset -c NSIDC_0713
g.region -d
r.external -o input=${DATADIR}/GIMP/0713/RGB.vrt output=rgb
#+END_SRC

*** Mouginot 2019

#+NAME: import_mouginot
#+BEGIN_SRC bash

log_info "Loading Mouginot 2019"

g.mapset -c Mouginot_2019
v.import input=${DATADIR}/Mouginot_2019/Greenland_Basins_PS_v1.4.2.shp output=basins snap=1
# v.to.rast input=basins output=basins use=cat label_column=NAME
# v.to.rast input=basins output=regions use=cat label_column=SUBREGION1
#+END_SRC

*** Zwally 2012

#+NAME: import_zwally
#+BEGIN_SRC bash

log_info "Loading Zwally 2012"

g.mapset -c Zwally_2012
v.import input=${DATADIR}/Zwally_2012/sectors output=sectors snap=1
# v.to.rast input=sectors output=sectors use=attr column=cat_
#+END_SRC


*** Other
**** Mankoff 2020 gates

+ According to "[[id:sec_new_this_version][New in this version]]" section, use doi:10.22008/promice/data/ice_discharge/gates/v02/UFW2WY 

#+BEGIN_SRC bash
g.mapset -c Mankoff_2020
log_info "Importing Mankoff 2020 gates"

mkdir -p tmp/Mankoff_2020_gates

dest=./tmp/Mankoff_2020_gates/gates.gpkg
if [[ ! -f ${dest} ]]; then
  wget "https://dataverse.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/promice/data/ice_discharge/gates/v02/UFW2WY" -O ${dest}
fi

md5sum ./tmp/Mankoff_2020_gates/*
# d28f4a1c4c72490dc83893c18352f579  ./tmp/Mankoff_2020_gates/gates.gpkg

v.in.ogr input=./tmp/Mankoff_2020_gates/gates.gpkg output=gates
v.db.select map=gates|head
#+END_SRC


**** Bjørk 2015 names

#+BEGIN_SRC bash
g.mapset -c Bjork_2015
log_info "Importing Bjørk 2015 names"

# ogr2ogr -f "ESRI Shapefile" -t_srs EPSG:3413 EPSG_3413 GreenlandGlacierNames_GGNv01_WGS84.shp 
v.in.ogr input=${DATADIR}/Bjørk_2015/EPSG_3413/ output=names
v.db.select map=names|head
#+END_SRC

#+RESULTS:
| cat | ID      |     LAT |      LON | New_Greenl            | Old_Greenl              | Foreign_na | Official_n            | Alternativ | RGI_ID         | GLIMS_ID       |  RGI_LON | RGI_LAT | Type |
|   1 | GGN0001 | 60.1166 |   -43.37 | Sermeq Kujalleq       | Sermeq Kujatdleq        |            | Sermeq Kujalleq       |            | RGI40-05.04361 | G316578E60159N | -43.4217 | 60.1593 | LGIC |
|   2 | GGN0002 | 60.1349 | -43.5125 | Sermeq Avannarleq     | Sermeq Avangnardleq     |            | Sermeq Avannarleq     |            | RGI40-05.04363 | G316482E60158N | -43.5182 | 60.1584 | LGIC |
|   3 | GGN0003 | 60.1627 | -43.7278 | Sermikasik Avannarleq | Sermikasik Avangnardleq |            | Sermikasik Avannarleq |            | RGI40-05.04356 | G316285E60178N | -43.7154 | 60.1779 | LGIC |
|   4 | GGN0004 | 60.1639 | -43.7038 | Sermikasik Kujalleq   | Sermikasik Kujatdleq    |            | Sermikasik Kujalleq   |            | RGI40-05.04356 | G316285E60178N | -43.7154 | 60.1779 | LGIC |
|   5 | GGN0005 | 60.2171 |  -43.337 | Sermeq Avannarleq     | Sermeq Avangnardleq     |            | Sermeq Avannarleq     |            | RGI40-05.04332 | G316577E60220N | -43.4229 | 60.2199 | LGIC |
|   6 | GGN0006 | 60.2352 | -43.2644 | Sermeq Qeqqarleq      | Sermeq Qerqardleq       |            | Sermeq Qeqqarleq      |            | RGI40-05.04331 | G316702E60261N |  -43.298 | 60.2613 | LGIC |


**** x and y in permanent mapset
#+BEGIN_SRC bash :results verbatim
<<xy_permanent>>
#+END_SRC

**** Bamber 2018

This is just for the outlines on the Disko island figure.

Sum a bunch of the data, then assume wherever it is not 0 is an outlet grid cell.

#+BEGIN_SRC bash
g.mapset -c Bamber_2018
FILE=${DATADIR}/Bamber_2018/FWF17.v3_a.nc

cdo -v -b F32 timsum ${FILE} ./tmp/B2018.nc # timcumsum?
r.external source=netcdf:./tmp/B2018.nc:runoff_ice output=ice # band=707
r.external source=netcdf:./tmp/B2018.nc:runoff_tundra output=tundra # band=707

r.mask -r
r.mapcalc "MASK = if(ice == 0, null(), 1)" --o
r.to.vect input=ice output=ice type=area
r.mask -r
r.mapcalc "MASK = if(tundra == 0, null(), 1)" --o
r.to.vect input=tundra output=tundra type=area
r.mask -r
#+END_SRC

* Quality control                                       :noexport:
:PROPERTIES:
:header-args: :tangle no
:header-args:bash+: :tangle no :eval no
:header-args:jupyter-python+: :tangle no
:END:
** Streams, Outlets, and Basins
*** Compare streams and outlets with Google Earth    :noexport:QC:

Data are too large for Google Earth (app), but using Google Earth tiles in QGIS works fine.

See [[./freshwater.qgz]] and add one or more of the following to QGIS Tile Server (XYZ)

Google Maps: https://mt1.google.com/vt/lyrs=r&x={x}&y={y}&z={z}
Google Satellite: http://www.google.cn/maps/vt?lyrs=s@189&gl=cn&x={x}&y={y}&z={z}
Google Satellite Hybrid: https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}
Google Terrain: https://mt1.google.com/vt/lyrs=t&x={x}&y={y}&z={z}
Bing Aerial: http://ecn.t3.tiles.virtualearth.net/tiles/a{q}.jpeg?g=1

*** Find lakes and compare w/ Google Earth           :noexport:QC:

#+BEGIN_SRC bash :results verbatim :eval no
g.mapset -c lakes
r.fill.dir input=head@land_surf output=filled direction=dir areas=problems format=grass
r.mapcalc "lakes = if(filled - head@land_surf > 0.0, 1, null() )"
r.to.vect input=lakes output=lakes type=area
#+END_SRC

Then load in QGIS

*** Land outlet elevations

+ All land outlets should be at 0 m, or within ArcticDEM uncertainty.
+ Some other elevations may exist because masks are not aligned.
+ In reality, outlets could exist at high elevations if they enter the ocean via waterfall from a cliff. See for example outlets at the edge of Petermann fjord.

TODO: Weight by runoff

#+BEGIN_SRC jupyter-python
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib
from matplotlib import rc

rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(211)

df = pd.read_csv("./freshwater/ice_100/outlets.csv")
df['elev'].plot.hist(bins = 100,
                     alpha = 0.5,
                     bottom = 0.1,
                     color = 'b',
                     label="Ice",
                     ax = ax)

df = pd.read_csv("./freshwater/land_100/outlets.csv")
df['elev'].plot.hist(bins = 100,
                     alpha = 0.5,
                     bottom = 0.1,
                     color = 'g',
                     label="Land",
                     ax = ax)

ax.set_yscale("log")    
ax.set_xlabel("Outlet elevation [m]")
ax.set_ylabel("Count")
ax.set_yticks([1E0,1E1,1E2,1E3,1E4])

ax2 = fig.add_subplot(212)

mm = df['elev'].abs().max()
h,b = np.histogram(df['elev'].abs().values,
                   bins=mm)
ax2.plot(b[1:], np.cumsum(h),
         alpha = 0.5,
         label="Land",
         color = 'g')


# mm = df['elev'].max()
# h,b = np.histogram(df[df['elev'] >= 0]['elev'].values,
#                    bins=mm)
# ax2.plot(b[1:], np.cumsum(h),
#          alpha = 0.5,
#          linestyle = '--',
#          label="Land > 0",
#          color = 'g')

# # ax2.set_xlim([0.1,mm])
ax2.set_ylim([1E0,3.1E4])
ax2.set_yticks([0,1E4,2E4,3E4])
ax2.set_xlim([1,1000])
# ax2.set_yscale("log")
ax2.set_xscale("log")
# ax2.set_yticks([1E0,1E1,1E2,1E3,1E4,1E5])

ax2.set_ylabel("Cumulative\ncounts")
ax2.set_xlabel("Elevation [m]")

ax.legend()
# ax2.legend(loc=4)

from adjust_spines import adjust_spines as adj
adj(ax, ['left','bottom'])
adj(ax2, ['left','bottom'])

df = pd.DataFrame()
df['Elevation [m]'] = np.append(np.arange(10), np.arange(10, 101, 10))
df.set_index('Elevation [m]', inplace=True)
df['CDF [%]'] = cumsum(h)[df.index] / cumsum(h).max() * 100

plt.savefig('./fig/outlet_elevation_histogram_cdf.png', transparent=True, bbox_inches='tight', dpi=300)

df
# (cumsum(h)[0:100+1:10])/cumsum(h).max()
#+END_SRC

#+RESULTS:
| Elevation [m] |  CDF [%] |
|---------------+----------|
|             0 | 0.200127 |
|             1 |  39.3483 |
|             2 |  45.9024 |
|             3 |  51.4292 |
|             4 |  56.6392 |
|             5 |  61.2721 |
|             6 |  65.2647 |
|             7 |  68.5634 |
|             8 |  71.4352 |
|             9 |  73.9168 |
|            10 |  76.0015 |
|            20 |  86.0745 |
|            30 |  89.8769 |
|            40 |   92.055 |
|            50 |  93.5259 |
|            60 |  94.5566 |
|            70 |  95.3604 |
|            80 |  95.9841 |
|            90 |  96.5078 |
|           100 |  96.9147 |

#+CAPTION: 
#+ATTR_LATEX: :width 0.8\textwidth
#+RESULTS:

** Outputs
*** Check CF compliance
#+NAME: cf_check
#+BEGIN_SRC bash :results verbatim :eval no-export :exports both
conda activate freshwater
cfchecks ./freshwater/land/runoff/MAR_2000.nc
#+END_SRC

#+RESULTS: cf_check
#+begin_example

CHECKING NetCDF FILE: ./freshwater/land/runoff/MAR_2000.nc
=====================
Using CF Checker Version 4.0.0
Checking against CF Version CF-1.7
Using Standard Name Table Version 76 (2020-10-13T12:38:27Z)
Using Area Type Table Version 10 (23 June 2020)
Using Standardized Region Name Table Version 4 (18 December 2018)


------------------
Checking variable: station
------------------
WARN: (3.1): units attribute should be present

------------------
Checking variable: time
------------------

------------------
Checking variable: runoff
------------------

------------------
Checking variable: lat
------------------

------------------
Checking variable: lon
------------------

------------------
Checking variable: alt
------------------

ERRORS detected: 0
WARNINGS given: 1
INFORMATION messages: 0
#+end_example

*** NetCDF header
#+NAME: netcdf-header-one-file
#+BEGIN_SRC bash :results verbatim :eval no-export :exports both
ncdump -chs ./freshwater/land/runoff/MAR_2000.nc
#+END_SRC

#+RESULTS: netcdf-header-one-file
#+begin_example
netcdf MAR_2000 {
dimensions:
	time = UNLIMITED ; // (366 currently)
	station = 29635 ;
variables:
	uint64 station(station) ;
		station:long_name = "outlet id" ;
		station:cf_role = "timeseries_id" ;
		station:_Storage = "contiguous" ;
		station:_Endianness = "little" ;
	int64 time(time) ;
		time:long_name = "time of measurement" ;
		time:standard_name = "time" ;
		time:axis = "T" ;
		time:units = "days since 2000-01-01 00:00:00" ;
		time:calendar = "proleptic_gregorian" ;
		time:_Storage = "chunked" ;
		time:_ChunkSizes = 512 ;
		time:_Endianness = "little" ;
	double runoff(station, time) ;
		runoff:_FillValue = NaN ;
		runoff:long_name = "MAR runoff" ;
		runoff:standard_name = "water_volume_transport_in_river_channel" ;
		runoff:units = "m3 s-1" ;
		runoff:coordinates = "lat lon alt station" ;
		runoff:_Storage = "chunked" ;
		runoff:_ChunkSizes = 29635, 1 ;
		runoff:_DeflateLevel = 2 ;
		runoff:_Shuffle = "true" ;
		runoff:_Endianness = "little" ;
	float lat(station) ;
		lat:_FillValue = NaNf ;
		lat:long_name = "latitude" ;
		lat:standard_name = "latitude" ;
		lat:units = "degrees_north" ;
		lat:axis = "Y" ;
		lat:_Storage = "contiguous" ;
		lat:_Endianness = "little" ;
	float lon(station) ;
		lon:_FillValue = NaNf ;
		lon:long_name = "longitude" ;
		lon:standard_name = "longitude" ;
		lon:units = "degrees_east" ;
		lon:axis = "X" ;
		lon:_Storage = "contiguous" ;
		lon:_Endianness = "little" ;
	float alt(station) ;
		alt:_FillValue = NaNf ;
		alt:long_name = "height_above_mean_sea_level" ;
		alt:standard_name = "altitude" ;
		alt:units = "m" ;
		alt:positive = "up" ;
		alt:axis = "Z" ;
		alt:_Storage = "contiguous" ;
		alt:_Endianness = "little" ;

// global attributes:
		:featureType = "timeSeries" ;
		:title = "Greenland runoff" ;
		:summary = "Greenland RCM runoff at basin outlets" ;
		:keywords = "Hydrology; Greenland; Runoff; Freshwater" ;
		:Conventions = "CF-1.7" ;
		:source = "git commit: 29aa681" ;
		:creator_name = "Ken Mankoff" ;
		:creator_email = "kdm@geus.dk" ;
		:creator_url = "http://kenmankoff.com" ;
		:institution = "GEUS" ;
		:references = "10.22008/promice/freshwater" ;
		:product_version = 1. ;
		:_NCProperties = "version=2,netcdf=4.7.4,hdf5=1.10.5" ;
		:_SuperblockVersion = 0 ;
		:_IsNetcdf4 = 1 ;
		:_Format = "netCDF-4" ;
}
#+end_example

*** Annual sums agree?

Yes, within ~0.3 %.

#+BEGIN_SRC jupyter-python :eval no
import xarray as xr
import glob as glob
import pandas as pd

df[80] = xr.open_mfdataset(glob.glob("./freshwater/ice_80/runoff/MAR_*.nc"), combine='by_coords')\
           .resample({'time':'A'})\
           .sum()\
           .sum(dim='station')['runoff']\
           .to_dataframe()\
           .values

df[90] = xr.open_mfdataset(glob.glob("./freshwater/ice_90/runoff/MAR_*.nc"), combine='by_coords')\
           .resample({'time':'A'})\
           .sum()\
           .sum(dim='station')['runoff']\
           .to_dataframe()\
           .values

df[100] = xr.open_mfdataset(glob.glob("./freshwater/ice_100/runoff/MAR_*.nc"), combine='by_coords')\
           .resample({'time':'A'})\
           .sum()\
           .sum(dim='station')['runoff']\
           .to_dataframe()\
           .values

df['range'] = df.max(axis='columns') - df.min(axis='columns')
df['%'] = df['range'] / df.max(axis='columns') * 100

df.describe()
#+END_SRC

* Supplemental material                                 :noexport:
:PROPERTIES:
:header-args:bash+: :eval no
:header-args:jupyter-python+: :eval no
:END:
** Coverage
:PROPERTIES:
:CUSTOM_ID: supplemental:coverage
:END:
*** Introduction

The 1) MAR and RACMO models, 2) basins based on the GIMP surface, and 3) reality, are not always correctly aligned. Misalignment includes the following:

#+NAME: tab:misalignment
| Reality | Basin   | Model   | Comment |
|---------+---------+---------+---------|
| Glacier | Glacier | Glacier | aligned |
| Land    | Land    | Land    | aligned |
|---------+---------+---------+---------|
| Glacier | Glacier | Land    |         |
| Glacier | Land    | Glacier |         |
| Glacier | Land    | Land    |         |
| Land    | Land    | Glacier |         |
| Land    | Glacier | Land    |         |
| Land    | Glacier | Glacier |         |

We ignore "Reality" and treat the basin output as the standard, which reduces Table [[tab:misalignment]] to just two cases where basins and model disagree, with the following effects:

1) Where basin = glacier and model = land, glacier runoff is lost
2) Where basin = land and model = glacier, land runoff is lost

#+NAME: coverage_report
#+BEGIN_SRC bash :results none :exports none :var mapset="coverage_report" :eval no
<<grass_init_mapset>>
g.mapset -c coverage_report --q
g.region -d

g.copy raster=MSK@MAR,model
r.category --q map=model separator=: rules=- << EOF
0:model fjord
1:model land
2:model ice
EOF

r.mapcalc "land = if(basins@land_100)"
r.mapcalc "ice = if(basins@ice_100)"

echo "1:land" | r.category --q map=land separator=: rules=-
echo "1:ice" | r.category --q map=ice separator=: rules=-


r.report -i --q -h units=k map=land,model > ./tmp/coverage_report
r.report -i --q -h units=k map=ice,model >> ./tmp/coverage_report
#+END_SRC

#+NAME: coverage_report
#+BEGIN_SRC bash :results drawer :exports results :eval no-export
cat ./tmp/coverage_report
#+END_SRC

#+RESULTS: coverage_report
:results:
+-----------------------------------------------------------------------------+
|                      Category Information                        |  square  |
|description                                                     |kilometers|
|-----------------------------------------------------------------------------|
|1|land                                                            |   361,950|
| |----------------------------------------------------------------|----------|
| |0|model fjord. . . . . . . . . . . . . . . . . . . . . . . . . .|       717|
| |1|model land . . . . . . . . . . . . . . . . . . . . . . . . . .|   339,749|
| |2|model ice. . . . . . . . . . . . . . . . . . . . . . . . . . .|    21,484|
|------------------------------------------------------------------|----------|
|*|no data                                                         | 3,676,860|
| |----------------------------------------------------------------|----------|
| |0|model fjord. . . . . . . . . . . . . . . . . . . . . . . . . .| 1,863,957|
| |1|model land . . . . . . . . . . . . . . . . . . . . . . . . . .|    51,532|
| |2|model ice. . . . . . . . . . . . . . . . . . . . . . . . . . .| 1,761,221|
| |*|no data. . . . . . . . . . . . . . . . . . . . . . . . . . . .|       150|
|-----------------------------------------------------------------------------|
|TOTAL                                                             | 4,038,810|
+-----------------------------------------------------------------------------+
+-----------------------------------------------------------------------------+
|                      Category Information                        |  square  |
|description                                                     |kilometers|
|-----------------------------------------------------------------------------|
|1|ice                                                             | 1,781,816|
| |----------------------------------------------------------------|----------|
| |0|model fjord. . . . . . . . . . . . . . . . . . . . . . . . . .|        27|
| |1|model land . . . . . . . . . . . . . . . . . . . . . . . . . .|    20,876|
| |2|model ice. . . . . . . . . . . . . . . . . . . . . . . . . . .| 1,760,912|
|------------------------------------------------------------------|----------|
|*|no data                                                         | 2,256,994|
| |----------------------------------------------------------------|----------|
| |0|model fjord. . . . . . . . . . . . . . . . . . . . . . . . . .| 1,864,647|
| |1|model land . . . . . . . . . . . . . . . . . . . . . . . . . .|   370,404|
| |2|model ice. . . . . . . . . . . . . . . . . . . . . . . . . . .|    21,793|
| |*|no data. . . . . . . . . . . . . . . . . . . . . . . . . . . .|       150|
|-----------------------------------------------------------------------------|
|TOTAL                                                             | 4,038,810|
+-----------------------------------------------------------------------------+
:end:

We adjust the model results to the basin in the following ways. For speed, the following is done once using a basin and model mask, not using the daily values. A coverage factor is calculated one time, and then used as a daily multiplier later in the workflow.

Where a basin reports ice and the model reports land, we divide the daily runoff values of the basin cells that do have model ice by the ratio of the total basin area to the area with ice (with runoff data). That is, the model land runoff is discarded, and the nearby model ice runoff is scaled to compensate for the uncovered basin cells. For example, if an ice basin is 90 % covered by model ice, model runoff is divided by 0.9 to scale it to an estimate of what 100 % runoff would be. This scenario occurs frequently at the ice margin because the 1 km^{2} model grid cell rarely matches 90 m^{2} basin boundary. It also occurs wherever nunatuks exist, because ice sheet interior "holes" are filled, otherwise they act as interior drains that block large areas from routing to the coast, something unlikely to occur in reality. When a small basin has no model cells covering any part of it, that basin never has any reported runoff. 

Where a basin reports land and the model reports ice, the same treatment as above is performed, but for land. That is, the model ice runoff is discarded, and the nearby model land runoff is scaled to compensate for the uncovered basin cells. As above, this occurs frequently at the ice margin for the same reason. Large areas of model ice (and reality ice) are occasionally reported over land basins where outlet glaciers are not properly captured in the model masks (FIGURE near UAK).

Where the model mask reports ocean, no basins exist and model runoff, both land and ice, are discarded. Large amounts of real ocean and fjord locations are classified as land in the MAR model mask variable.

The above means that model runoff is not conserved. 

*** Algorithm                                           :noexport:
:PROPERTIES:
:ID:       f4817a3a-ba97-45b3-8c46-1894f75e91a4
:END:
**** Test Manual
Scale the model area covering each basin so that it equals the basin area.

First, lets test this - some visual examination
#+BEGIN_SRC bash :results verbatim :tangle no :session foo
rm -fR ./G/test_coverage
grass -c ./G/test_coverage

g.mapset -c coverage_test
g.region -d
r.mask -r

# pick one and zoom in
r.mapcalc "land_basin = if(basins@ice_surf == 353, 353, null())"  --q --o
r.colors map=land_basin color=green
r.mapcalc "ice_basin = if(basins@ice_surf == 12, 12, null())"  --q --o
r.colors map=ice_basin color=water

g.region zoom=land_basin --q

d.mon start=wx0
d.erase
d.rast land_basin
d.rast ice_basin
# # check if model ice exists here
d.rast mask_ice_MAR@MAR # yes

r.report --q -h map=ice_basin,mask_ice_MAR@MAR units=k | grep -A4 "|12|"
# SAME -> setting mask not needed for ice.

g.region zoom=land_basin --q
r.report --q -h map=land_basin,mask_land_MAR@MAR units=k | grep -A4 "|353|"

g.region zoom=land_basin --q
r.report --q -h map=ice_basins@land_surf,mask_ice_MAR@MAR units=k | grep -A4 "|353|"

# coverage report
r.report --q -h map=basins@land_surf,mask_ice_MAR@MAR units=k
#+END_SRC


Generate a test file

#+BEGIN_SRC bash :results verbatim :tangle no
grass -c ./G/test_coverage
r.report --q -h map=basins@ice_surf,mask_ice_MAR@MAR units=k | head -n 100
r.stats --q -aN input=basins@ice_surf,mask_ice_MAR@MAR separator=,  > ./tmp/coverage_test.csv
exit
#+END_SRC

#+RESULTS:

Compute coverage

#+BEGIN_SRC jupyter-python :session coverage_test :exports results :results raw drawer :eval no
import numpy as np
import pandas as pd

df_raw = pd.read_csv("./tmp/coverage_test.csv", index_col=0, names=["c_or_uc", "area"])
df_raw = df_raw.drop(df_raw[df_raw.index == '*'].index)
df_raw.index = df_raw.index.astype(int)

df_c = df_raw[df_raw['c_or_uc'] == '1']\
    .drop(labels='c_or_uc', axis='columns')\
    .rename({'area':'covered'}, axis='columns')

df_uc = df_raw[df_raw['c_or_uc'] == '*']\
    .drop(labels='c_or_uc', axis='columns')\
    .rename({'area':'uncovered'}, axis='columns')

df = df_c.merge(df_uc, how='outer', left_index=True, right_index=True)\
         .sort_index()\
         .fillna(0)

df['coverage'] = df['covered'] / (df['covered'] + df['uncovered'])

# If we take the model area, divide by coverage, is it equal to the basin area?
# df['test'] = ((df['covered']+df['uncovered']) - (df['covered']/df['coverage'])) < 0.001
# some tests are False because coverage is 0: df[df['test'] == False].coverage.sum()

df.head(30)
#+END_SRC

**** Solution

The key line is:

#+BEGIN_SRC bash :results none :eval no
r.stats --q -aN input=basins@ice_surf,mask_ice_MAR@MAR separator=,  > ./tmp/coverage_test.csv
#+END_SRC

In the main processing loop, I'll add a line like:

#+BEGIN_SRC bash :results none :eval no
r.stats --q -aN input=basins@<MAPSET>,mask_<domain>_<model>@<model> separator=,  \
	> ./tmp/coverage_<mapset>_<domain>_<model>.csv
#+END_SRC

And then in post-processing I will calculate coverage and apply it to each basin.

*** Figure

#+BEGIN_SRC bash :results verbatim
g.mapset -c test_alignment

g.region n=-3227490 s=-3253500 w=7110 e=48960 res=90 -pa align=mask_ice_basin@MAR
g.region save=test --o

# MAR grid to this mapset and region subset
r.to.vect input=mask_ice_MAR@MAR output=MAR_grid_ice type=area
r.to.vect input=mask_land_MAR@MAR output=MAR_grid_land type=area

# MAR grid centers at MAR res to this mapset and region subset
g.region res=1000 -p
r.to.vect input=mask_ice_MAR@MAR output=MAR_grid_ice_point type=point
r.to.vect input=mask_land_MAR@MAR output=MAR_grid_land_point type=point
g.region region=test -p

d.mon start=wx1
d.erase

d.vect basins@land_surf fill_color=178:223:138 color=100:100:100 legend_label="Land Basin"
d.vect basins@ice_surf fill_color=166:206:227 color=100:100:100 legend_label="Ice Basin" 
# d.vect outlets@land_surf fill_color=green icon=basic/circle size=7 legend_label="Ice Outlet"
# d.vect outlets@ice_surf fill_color=blue icon=basic/circle size=7 legend_label="Land Outlet"

d.vect MAR_grid_ice fill_color=none color=black width=3 legend_label="MAR Ice/Land Boundary"
d.vect MAR_grid_ice_point icon=basic/box color=black fill_color=blue size=3 legend_label="MAR Ice Cell"
d.vect MAR_grid_land_point icon=basic/box color=black fill_color=green size=3 legend_label="MAR Land Cell"
#+END_SRC

NOTE - better figure generated in QGIS, but using the data created above. See [[./fig/alignment.qgz]] and output ./fig/basin_MAR_align.png

#+BEGIN_SRC bash :results verbatim
ps.map -e input=./tmp/basin_MAR_align.psmap output=./fig/basin_MAR_align.eps --o
convert -trim -density 300 ./fig/basin_MAR_align.eps ./fig/basin_MAR_align.png
o ./fig/basin_MAR_align.png
#+END_SRC
#+RESULTS:

#+NAME: basin_MAR_align_psmap
#+BEGIN_SRC bash :results verbatim :tangle ./tmp/basin_MAR_align.psmap :mkdirp tmp
border n
# scale 1:1000000
paper a4
  end

vareas MAR_grid_ice
  color black
  pat $GISBASE/etc/paint/patterns/diag_down.eps
  scale 1
  fcolor 55:126:184
  width 1
  label "MAR ice"
  end

vareas MAR_grid_land
  color black
  pat $GISBASE/etc/paint/patterns/diag_up.eps
  scale 1
  fcolor 51:160:44
  width 1
  label "MAR land"
  end

# hatch fill
vareas basins@ice_surf
  # pat $GISBASE/etc/paint/patterns/diag_up.eps
  # scale 0.5
  # fcolor 55:126:184
  color 55:126:184
  # fcolor 166:206:227
  fcolor 240:240:240
  label "Basin ice"
  end

# vareas basins@ice_surf
#   color 55:126:184
#   fcolor 166:206:227
#   end

vareas basins@land_surf
  color 51:160:44
  fcolor 127:223:138
  label "Basin land"
  end

# # crosses on land
# vpoints MAR_grid_land_point
#   type point
#   color 51:160:44
#   scale 3
#   # see ${GISBAS}/etc/symbol/basic/
#   symbol basic/x
#   label "Model Land Grid Cell"
#   end

vlegend
  where 5.7 1.1
  fontsize 14
  end

scalebar f
   length 4
   units kilometers
   segment 2
   where 1 5
   fontsize 14
   end
#+END_SRC


#+NAME: fig:alignment
#+ATTR_LATEX: :width \textwidth :placement [!h]
#+CAPTION: Example region near southren Greenland showing 90 m basin delineation and 1000 m model boundary. Basins are delineated by gray line and classified as ice (blue) and land (green). Model ice/land boundary is delineated by black line and cells are classified by a small blue (ice) or green (land) box at cell center.
[[./fig/basin_MAR_align.png]]



* Figures
:PROPERTIES:
:clearpage: t    
:header-args:bash+: :eval no :session :tangle no
:header-args:jupyter-python+: :eval no :tangle no
:END:

# %% ONE-COLUMN FIGURES
# %\begin{figure}[t]
# %\includegraphics[width=8.3cm]{FILE NAME}
# %\caption{TEXT}
# %\end{figure}
# %
# %%% TWO-COLUMN FIGURES
# %\begin{figure*}[t]
# %\includegraphics[width=12cm]{FILE NAME}
# %\caption{TEXT}
# %\end{figure*}


** Overview

#+BEGIN_SRC jupyter-python :var obs_xy=tbl_obs_xy_cache
<<py_init>>
<<py_init_graphics>>

import geopandas as gp
from shapely.geometry import Point

import matplotlib
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(8,11)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)

if 'land' not in locals():
    land = (gp.read_file("./freshwater/land_100/outlets.gpkg").set_index("cat"))\
        .merge(gp.read_file("./freshwater/land_100/basins_filled.gpkg").set_index("cat"), left_index=True, right_index=True)\
        .rename(columns={"geometry_x":"outlet", "geometry_y":"basin"})\
        .set_geometry('basin')

    ice = (gp.read_file("./freshwater/ice_100/outlets.gpkg").set_index("cat"))\
        .merge(gp.read_file("./freshwater/ice_100/basins.gpkg").set_index("cat"), left_index=True, right_index=True)\
        .rename(columns={"geometry_x":"outlet", "geometry_y":"basin"})\
        .set_geometry('basin')

kw = {'ax':ax, 'linewidth':0.3}
land.plot(color=C_lightgreen, edgecolor=C_darkgreen, **kw)
ice[ice.elev > -10].plot(color=(0.8, 0.8, 0.8), edgecolor=C_darkblue, **kw)
ice[ice.elev <= -10].plot(color=C_lightblue, edgecolor=C_darkblue, **kw)

from matplotlib_scalebar.scalebar import ScaleBar
ax.add_artist(ScaleBar(1))

gdf = gp.GeoDataFrame(obs_xy, columns=['abbrev','x','y'], crs="EPSG:3413").set_index("abbrev")
gdf['geometry'] = [Point(x,y) for x,y in zip(gdf['x'],gdf['y'])]

import matplotlib.patheffects as pe
kw = {'color':'k', 'path_effects':[pe.withStroke(linewidth=4, foreground="white")]}

for obs in gdf.index:
    basin = land[land.contains(gdf.loc[obs].geometry)].geometry
    if obs == 'L':
        basin = ice[ice.contains(gdf.loc[obs].geometry)].geometry
    box = basin.envelope.scale(1.1, 1.1)
    box.plot(ax=ax, color='none', edgecolor='k')
    xy = box.iloc[0].exterior.coords.xy
    x,y = xy[0][-2], xy[1][-2]

    
    txt=obs
    # if obs == 'L': txt = ''
    # if obs == 'W': 
    #     txt = 'W & L'
    #     ax.text(x-35000,y+12000, txt, horizontalalignment='left', **kw)
    if obs not in ['K','Kb','O']:
        ax.text(x-3000,y+5000, txt, horizontalalignment='right', **kw)
    else: # obs in ['K','Kb','O']:
        if obs == 'K':
            x,y = xy[0][-1], xy[1][-1]
            ax.text(x-3000,y-5000, txt, horizontalalignment='right', verticalalignment='top', **kw)
        if obs == 'O':
            x,y = xy[0][2], xy[1][2]
            ax.text(x+3000,y+5000, txt, horizontalalignment='left', verticalalignment='bottom', **kw)
        if obs == 'Kb':
            x,y = xy[0][1], xy[1][1]
            ax.text(x+3000,y-5000, txt, horizontalalignment='left', verticalalignment='top', **kw)

plt.axis('off')

plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)
plt.margins(0,0)
plt.gca().xaxis.set_major_locator(plt.NullLocator())
plt.gca().yaxis.set_major_locator(plt.NullLocator())
plt.savefig("./fig/overview.png", bbox_inches='tight', dpi=300, pad_inches=0)
#+END_SRC

#+RESULTS:

#+NAME: fig:overview
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Map of Greenland showing all basins and the location of 10 gauged streams used for comparison. Land basins are shown in green. Ice basins are shown in blue when outlet elevation < 0, and gray when outlet elevation >= 0 (outlet error elevation is discussed in Sect. \ref{sec:QC}). Black boxes and labels mark the location of stream gauge observation locations (see Table  \ref{tbl_obs}).
[[./fig/overview.png]]


** Basin changes with changing k
:PROPERTIES:
:header-args:bash+: :tangle k_basin_change.sh
:header-args:bash+: :comments both
:header-args:bash+: :tangle-mode (identity #o544)
:header-args:bash+: :shebang #!/usr/bin/env bash
:clearpage: t
:END:

#+NAME: fig:k_basin_change
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Map of Greenland showing maximum of all possible distances among outlet cell locations for all upstream cells, based on three effective basal pressure regimes (\(k \in [0.8, 0.9, 1.0]\), Eq \ref{eq:head}). Contour line shows 1500 m elevation contour - most runoff occurs below this elevation.
[[./fig/ice_max_class.png]]


*** Notes                                               :noexport:
+ To find out how much each upstream cell moved between two basin delineations, B0 and B1...
  + For each outlet in B0 and B1 get the x and y coordinate and the outlet ID (same as the basin ID).
  + Build four raster maps, B0_x, B0_y, B1_x, B1_y, where each cell in x(y) has the x(y) coordinate of the outlet for that cell.
  + Distance in outlet location is then sqrt((B0_x - B1_x)^2 + (B0_y - B1_y)^2) for each cell.
+ When comparing many (n) basin delineations, each cell has n (x,y) possible outlet locations.
  + Calculate mean_x, mean_y for each cell from n (x,y) possibilities
  + Then calculate average/max/std distance for each cell from the n (x,y) to the mean.
  + Then, one map captures n possible delineations

*** Generate difference maps for different basins       :noexport:

#+BEGIN_SRC bash :results verbatim
<<init>>
#+END_SRC

**** Extract the x and y coordinates of each outlet
#+BEGIN_SRC bash :results verbatim
g.mapset -c k_basin_change

log_info "Exporting outlet coordinates"

mapsets=$(g.mapsets -l separator="\n" | grep -E "^ice_*")
parallel --bar "r.out.xyz input=outlets@{1} | awk -F'|' '{print \$3, \$1}' > ./tmp/outlets_{1}_x" ::: ${mapsets}
parallel --bar "r.out.xyz input=outlets@{1} | awk -F'|' '{print \$3, \$2}' > ./tmp/outlets_{1}_y" ::: ${mapsets}
#+END_SRC

**** Basins map where pixel encodes the x and y coordinate of its outlet

+ First encode the outlet location as the category information of each basin, rather than as the value for each (x,y) cell.
  + This means we encode n basin bits of info (20,000?) rather than n grid cells bits of info (4.5M?)
+ Then create new rasters where the grid cells contain the outlet info directly. Easier for math further down in the code.

#+BEGIN_SRC bash :results verbatim

log_info "Encoding outlet coordinates"

coord="x y"
parallel --bar "g.copy basins@{1},cat_{1}_{2}" ::: ${mapsets} ::: ${coord}
parallel --bar "r.category map=cat_{1}_{2} rules=./tmp/outlets_{1}_{2} separator=space" ::: ${mapsets} ::: ${coord}
parallel --bar "r.mapcalc '{1}_{2} = @cat_{1}_{2}'" ::: ${mapsets} ::: ${coord}

#+END_SRC


*** More complex stats in Python                        :noexport:
**** Export to CSV

#+BEGIN_SRC bash :results verbatim

log_info "Exporting cells..."
log_warn "Reducing resolution."

LIST=$(g.list type=raster pattern='^[i|l][ceand]*_*[x|y]$' separator=,)
echo "x,y,${LIST}" | tr "," "|" > ./tmp/cells_xy.bsv
g.region res=1000 -a
r.out.xyz input=${LIST} output=- >> ./tmp/cells_xy.bsv
g.region -d


LIST=ice_100_x,ice_100_y,ice_80_x,ice_80_y,ice_90_x,ice_90_y,z_s@ArcticDEM
echo "x,y,${LIST}" | tr "," "|" > ./tmp/cells_elev.bsv
g.region res=1000 -a
r.out.xyz input=${LIST} output=- >> ./tmp/cells_elev.bsv
g.region -d
#+END_SRC


**** Import & process in Python

#+BEGIN_SRC jupyter-python :tangle k_basin_change.py
import pandas as pd
import numpy as np

df_xy = pd.read_csv("./tmp/cells_xy.bsv", delimiter="|", usecols=['x','y']).astype(int)

header = pd.read_csv("./tmp/cells_xy.bsv", delimiter="|", nrows=1)
cols_in = header.columns[['ice' in _ for _ in header.columns]]
df = pd.read_csv("./tmp/cells_xy.bsv", delimiter="|", usecols=cols_in)

multi_hdr = [np.array([_.split("_")[1] for _ in cols_in]).astype(int), 
             [_.split("_")[2] for _ in cols_in]]
df.columns = pd.MultiIndex.from_arrays(multi_hdr, names=['k','coord'])

k = np.unique(multi_hdr[0])

for kk in k:

    # mean distance for this k =
    # all other columns minus this column squared for x
    # also for y
    # square root of all that
    # take the mean of all columns

    df[(kk,'avg_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).mean(axis='columns')

    # same for max, except last step

    df[(kk,'max_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).max(axis='columns')

    # df[(kk,'std_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).std(axis='columns')

df_out = pd.DataFrame()
df_out['avg_avg'] = df.xs('avg_dist', level='coord', axis='columns').mean(axis='columns')
# df_out['avg_max'] = df.xs('max_dist', level='coord', axis='columns').mean(axis='columns')
# df_out['avg_std'] = df.xs('std_dist', level='coord', axis='columns').mean(axis='columns')

# df_out['max_avg'] = df.xs('avg_dist', level='coord', axis='columns').max(axis='columns')
df_out['max_max'] = df.xs('max_dist', level='coord', axis='columns').max(axis='columns')
# df_out['max_std'] = df.xs('std_dist', level='coord', axis='columns').max(axis='columns')

# df_out['std_avg'] = df.xs('avg_dist', level='coord', axis='columns').std(axis='columns')
# df_out['std_max'] = df.xs('max_dist', level='coord', axis='columns').std(axis='columns')
# df_out['std_std'] = df.xs('std_dist', level='coord', axis='columns').std(axis='columns')

df_out = df_out.merge(df_xy, left_index=True, right_index=True)
df_out.to_csv("./tmp/cells_xy_ice_stats.bsv", sep="|", float_format='%d')
#+END_SRC


NO - Now that only doing 1x land_100, this method no longer works

# #+header: :tangle k_basin_change.py
#+BEGIN_SRC jupyter-python 
cols_in = header.columns[['land' in _ for _ in header.columns]]
df = pd.read_csv("./tmp/cells_xy.bsv", delimiter="|", usecols=cols_in)
df.columns = pd.MultiIndex.from_arrays(multi_hdr, names=['k','coord'])

for kk in k:

    df[(kk,'avg_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).mean(axis='columns')

    df[(kk,'max_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).max(axis='columns')

df_out = pd.DataFrame()
df_out['avg_avg'] = df.xs('avg_dist', level='coord', axis='columns').mean(axis='columns')

df_out['max_max'] = df.xs('max_dist', level='coord', axis='columns').max(axis='columns')

df_out = df_out.merge(df_xy, left_index=True, right_index=True)
df_out.to_csv("./tmp/cells_xy_land_stats.bsv", sep="|", float_format='%d')
#+END_SRC


#+RESULTS:

**** Import Python results back to GRASS

#+BEGIN_SRC bash :results verbatim

# run python code above to calculate basin outlet statistics

log_info "Calculating cell outlet statistics..."

python ./k_basin_change.py 

log_info "Re-importing rasters."
log_warn "Reduced resolution."

g.region res=1000 -a
r.in.xyz input=./tmp/cells_xy_ice_stats.bsv output=ice_max method=mean x=4 y=5 z=3 skip=1
r.in.xyz input=./tmp/cells_xy_ice_stats.bsv output=ice_avg method=mean x=4 y=5 z=2 skip=1

# r.in.xyz input=./tmp/cells_xy_land_stats.bsv output=land_max method=mean x=4 y=5 z=3 skip=1
# r.in.xyz input=./tmp/cells_xy_land_stats.bsv output=land_avg method=mean x=4 y=5 z=2 skip=1
#+END_SRC



*** Visualize Maps                                      :noexport:
# :PROPERTIES:
# :header-args:bash+: :tangle k_basin_change_graphics.sh
# :header-args:bash+: :comments both
# :header-args:bash+: :tangle-mode (identity #o544)
# :header-args:bash+: :shebang #!/usr/bin/env bash
# :END:

# #+BEGIN_SRC bash :results verbatim
# <<init>>
# #+END_SRC


**** Color the difference maps

# # #+BEGIN_SRC ascii :tangle ./tmp/categories.txt :mkdirp t :eval no :comments nil
# #+BEGIN_SRC ascii :tangle no
# 0 = 1 no change
# 0 thru 999 = 1 < 1 km
# 1000 thru 2999 = 2 1 to < 3 km
# 3000 thru 10000 = 3 3 to < 10 km
# 10001 thru 29999 = 4 10 to < 30 km
# 30000 thru 99999 = 5 30 to < 100 km
# 100000 thru 10000000 = 6 > 100 km
# #+END_SRC

#+BEGIN_SRC ascii :tangle ./tmp/categories.txt :mkdirp t :eval no :comments nil
-1 = -1
0 thru 2999 = 1 0 to < 3 km
3000 thru 10000 = 2 3 to < 10 km
10001 thru 29999 = 3 10 to < 30 km
30000 thru 99999 = 4 30 to < 100 km
100000 thru 10000000 = 5 > 100 km
#+END_SRC

#+BEGIN_SRC bash :results verbatim
# for raster in ice_max ice_avg land_max land_avg; do
for raster in ice_max ice_avg; do
  r.mask raster=mask_o_l_i@ArcticDEM maskcats="2 3" --o
  r.mapcalc "${raster}_land = if(isnull(${raster}), -1 * (mask_o_l_i@ArcticDEM >=2), ${raster})" --o
  r.mask -r
  r.reclass input=${raster}_land output=${raster}_class --o rules=./tmp/categories.txt

  cat << EOF | r.colors map=${raster}_class rules=-
-1 128:128:128
5 255:255:204
4 161:218:180
3 65:182:196
2 44:127:184
1 37:52:148
EOF
done

# https://colorbrewer2.org/?type=sequential&scheme=YlGnBu&n=5
#+END_SRC

**** Prepare coastline vectors
#+BEGIN_SRC bash :results verbatim
g.mapset k_basin_change

g.region -d
r.mapcalc "outline = if(mask_o_l_i@ArcticDEM != 1)"
r.to.vect input=outline output=outline type=area

g.region res=1000 -a
r.mapcalc "outline_low = if(mask_o_l_i@ArcticDEM != 1, 1, null())"
r.to.vect input=outline_low output=outline_low type=area
g.region -d
#+END_SRC
**** Prepare some contours
+ Could be useful to show an elevation contour representative of the max melt elevation
#+BEGIN_SRC bash :results verbatim
r.mask outline_low maskcats=1 --o
g.region res=1000 -a
r.mapcalc "z_s = z_s@BedMachine" # mask
r.contour input=z_s output=z_s levels=1000,1500,2000
g.region -d
r.mask -r
#+END_SRC

**** PSMAP commands
#+NAME: psmap
#+BEGIN_SRC bash :results verbatim :tangle no
border n
# scale 1:1000000
paper a3
  end

raster ${raster}

# vareas outline_low
#   color gray
#   fcolor gray
#   # width 0.1
#   end

vlines z_s
  type line
  where level = 1500
  color black
  width 1
  end
vlines z_s
  type line
  where level = 1500
  color white
  width 5
  end

colortable y
  nodata n
  where 5.5 12
  fontsize 24
  end
scalebar s
  length 100
  units kilometers
  segment 1
  where 7 11.5
  fontsize 24
  end

#+END_SRC
**** TEST Generate an image
#+BEGIN_SRC bash :results verbatim :tangle no :session *freshwater-shell*
# All of Greenland

g.region -d 
g.region res=500 -a

raster=land_avg_class
cat << EOF | ps.map -e input=- output=./tmp/${raster}.eps --o
<<psmap>>
<<psmap_legend_GL>>
EOF
convert -trim ./tmp/${raster}.{eps,png}
o ./tmp/${raster}.png
g.region -d

#+END_SRC

**** Generate EPS files: Greenland
+ Use the PSMAP block above
#+BEGIN_SRC bash :results verbatim :session *freshwater-shell* :noweb yes

log_info "Generating graphic..."

mkdir -p ./fig

for domain in ice; do
  for stat in max avg; do
    raster=${domain}_${stat}_class

    g.region -d
    g.region res=1000 -a
    r.mask -r

    cat << EOF | ps.map input=- output=./tmp/${raster}.ps --o
    <<psmap>>
EOF

    convert -trim -transparent white ./tmp/${raster}.ps ./fig/${raster}.png
    g.region -d
  done
done
#+END_SRC

#+RESULTS:





**** Hexbin heatmap of dist vs. elevation
:PROPERTIES:
::header-args:bash+: :export no
::header-args:jupyter-python+: :export no
:END:
***** Import & process in Python

#+BEGIN_SRC jupyter-python :tangle k_basin_change.py
import pandas as pd
import numpy as np

df_xy = pd.read_csv("./tmp/cells_elev.bsv", delimiter="|", usecols=['x','y','z_s@ArcticDEM']).astype(int)

header = pd.read_csv("./tmp/cells_elev.bsv", delimiter="|", nrows=1)
cols_in = header.columns[['ice' in _ for _ in header.columns]]
df = pd.read_csv("./tmp/cells_elev.bsv", delimiter="|", usecols=cols_in)

multi_hdr = [np.array([_.split("_")[1] for _ in cols_in]).astype(int), 
             [_.split("_")[2] for _ in cols_in]]
df.columns = pd.MultiIndex.from_arrays(multi_hdr, names=['k','coord'])

k = np.unique(multi_hdr[0])

for kk in k:

    # mean distance for this k =
    # all other columns minus this column squared for x
    # also for y
    # square root of all that
    # take the mean of all columns

    df[(kk,'avg_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).mean(axis='columns')

    # same for max, except last step

    df[(kk,'max_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).max(axis='columns')

    # df[(kk,'std_dist')] = (((df.xs('x', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('x', level='coord', axis='columns')[kk]))**2 + (df.xs('y', level='coord', axis='columns').drop(kk, axis='columns').apply(lambda c: c-df.xs('y', level='coord', axis='columns')[kk]))**2)**0.5).std(axis='columns')

df_out = pd.DataFrame()
df_out['avg_avg'] = df.xs('avg_dist', level='coord', axis='columns').mean(axis='columns')
# df_out['avg_max'] = df.xs('max_dist', level='coord', axis='columns').mean(axis='columns')
# df_out['avg_std'] = df.xs('std_dist', level='coord', axis='columns').mean(axis='columns')

# df_out['max_avg'] = df.xs('avg_dist', level='coord', axis='columns').max(axis='columns')
df_out['max_max'] = df.xs('max_dist', level='coord', axis='columns').max(axis='columns')
# df_out['max_std'] = df.xs('std_dist', level='coord', axis='columns').max(axis='columns')

# df_out['std_avg'] = df.xs('avg_dist', level='coord', axis='columns').std(axis='columns')
# df_out['std_max'] = df.xs('max_dist', level='coord', axis='columns').std(axis='columns')
# df_out['std_std'] = df.xs('std_dist', level='coord', axis='columns').std(axis='columns')

df_out = df_out.merge(df_xy, left_index=True, right_index=True)
# df_out.to_csv("./tmp/cells_xy_ice_stats.bsv", sep="|", float_format='%d')
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
import matplotlib.pyplot as plt

import matplotlib
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
fig.set_tight_layout(True)
# import matplotlib.gridspec as gridspec
# gs = gridspec.GridSpec(1, 1) #w,h
# ax = plt.subplot(gs[:,:])
ax = fig.add_subplot(111)

df2 = df_out.copy(deep=True)
df2 = df2[df2['z_s@ArcticDEM'] < 1500]
df2 = df2[df2['max_max'] < 250*1E3]
df2 = df2[df2['max_max'] > 100*10*sqrt(2)]
ax.hexbin(df2['max_max']/1E3,df2['z_s@ArcticDEM'], mincnt=1, gridsize=(50,25), bins='log')
# ax.set_xlim(0,100E3)
# ax.set_ylim(0,3000)
# ax.plot(np.sin(np.arange(0,2*pi,0.1)))

# plt.savefig('.png', transparent=True, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

#+CAPTION: 
#+ATTR_LATEX: :width 0.8\textwidth
#+RESULTS:
** Bulk observation vs. RCM scatter plots
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:scatter_daily
#+ATTR_LATEX: :width 0.9\textwidth :placement [!h]
#+CAPTION: Daily runoff vs. observations for 10 outlets and a total of 15778 days. Solid lines show 1:1 (center), 1:5 (upper), and 5:1 (lower). Grey band shows 5 to 95 % prediction interval. Red band shows 5 to 95 % prediction interval when removing the GEM stations near Nuuk (Table \ref{tbl_obs}) that have small glaciers not included in the RCMs (5341 days remain).
[[./fig/scatter_daily.png]]

#+NAME: fig:scatter_yearsum
#+ATTR_LATEX: :width 0.9\textwidth :placement [!h]
#+CAPTION: Similar to Figure \ref{fig:scatter_daily}, except here showing annual sum of observed runoff - all days within each year when observations exist are summed. Days without observation are excluded from this comparison. Solid lines show 1:1 (center), 1:2 (upper), and 2:1 (lower). Grey band shows 5 to 95 % prediction interval.
[[./fig/scatter_yearsum.png]]


** Modified Tukey plot for all observations

#+NAME: fig:tukey
#+ATTR_LATEX: :width 0.9\textwidth :placement [!h]
#+CAPTION: Observation vs. ratio of RCM to observations for MAR (left) and RACMO (right), discussed in Sect. \ref{sec:method:tukey}. Number of samples at a location is represented by color. The horizontal solid line shows the mean, dashed lines show the 5 to 95 % quantile range, and the horizontal split denotes the bottom one-third and top two-thirds quantiles of observed discharge. The four near-Nuuk GEM basins which have glaciers not included in the RCM domain are excluded.
[[./fig/tukey_daily3.png]]

** Bamber 2018
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:bamber_2018
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Disko Island comparison between this product and citet:bamber_2018_freshwater. Light green are land basins with dark green outlet dots. Light blue are ice basins with dark blue outlet dots. Brown and hatched blue 5 km^{2} cells are the land and ice runoff locations, respectively, from citet:bamber_2018_freshwater. Bottom graphs show ice (upper) and land (lower) runoff for the 2012 runoff calendar year.
[[./fig/disko_merged.png]]


** Observations vs. RCM, map + ts + scatter             :noexport:
:PROPERTIES:
:clearpage: t
:END:

*** Ingest obs location into GRASS obs mapset
#+BEGIN_SRC bash :results verbatim :var mapset="obs" :var tbl_obs=tbl_obs_xy_cache :session *freshwater-shell*

# this is in Bash w/o GRASS
rm -f ./tmp/obs_loc.bsv
for key in "${!tbl_obs[@]}"; do 
  row=(${tbl_obs[$key]})
  echo ${row[0]}"|"${row[1]}"|"${key}"|" >> ./tmp/obs_loc.bsv
done

# in GRASS
<<grass_init_mapset>>
g.mapset -c obs

v.in.ascii input=./tmp/obs_loc.bsv output=obs_loc x=1 y=2
v.db.renamecolumn map=obs_loc column=int_1,x
v.db.renamecolumn map=obs_loc column=int_2,y
v.db.renamecolumn map=obs_loc column=str_1,label
v.db.dropcolumn map=obs_loc column=int_3

db.select table=obs_loc
#+END_SRC

*** RCM at each obs
**** Check locations

Recall locations:

#+BEGIN_SRC bash :results table :var tbl=tbl_obs_xy_cache :session
for key in "${!tbl[@]}"; do 
  row=(${tbl[$key]})
  echo ${row[@]} ${key} 
done

# also
# cat ./tmp/obs_loc.bsv
#+END_SRC

#+RESULTS:
|  699990 | -1540459 | Z  |
| -249713 | -2510668 | W  |
| -324548 | -2827284 | T  |
| -335678 | -2246371 | R  |
| -560538 | -1241281 | Q  |
|  -18335 | -3183360 | Ks |
| -317396 | -2826710 | O  |
| -216646 | -2504583 | L  |
| -326372 | -2829354 | K  |
| -316602 | -2831048 | Kb |

#+BEGIN_SRC jupyter-python :var tbl=tbl_obs_xy_cache
import geopandas as gpd
from shapely.geometry import Point

gdf = gpd.GeoDataFrame(tbl, columns=['abbrev','x','y'], crs="EPSG:3413").set_index("abbrev")
gdf['geometry'] = [Point(x,y) for x,y in zip(gdf['x'],gdf['y'])]
gdf.to_file("./tmp/obs.gpkg", driver="GPKG")
gdf
#+END_SRC

#+RESULTS:
| abbrev |       x |        y | geometry                 |
|--------+---------+----------+--------------------------|
| Ks     |  -18335 | -3183360 | POINT (-18335 -3183360)  |
| K      | -326372 | -2829354 | POINT (-326372 -2829354) |
| Kb     | -316602 | -2831048 | POINT (-316602 -2831048) |
| L      | -216646 | -2504583 | POINT (-216646 -2504583) |
| O      | -317396 | -2826710 | POINT (-317396 -2826710) |
| Q      | -560538 | -1241281 | POINT (-560538 -1241281) |
| R      | -335678 | -2246371 | POINT (-335678 -2246371) |
| T      | -324548 | -2827284 | POINT (-324548 -2827284) |
| W      | -249713 | -2510668 | POINT (-249713 -2510668) |
| Z      |  699990 | -1540459 | POINT (699990 -1540459)  |

View

#+BEGIN_SRC bash :results verbatim
qgis ./tmp/obs.gpkg &
#+END_SRC

**** Comments

Issues
+ Leverett always in micro-basin at ice sheet edge. Suggest manually moving *or* using =upstream= to collect other nearby micro-catchments.
  + Used "upstream" from original Leverett and there was too much runoff.
  + New Leverett is adjusted into the largest nearby ice basin.
+ Narsarsuaq in micro-basin at glacier snout. Seems likely that =upstream= fixes this. It appears that upstream glaciers drain to land and then under this glacier.

**** Runoff at each obs

#+BEGIN_SRC screen :screenrc /dev/null :session obs_runoff :cmd /bin/bash
source ~/.bash_profile
conda activate freshwater
mkdir -p ./dat/runoff
for line in $(cat ./tmp/obs_loc.bsv); do
  echo $line
  IFS="|" read x y abb <<< ${line[@]}
  echo $abb $x $y
  python ./discharge.py --base ./freshwater --roi=${x},${y} -u -d > ./dat/runoff/${abb}.csv
done
#+END_SRC

This takes an hour to run...


*** Plan overview map

#+BEGIN_SRC bash :results verbatim :session *freshwater-shell*
g.mapset -c obs

# | Color       |   R |   G |   B | hex     |
# |-------------+-----+-----+-----+---------|
# | light blue  | 166 | 206 | 227 | #a6cee3 |
# | dark blue   |  31 | 120 | 180 | #1f78b4 |
# | light green | 178 | 223 | 138 | #b2df8a |
# | dark green  |  51 | 160 |  44 | #33a02c |
# | pink        | 251 | 154 | 153 | #fb9a99 |
# | red         | 227 |  26 |  28 | #e31a1c |
# | pale orange | 253 | 191 | 111 | #fdbf6f |
# | orange      | 255 | 127 |   0 | #ff7f00 |

C_lightblue=#a6cee3
C_darkblue=#1f78b4
C_lightgreen=#b2df8a
C_darkgreen=#33a02c
C_pink=#fb9a99

export GRASS_OVERWRITE=1
# for label in $(db.select -c sql="select label from obs_loc where label == 'L'"); do
for label in $(db.select -c sql="select label from obs_loc"); do
  v.extract input=obs_loc where="label=='${label}'" output=this

  # set up the rasters and vectors
  <<plan_view_obs_loc>>

  # Make the map
cat << EOF | ps.map -e input=- output=./fig/${label}.eps --o
<<plan_view_obs_loc_psmap>>
EOF

    convert -trim -density 300 ./fig/${label}.eps ./fig/${label}.png
    # o ./fig/${label}.png

done

## Open each in inkscape, adjust scalebar if necessary (x4 for L and W), save all (even if not adjustments)
# for f in $(ls fig/{?,??}.eps); do inkscape $f; done
## Make PNGs: 
# parallel --verbose --bar "convert -trim -density 300 ./fig/{1}.eps ./fig/{1}.png" ::: Kb K Ks L O Q R T W Z 
#+END_SRC

#+NAME: plan_view_obs_loc
#+BEGIN_SRC bash :results verbatim

# # B2018 cell nearby
# x=$(db.select -c sql="select round(x) from b2018 where label == '${label}'")
# y=$(db.select -c sql="select round(y) from b2018 where label == '${label}'")
# g.region w=$(( ${x} - 2500 )) e=$(( ${x} + 2499 )) s=$(( ${y} - 2500 )) n=$(( ${y} + 2499 )) -pa
# v.in.region output=b2018_this  # vector outlining region. Useful for cropping.

v.select ainput=basins_filled@land_100 binput=this output=selected operator=contains

g.region vector=selected -pa

# expand by 10 %
eval $(g.region -pg)
w_adj=$(echo "(${e} - ${w}) * 0.05" | bc)
h_adj=$(echo "(${n} - ${s}) * 0.05" | bc)
g.region e=e+${w_adj} w=w-${w_adj} n=n+${h_adj} s=s-${h_adj} -pa
g.region w=w-${w_adj}
g.region w=w-${w_adj} # another 10 % for the legend

v.in.region output=region  # vector outlining region. Useful for cropping.

# All basins within region
v.overlay ainput=region binput=basins@land_100 operator=and output=basins_land
v.overlay ainput=region binput=basins_filled@land_100 operator=and output=basins_land_filled
v.overlay ainput=region binput=basins@ice_100 operator=and output=basins_ice

# this land basin + outlet + stream
v.select ainput=basins_land binput=this operator=contains output=basins_land_this
v.select ainput=basins_land_filled binput=this operator=contains output=basins_land_filled_this
v.select ainput=outlets@land_100 binput=basins_land_this  operator=within output=outlets_land_this
v.select ainput=streams@land_100 atype=line binput=basins_land_this operator=overlap output=streams_land_this

# ice outlets, basins, and streams draining into this basin
v.select ainput=outlets@ice_100 binput=basins_land_filled_this operator=within output=outlets_ice_this
v.select ainput=basins_ice binput=outlets_ice_this operator=contains output=basins_ice_this
v.select ainput=streams@ice_100 atype=line binput=basins_ice_this operator=overlap output=streams_ice_this

if [[ ${label} == "L" ]]; then
  v.select ainput=this binput=basins_ice operator=within output=outlets_ice_this
  v.select ainput=basins_ice binput=this operator=contains output=outlets_ice_this
  v.select ainput=basins_ice binput=outlets_ice_this operator=contains output=basins_ice_this
  v.select ainput=streams@ice_100 atype=line binput=basins_ice_this operator=overlap output=streams_ice_this
fi

### Basemap
g.region res=15 -a
parallel --verbose --bar "r.mapcalc \"{}float = (rgb.{#}@NSIDC_0713)^0.33\"" ::: r g b
eval $(r.univar map=rfloat,gfloat,bfloat -g) # get max of all three
parallel --verbose --bar "r.mapcalc \"{} = int( round( ({}float - ${min}) / (${max} - ${min}) * 255 ) )\"" ::: r g b
r.colors map=r,g,b color=grey

# RCM cells here
r.to.vect input=mask_ice_MAR@MAR output=MAR_ice type=area
r.to.vect input=mask_ice_RACMO@RACMO output=RACMO_ice type=area

# d.rgb red=r green=g blue=b
# d.vect basins@land_100 fill_color=none color=${C_darkgreen} width=2
# d.vect outlets@land_100 icon=basic/cross2 fillcolor=${C_darkgreen} color=${C_darkgreen} size=10
# d.vect streams@land_100 color=${C_lightgreen}
# d.vect basins@ice_100 fill_color=none color=${C_darkblue} width=2
# d.vect outlets@ice_100 icon=basic/cross2 fillcolor=${C_darkblue} color=${C_darkblue} size=10
# d.vect streams@ice_100 color=${C_lightblue}
# d.vect this icon=basic/cross2 color=red fill_color=red size=15
# d.out.file output=./fig/b.png size=${width},${height}

#+END_SRC

#+RESULTS: plan_view_obs_loc

#+NAME: plan_view_obs_loc_psmap
#+BEGIN_SRC bash :results verbatim :tangle no
border n

paper a4
  end

vareas basins_land
  color ${C_darkgreen}
  fcolor none
  lpos 0
  width 0.33
  end

vareas basins_ice_this
  color ${C_darkblue}
  fcolor none
  label Ice basins
  end

vareas basins_ice
  color ${C_darkblue}
  fcolor none
  lpos 0
  width 0.25
  end

vareas basins_land_this
  color ${C_darkgreen}
  fcolor none
  label Land basin
  end

# vlines streams_ice_this
#   color ${C_lightblue}
#   # lpos 0
#   label Streams
#   end

vlines streams_land_this
  color ${C_lightgreen}
  # lpos 0
  label Streams
  end

vpoints outlets_ice_this
  fcolor 255:127:0
  # fcolor white
  color none
  # symbol basic/box
  label Outlets
  size 5
  end

vpoints outlets_land_this
  # color 51:160:44
  fcolor 255:127:0
  color none
  size 5
  lpos 0
  end

vpoints this
  type point
  color 255:127:0
  fcolor none
  label Station
  end

vareas MAR_ice
  color ${C_lightblue}
  # pat $GISBASE/etc/paint/patterns/diag_down.eps
  # fcolor 126:206:227
  fcolor none
  scale 1
  width 3
  label RCM ice
  end

vareas RACMO_ice
  color ${C_lightblue}
  # pat $GISBASE/etc/paint/patterns/diag_up.eps
  # fcolor 126:206:227
  fcolor none
  scale 1
  width 1
  # label RACMO ice
  lpos 0
  end

# vareas b2018_this
#   color ${C_pink}
#   # pat $GISBASE/etc/paint/patterns/diag_up.eps
#   # fcolor 126:206:227
#   fcolor none
#   scale 1
#   width 1
#   # label RACMO ice
#   lpos 0
#   end

rgb r g b

vlegend
  where 0.1 1
  fontsize 8
  end

text 3% 3% a
  background white
  fontsize 20
  end
  
scalebar s
  length 1
  units kilometers
  segment 1
  where 1 3.25
  fontsize 12
  end
#+END_SRC


*** Time series at each obs

#+BEGIN_SRC jupyter-python :eval no-export
<<py_init>>
<<py_init_graphics>>

<<load_all_obs>>
# k='W'; obs={k:obs[k]}

for k in obs.keys():
    fig = plt.figure(1, figsize=(8,3.5)) # w,h
    fig.clf()
    fig.set_tight_layout(True)
    ax1 = fig.add_subplot(111)

    adjust_spines(ax1, ['left','bottom'])

    df = obs[k]
    name = df.attrs['name']

    df = df.replace(0, np.nan)
    kw = {'ax': ax1, 'drawstyle':'steps-post'}
    dfly = df[df.index.year == df.dropna().index.year[-1]] # .dropna() # last year
    dfly = dfly.loc[dfly['obs'].first_valid_index():dfly['obs'].last_valid_index()]

    # dfly = df
    dfly['obs'].plot(color=C_darkblue, **kw, alpha=1, label=name + ' observed')
    dfly['MAR'].plot(color=C_MAR, **kw, alpha=0.5, label='MAR')
    dfly['RACMO'].plot(color=C_RACMO, **kw, alpha=0.5, label='RACMO')

    # \pm 15 % according to Xavier
    kw={'step':'post', 'alpha':0.25}
    ax1.fill_between(dfly.index, dfly['MAR']*0.85, dfly['MAR']*1.15,color=C_MAR, **kw)
    ax1.fill_between(dfly.index, dfly['RACMO']*0.85, dfly['RACMO']*1.15,color=C_RACMO, **kw)
    # ax1.fill_between(dfly.index, dfly['MAR_90']*0.85, dfly['MAR_90']*1.15, color=C_MAR, **kw)
    # ax1.fill_between(dfly.index, dfly['RACMO_90']*0.85, dfly['RACMO_90']*1.15, color=C_RACMO, **kw)
    # ax1.fill_between(dfly.index, dfly['MAR_80']*0.85, dfly['MAR_80']*1.15, color=C_MAR, **kw)
    # ax1.fill_between(dfly.index, dfly['RACMO_80']*0.85, dfly['RACMO_80']*1.15, color=C_RACMO, **kw)

    if k == 'Q': # 9 % 2017, 22 % 2018 and 2019 error according to Ken Kondo email
        dfly['err'] = dfly['obs'] * 0.22
        ax1.fill_between(dfly.index, dfly['obs']-dfly['err'], dfly['obs']+dfly['err'], color=C_darkblue, step='post', alpha=0.25)

    if k == 'W': # Dirk provides err w/ his data
        ax1.fill_between(dfly.index, dfly['obs']-dfly['err'], dfly['obs']+dfly['err'], color=C_darkblue, step='post', alpha=0.25)

    plt.legend(fontsize=8, fancybox=False, frameon=False)
    ax1.set_xlabel("Time")
    ax1.set_ylabel("Runoff [m$^{3}$ s$^{-1}$]")
    ax1.text(-0.14, 0.95, 'b', size=15, color='white', bbox=dict(facecolor='black'), transform=ax1.transAxes)

    plt.savefig("./fig/" + k + "_ts.png", bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:



*** Scatter & Tukey at each obs

#+BEGIN_SRC jupyter-python :eval no-export
<<py_init>>
<<py_init_graphics>>

<<load_all_obs>>
# k="Q"; obs = {k:obs[k]}

for k in obs.keys():

    fig = plt.figure(1, figsize=(8,6.5)) # w,h
    fig.clf()
    fig.set_tight_layout(True)
    ax1 = fig.add_subplot(221)
    ax2 = fig.add_subplot(222)
    ax3 = fig.add_subplot(223)
    ax4 = fig.add_subplot(224)

    adjust_spines(ax1, ['left','bottom'])
    adjust_spines(ax2, ['right','bottom'])
    adjust_spines(ax3, ['left','bottom'])
    adjust_spines(ax4, ['right','bottom'])

    df = obs[k]
    
    df = df.replace(0, np.nan).dropna()
    df = np.log10(df)
    # df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)] # clean up nan and inf

    kw = {'alpha': 1, 'cmap': cm.viridis, 'marker':'.', 'c':df.index.dayofyear, 'edgecolor':'none', 'clip_on':False}
    s = ax1.scatter(df['obs'], df['MAR'], **kw)
    s = ax2.scatter(df['obs'], df['RACMO'], **kw)

    kw = {'color':'k', 'alpha':0.66, 'linewidth':0.5, 'levels':5}
    sns.kdeplot(df['obs'], df['MAR'], ax=ax1, **kw)
    sns.kdeplot(df['obs'], df['RACMO'], ax=ax2, **kw)

    lims = [np.min([ax1.get_xlim()[0], ax1.get_ylim()[0], ax2.get_xlim()[0], ax2.get_ylim()[0]]),
            np.max([ax1.get_xlim()[1], ax1.get_ylim()[1], ax2.get_xlim()[1], ax2.get_ylim()[1]])]

    # drop 5/95 outliers
    # q = df['obs'].quantile([0.05, 0.95])
    # df = df[(df['obs'] > q[0.05]) & (df['obs'] < q[0.95])]

    df.sort_values(by='obs', inplace=True)
    x = df['obs'].values
    y_MAR = df['MAR'].values
    y_RACMO = df['RACMO'].values
    
    X = sm.add_constant(x)
    # X = x
    model = sm.OLS(y_MAR, X)
    results = model.fit()
    prstd, iv_l, iv_u = wls_prediction_std(results)
    ax1.fill_between(x, iv_u, iv_l, color="grey", alpha=0.25)
    ax1.text(0.05, 0.85, 'r$^{2}$:' + str(round(results.rsquared,2)), transform=ax1.transAxes, horizontalalignment='left')

    model = sm.OLS(y_RACMO, X)
    results = model.fit()
    prstd, iv_l, iv_u = wls_prediction_std(results)
    ax2.fill_between(x, iv_u, iv_l, color="grey", alpha=0.25)
    ax2.text(0.05, 0.85, 'r$^{2}$:' + str(round(results.rsquared,2)), transform=ax2.transAxes, horizontalalignment='left')

    ax1.text(0.05, 0.95, 'n:' + str(df['obs'].size), transform=ax1.transAxes, horizontalalignment='left')

    ax1.set_xlabel('Observed [m$^{3}$ s$^{-1}$]')
    ax1.set_ylabel('MAR [m$^{3}$ s$^{-1}$]')
    ax2.set_xlabel('Observed [m$^{3}$ s$^{-1}$]')
    ax2.set_ylabel('RACMO [m$^{3}$ s$^{-1}$]')


    if lims[0] < -3: lims[0] = -3
    lims_upstreamp = np.log10((10**np.array(lims))*5)
    lims_down = np.log10((10**np.array(lims))/5)
    kw = {'alpha':0.5, 'linewidth':1, 'color':'k', 'linestyle':'-'}
    for ax in [ax1,ax2]:
        ax.plot(([lims[0],lims[1]]), ([lims[0],lims[1]]), **kw)
        ax.plot(([lims[0],lims[1]]), ([lims_upstreamp[0],lims_upstreamp[1]]), **kw)
        ax.plot(([lims[0],lims[1]]), ([lims_down[0],lims_down[1]]), **kw)
        ax.set_ylim(lims[0], lims[1])
        ax.set_xlim(lims[0], lims[1])

        ticks = np.arange(round(lims[0]), round(lims[1])+1)
        ax.set_yticks(ticks)
        labels = ['10$^{' + str(int(_)) + '}$' for _ in ticks]
        ax.set_yticklabels(labels)
        ax.set_xticks(ax.get_yticks())
        ax.set_xticklabels(ax.get_yticklabels())
        
    # cax = fig.add_axes([0.46, 0.6, 0.01, 0.2])
    # cb = fig.colorbar(s, cax=cax)
    cax = fig.add_axes([0.40, 0.53, 0.2, 0.015])
    cb = fig.colorbar(s, cax=cax, orientation='horizontal')
    cax.xaxis.set_ticks_position('top')
    cax.xaxis.set_label_position('top')
    cb.set_label('Day of year')

    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=30)
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=30)



    ### LOWER PANELS
    # Included here so that we can easily match the x-axis limits
    df = obs[k]

    df['x'] = df['obs']
    df['y_MAR'] = df['MAR'] / df['obs']
    df['y_RACMO'] = df['RACMO'] / df['obs']
    df = df.replace(0, np.nan).dropna()
    df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]
    df = np.log10(df)

    kw = {'mincnt':1,
          'bins':'log',
          'clip_on':True,
          'gridsize':20,
          'cmap':cm.cividis}

    # plot all to get max of both for colorbar range
    h_MAR = ax3.hexbin(df['x'], df['y_MAR'], alpha=0, **kw)
    h_RACMO = ax4.hexbin(df['x'], df['y_RACMO'], alpha=0, **kw)
    
    ymin = np.floor(np.min([ax1.get_ylim()[0], ax2.get_ylim()[0]]))
    ymax = np.ceil(np.max([ax1.get_ylim()[1], ax2.get_ylim()[1]]))
    THRESH=3
    if ymax > THRESH: ymax = THRESH

    kw['alpha'] = 1
    kw['extent'] = [lims[0], lims[1], ymin, ymax]
    kw['vmax'] = max([h_MAR.get_array().max(),h_RACMO.get_array().max()])

    h_MAR = ax3.hexbin(df['x'], df['y_MAR'], **kw)
    h_RACMO = ax4.hexbin(df['x'], df['y_RACMO'], **kw)

    df_top = df[df['obs'] > df['obs'].quantile(0.33)]
    df_bot = df[df['obs'] < df['obs'].quantile(0.33)]

    kwline = {'color':'k'}
    kwtext = {'path_effects':[pe.withStroke(linewidth=2, foreground="white")], 
              'color':'k',
              'fontsize':10,
              'verticalalignment':'center'}
    for d in [df_top, df_bot]:
    
        for ax in [ax3,ax4]:
            if d is df_top:
                max_MAR = np.max([_[0] for _ in h_MAR.get_offsets()])
                max_RACMO = np.max([_[0] for _ in h_RACMO.get_offsets()])
                xpos = np.max([max_MAR, max_RACMO])
                # xpos = round(xmax)
                kwtext['horizontalalignment'] = 'left'
            elif d is df_bot:
                min_MAR = np.min([_[0] for _ in h_MAR.get_offsets()])
                min_RACMO = np.min([_[0] for _ in h_RACMO.get_offsets()])
                xpos = np.min([min_MAR, min_RACMO])
                kwtext['horizontalalignment'] = 'right'

            if ax is ax3: yy = d['y_MAR']
            if ax is ax4: yy = d['y_RACMO']
            y = yy.mean()
            ax.plot([d['x'].min(),d['x'].max()], [y,y], **kwline)
            ax.text(xpos, y, str(round(10**y,2)), **kwtext)
            
            y = yy.quantile(0.95)
            ax.plot([d['x'].min(),d['x'].max()], [y,y], linestyle='--', **kwline)
            ax.text(xpos, y, str(round(10**y,2)), **kwtext)
            
            y = yy.quantile(0.05)
            ax.plot([d['x'].min(),d['x'].max()], [y,y], linestyle='--', **kwline)
            ax.text(xpos, y-0.15, str(round(10**y,2)), **kwtext)
            
    ax3.set_xlabel('Observed [m$^{3}$ s$^{-1}$]')
    ax3.set_ylabel('MAR / Observed')
    ax4.set_xlabel('Observed [m$^{3}$ s$^{-1}$]')
    ax4.set_ylabel('RACMO / Observed')

    for ax in [ax3,ax4]:
        ax.set_xlim(lims[0], lims[1])
        ax.set_xticks(ax1.get_xticks())
        ax.set_xticklabels(ax1.get_xticklabels())
        ticks = np.arange(round(ymin), round(ymax)+1)
        labels = ['10$^{' + str(int(_)) + '}$' for _ in ticks]
        ax.set_yticks(ticks)
        ax.set_ylim([ticks[0], ticks[-1]])
        ax.set_yticklabels(labels)

    ax1.text(-0.33, 0.95, 'c', size=15, color='white', bbox=dict(facecolor='black'), transform=ax1.transAxes)
    ax3.text(-0.33, 0.99, 'd', size=15, color='white', bbox=dict(facecolor='black'), transform=ax3.transAxes)

    cax = fig.add_axes([0.40, 0.5, 0.2, 0.015])
    cb = fig.colorbar(h_MAR, cax=cax, orientation='horizontal')
    if k in ['Ks','R','Q']: cax.xaxis.set_minor_formatter(plt.ScalarFormatter())
    cb.set_label('Count')

    plt.setp(ax3.xaxis.get_majorticklabels(), rotation=30)
    plt.setp(ax4.xaxis.get_majorticklabels(), rotation=30)

    # clean up upper panel
    adjust_spines(ax1,['left'])
    adjust_spines(ax2,['right'])
    ax1.set_xlabel('')
    ax2.set_xlabel('')

    plt.savefig("./fig/" + k + "_tukey_scatter.png", bbox_inches='tight', dpi=300)
#+END_SRC

*** Stack

#+BEGIN_SRC screen :cmd /bin/bash :session stack :screenrc /dev/null
mkdir ./tmp/stack
f=$(ls fig/{?,??}_ts.png|head -n1) # debug
for f in $(ls fig/{?,??}_ts.png); do
  ff=$(basename $f)
  k=$(echo ${ff} | cut -d"_" -f1)
  echo $ff $k

  cp fig/${k}.png ./tmp/stack/map.png
  cp fig/${k}_ts.png ./tmp/stack/ts.png
  cp fig/${k}_tukey_scatter.png ./tmp/stack/tukey_scatter.png
  
  convert ./tmp/stack/{map,ts,tukey_scatter}.png -gravity center -append fig/${k}_stack.png
done

convert -pointsize 40 -fill red -draw 'text 850,250 "X"' ./fig/L_stack.png ./fig/tmp.png
mv ./fig/tmp.png ./fig/L_stack.png
#+END_SRC

#+RESULTS:

** Watson River
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:W
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Watson River outlet, basin, and discharge (W in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:W} for discussion of the Watson River basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/W_stack.png]]

** Watson Adjustments
:PROPERTIES:
:clearpage: t
:END:


#+BEGIN_SRC jupyter-python
import matplotlib.pyplot as plt

import matplotlib
from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

from discharge import discharge 
import geopandas as gp
from adjust_spines import adjust_spines as adjust_spines

if 'r_land' not in locals():
    # runoff at Watson land outlet, and for two ice basins to the S not included in the uptream Watson outlets
    r_land = discharge(base="./freshwater", roi="-50.68,67.01", upstream=True, quiet=False).discharge()
    r_ice0 = discharge(base="./freshwater", roi="-49.40,66.90", upstream=False, quiet=False).discharge()
    r_ice1 = discharge(base="./freshwater", roi="-49.25,66.80", upstream=False, quiet=False).discharge()

    g_land = discharge(base="./freshwater", roi="-50.68,67.01", upstream=True, quiet=False).outlets().set_geometry('basin')
    g_ice0 = discharge(base="./freshwater", roi="-49.40,66.90", upstream=False, quiet=False).outlets().set_geometry('basin')
    g_ice1 = discharge(base="./freshwater", roi="-49.25,66.80", upstream=False, quiet=False).outlets().set_geometry('basin')

# plt.close(1)
fig = plt.figure(1, figsize=(4,4.5)) # w,h
fig.clf()
fig.set_tight_layout(True)
import matplotlib.gridspec as gridspec
gs = gridspec.GridSpec(2, 2, width_ratios=[1,1000], height_ratios=[1,2]) #h, w
ax1 = plt.subplot(gs[0, :])
ax2 = plt.subplot(gs[1, :])

C_lightblue = np.array((166, 206, 227))/255
C_darkblue = np.array((31, 120, 180))/255
C_lightgreen = np.array((127, 223, 138))/255
C_darkgreen = np.array((51, 160, 44))/255

kw = {'ax':ax1, 'linewidth':0.3, 'clip_on':False}
g_land[g_land['domain'] == 'land'].plot(color=C_lightgreen, edgecolor='k', **kw)
g_land[g_land['domain'] == 'ice'].plot(color='orange', edgecolor='k', **kw)
g_land[g_land['domain'] == 'land'].set_geometry('outlet').plot(color='r', **kw)
g_ice0[g_ice0['domain'] == 'ice'].plot(color=C_darkblue, edgecolor='k', **kw)
g_ice1[g_ice1['domain'] == 'ice'].plot(color=C_darkblue, edgecolor='k', **kw)

# ax1.set_ylim([-2.59E6,-2.49E6])
ax1.set_ylim([-2.60E6,-2.50E6])

# write out for Google Eearth so we can draw approx location of contour line
# g_ice1[(g_ice1['domain'] == 'ice') & (g_ice1['k'] == 100)].drop(columns="outlet").to_file('./tmp/g_ice1.shp')
# 1500 @ -48.3
# 1850 @ -47.33
# most runoff below that (see van As 2017)
from shapely.geometry import Point, Polygon
xy = gp.GeoSeries(data=Point(-48.3, 66.6), crs="EPSG:4326").to_crs("EPSG:3413").loc[0].xy
ax1.plot(list(xy[0])*2,[-2.52E6,-2.57E6], 'k--', alpha=0.5, clip_on=False)
xy = gp.GeoSeries(data=Point(-47.33, 66.6), crs="EPSG:4326").to_crs("EPSG:3413").loc[0].xy
ax1.plot(list(xy[0])*2,[-2.54E6,-2.59E6], 'k--', alpha=0.5, clip_on=False)

# ax1.margins(0,0)
# ax1.xaxis.set_major_locator(plt.NullLocator())
# ax1.yaxis.set_major_locator(plt.NullLocator())
adjust_spines(ax1, [])

from matplotlib_scalebar.scalebar import ScaleBar
ax1.add_artist(ScaleBar(1))

W = pd.read_csv("./dat/runoff/obs_W.csv", index_col=0, parse_dates=True)

MAR = r_land[['MAR_land','MAR_ice_upstream']]\
    .sum(dim=['land','ice_upstream'])\
    .to_dataframe()\
    .merge(r_ice0['MAR_ice']\
           .squeeze()\
           .to_dataframe()['MAR_ice'], left_index=True, right_index=True)\
    .rename(columns={"MAR_ice":"ice0"})\
    .merge(r_ice1['MAR_ice']\
           .squeeze()\
           .to_dataframe()['MAR_ice'], left_index=True, right_index=True)\
    .rename(columns={"MAR_ice":"ice1"})\
    .merge(W, left_index=True, right_index=True)

combine = ['MAR_land','MAR_ice_upstream']
MAR['land'] = MAR[combine].sum(axis='columns')
MAR.drop(columns=combine, inplace=True)


# identical to MAR
RACMO = r_land[['RACMO_land','RACMO_ice_upstream']]\
    .sum(dim=['land','ice_upstream'])\
    .to_dataframe()\
    .merge(r_ice0['RACMO_ice']\
           .squeeze()\
           .to_dataframe()['RACMO_ice'], left_index=True, right_index=True)\
    .rename(columns={"RACMO_ice":"ice0"})\
    .merge(r_ice1['RACMO_ice']\
           .squeeze()\
           .to_dataframe()['RACMO_ice'], left_index=True, right_index=True)\
    .rename(columns={"RACMO_ice":"ice1"})\
    .merge(W, left_index=True, right_index=True)

combine = ['RACMO_land','RACMO_ice_upstream']
RACMO['land'] = RACMO[combine].sum(axis='columns')
RACMO.drop(columns=combine, inplace=True)

df = (MAR+RACMO)/2
df['merge'] = df['land'] + df['ice0'] + df['ice1']
df = np.log10(df).dropna()
df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)] # clean up nan and inf

import seaborn as sns

kw = {'alpha':0.66, 'shade_lowest':False}
sns.kdeplot(df['Observed'], df['land'], cmap=cm.Oranges, ax=ax2, shade=True, **kw)
sns.kdeplot(df['Observed'], df['merge'], cmap=cm.Blues, ax=ax2, **kw)

lims = np.array((ax2.get_xlim(),ax2.get_ylim())).flatten()
ax2.set_xlim(1, 3.8)
ax2.set_ylim(ax2.get_xlim())
ax2.set_xlabel('Observed [m$^{3}$ s$^{-1}$]')
lims = [1,3.8]

if lims[0] < -3: lims[0] = -3
lims_upstreamp = np.log10((10**np.array(lims))*2)
lims_down = np.log10((10**np.array(lims))/2)
kw = {'alpha':0.5, 'linewidth':1, 'color':'k'}
ax2.plot(([lims[0],lims[1]]), ([lims[0],lims[1]]), **kw)
# ax2.plot(([lims[0],lims[1]]), ([lims_upstreamp[0],lims_upstreamp[1]]), **kw)
ax2.plot(([lims[0],lims[1]]), ([lims_down[0],lims_down[1]]), linestyle='--', **kw)
ax2.set_ylim(lims[0], lims[1])
ax2.set_xlim(lims[0], lims[1])
    
ticks = np.arange(round(lims[0]), round(lims[1])+1)
ax2.set_yticks(ticks)
labels = ['10$^{' + str(int(_)) + '}$' for _ in ticks]
ax2.set_yticklabels(labels)
ax2.set_xticks(ax2.get_yticks())
ax2.set_xticklabels(ax2.get_yticklabels())
    
adjust_spines(ax2, ['left','bottom'])
ax2.set_ylabel('RCM mean [m$^{^3}$ s$^{-1}$]')

plt.savefig('./fig/watson_adjusted_south.png', transparent=True, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:

#+NAME: fig:W_adjust
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Watson River and manually adjusted basin area. Top panel: map view showing land and ice basin from this work -- green and orange, respectively, are the same as the region shown in \ref{fig:W}, and two additional basins to the south are shown in blue. Vertical dashed lines denote approximate location of 1500 m and 1850 m elevation. Bottom panel: Kernel density estimate (concentration of points) comparing observed vs. average of RACMO and MAR RCM runoff for the default land and ice basin (orange; filled) and with the additional southern basins (blue; lines). Solid and dashed lines are 1:1 and 2:1 (respectively) observed-to-RCM ratios.
[[./fig/watson_adjusted_south.png]]

** Leverett Glacier
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:L
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Leverett Glacier outlet, basin, and discharge (L in Fig. \ref{fig:overview}). Red X in panel (a) marks approximate observation location, but adjusted here to an orange diamond within the ice basin. See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:L} for discussion of the Leverett Glacier basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/L_stack.png]]

** Kiattuut Sermiat
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:Ks
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Kiattuut Sermiat outlet, basin, and discharge (Ks in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:Ks} for discussion of the Kiattuut Sermiat basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/Ks_stack.png]]

** Kingigtorssuaq
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:K
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Kingigtorssuaq outlet, basin, and discharge (K in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:K} for discussion of the Kingigtorssuaq basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/K_stack.png]]


** Oriartorfik
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:O
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Oriartorfik outlet, basin, and discharge (O in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:O} for discussion of the Oriartorfik basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/O_stack.png]]

** Teqinngalip
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:T
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Teqinngalip outlet, basin, and discharge (T in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:T} for discussion of the Teqinngalip basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/T_stack.png]]

** Kobbefjord
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:Kb
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Kobbefjord outlet, basin, and discharge (Kb in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:Kb} for discussion of the Kobbefjord basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/Kb_stack.png]]

** Røde Elv
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:R
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Røde Elv outlet, basin, and discharge (R in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:R} for discussion of the Røde Elv basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/R_stack.png]]

** Zackenberg
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:Z
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Zackenberg outlet, basin, and discharge (Z in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:Z} for discussion of the Zackenberg basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/Z_stack.png]]

** Qaanaaq
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:Q
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Graphical summary of Qaanaaq outlet, basin, and discharge (Q in Fig. \ref{fig:overview}). See Sect. \ref{sec:graphics} for a general overview of graphical elements and Sect. \ref{sec:Q} for discussion of the Qaanaaq basin. Basemap from citet:howat_2014 and citet:NSIDC_0713.
[[./fig/Q_stack.png]]

** Elevation histogram
:PROPERTIES:
:clearpage: t
:END:

#+NAME: fig:elev
#+ATTR_LATEX: :width 0.4\textwidth :placement [!h]
#+CAPTION: Top: Histogram of outlet elevations. Bottom: Cumulative distribution of absolute land outlet elevation. More than 75 % of land outlets occur within \pm10 m and 90 % within \pm30 m.
[[./fig/outlet_elevation_histogram_cdf.png]]

* README                                                :noexport:

#+BEGIN_SRC org :tangle ./freshwater/README.txt :mkdirp ./freshwater :eval no
README for "Greenland liquid water runoff from 1940 through December 2024"

Data DOI: doi:10.22008/promice/freshwater
Source: https://github.com/GEUS-Glaciology-and-Climate/freshwater

,* Data Description

Data sets released as part of this work include:
+ Streams
+ Outlets
+ Basins
+ Runoff

,** Streams, outlets, and basins

Streams, outlets, and basins are calculated for both land coast outlets and ice margin outlets, and the upstream basins and streams that feed those outlets. For each of these two (land coast, ice margin) we estimate streams, outlets, and basins, assuming subglacial pressure is equal to ice overburden pressure.

Streams over land closely follow actual streams based on comparison with satellite imagery.
Subglacial streams are merely representative of where the model hydropotential routes most of the water. 

Outlets are marked where streams leave the domain

Basins are the usptream grid cells that feed into each outlet.

,** Runoff

Runoff comes from daily MAR and RACMO RCM runoff, partitioned into each basin, and assigned to each outlet.

The ice dataset report the ice runoff. The land dataset report the the land runoff. The land dataset includes the ID of the upstream ice basins that drain into each land basin, allowing one to find the ice melt runoff at any land outlet.

,* Datasets

Each dataset is in a folder named <domain>, where =domain= is one of "ice" or "land". Within each folder the following files and sub-folders are provided:

| Filename     | Description                           |
|--------------+---------------------------------------|
| streams.gpkg | GeoPackage of stream locations        |
| streams.csv  | Metadata for streams                  |
| outlets.gpkg | GeoPackage of outlet locations        |
| outlets.csv  | Metadata for outlets                  |
| basins.gpkg  | GeoPackage of basin locations         |
| basins.csv   | Metadata for basins                   |
| runoff       | NetCDF files of runoff at each outlet |

In the runoff sub-folders, files are named <RCM>_<YYYY>.nc, where =RCM= is one of "MAR" or "RACMO", and =YYYY= is the year of the data. Within each file are daily runoff values at each outlet.

,* Database access software

The =discharge.py= script provides high-level access to the database. See =README.org= for usage examples.

Complete documentation and example use cases with code are available at https://github.com/GEUS-Glaciology-and-Climate/freshwater, or by contacting Ken Mankoff <kdm@geus.dk>
#+END_SRC



* Appendix                                                :ignore:
#+LaTeX: \clearpage
#+LaTeX: \appendix


** Software
:PROPERTIES:
:clearpage: t
:END:

This work was performed using only open-source software, primarily =GRASS GIS= citep:neteler_2012, CDO citep:CDO, NCO citep:NCO, GDAL citep:GDAL, and =Python= citep:van-rossum_1995, in particular the =Jupyter= citep:kluyver_2016, =dask= citep:dask_sw,dask_paper, =pandas= citep:mckinney_2010, =geopandas= citep:geopandas, =numpy= citep:oliphant_2006, =x-array= citep:hoyer_2017, and =Matplotlib= citep:hunter_2007 packages. The entire work was performed in =Emacs= citep:stallman_1981 using =Org Mode= citep:schulte_2012 on GNU/Linux and using many GNU utilities (See https://github.com/GEUS-Glaciology-and-Climate/freshwater citep:github_freshwater). The =parallel= citep:tange_2011 tool was used to speed up processing. We used =proj4= citep:proj4 to compute the errors in the EPSG 3413 projection. The color map for Fig. [[fig:k_basin_change]] comes from citet:colorbrewer.

* Misc journal sections                                   :ignore:

\authorcontribution{KDM produced this work and wrote the code and the text. XF and BN supplied RCM inputs. APA, WIC, DVA, and RSF helped with discussions of methods, quality control, or writing. KK and SS supplied Qaanaaq data. KL provided GEM data.}

\competinginterests{The authors declare that they have no conflict of interest.}


#+BEGIN_acknowledgements
DEMs were provided by the Polar Geospatial Center under NSF-OPP awards 1043681, 1559691, and 1542736. Data from the Greenland Ecosystem Monitoring (GEM) program were provided by Asiaq – Greenland Survey, Nuuk, Greenland. We thank Dorthe Petersen (Asiaq) for help with basin quality control. The editor and two anonymous reviewers provided valuable feedback and helped improve this paper \citep{ESSD_reviewer1,ESSD_reviewer2}.

Financial Support: Funding was provided by the Programme for Monitoring of the Greenland Ice Sheet (PROMICE). Parts of this work were funded by the INTAROS project under the European Union’s Horizon 2020 research and innovation program under grant agreement no. 727890. Brice Noël was funded by NWOVENI grant VI.Veni.192.019.
#+END_acknowledgements

* References                                              :ignore:

#+LaTeX: \bibliographystyle{copernicus}
# #+LaTeX: \bibliography{/home/kdm/Documents/Papers/library,freshwater}{}
#+LaTeX: \bibliography{freshwater}{}

* Meta                                                  :noexport:
** Software

This project uses software - bash, GRASS, Python, etc. The python environment is reproducible if you have Conda installed. Below I provide the version of the software(s) used to create this document in order to support the goal of bit-matching reproducibility. 

*** Os installed
#+BEGIN_SRC bash :results table
for tool in gdal-bin parallel sed gawk netcdf-bin proj-bin nco cdo bash grass-gui datamash; do dpkg -l | grep "ii  ${tool} " | cut -c5-90; done| sort
#+END_SRC

#+RESULTS:
| bash       | 5.2.15-2+b8     | amd |
| cdo        | 2.1.1-1+deb12u1 | amd |
| datamash   | 1.7-2           | amd |
| gdal-bin   | 3.6.2+dfsg-1+b2 | amd |
| grass-gui  | 8.2.1-1         | amd |
| nco        | 5.1.4-1+deb12u1 | amd |
| netcdf-bin | 1:4.9.0-3+b1    | amd |
| parallel   | 20221122+ds-2   | all |
| proj-bin   | 9.1.1-1+b1      | amd |
| sed        | 4.9-1           | amd |


*** Org Mode
#+BEGIN_SRC emacs-lisp :eval no-export :exports both
(org-version nil t)
#+END_SRC

#+RESULTS:
: Org mode version 9.7.29 (release_9.7.29 @ /home/kdm/local/src/org-mode/lisp/)

*** Python

**** Dev environment
The code below produces [[./environment.yml]] when this file is exported. If that file exists, then ~mamba env create -f environment.yml~ and ~mamba activate freshwater~ will install all the python packages used in this document.

#+NAME: conda_env 
#+BEGIN_SRC bash :cmdline -i :results verbatim :eval no-export :exports both
conda env export --name freshwater | cat | tee environment-dev.yml
#+END_SRC

#+RESULTS: conda_env
#+begin_example
name: freshwater_user
channels:
  - conda-forge
  - nodefaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - attrs=25.3.0=pyh71513ae_0
  - aws-c-auth=0.9.0=h66f1c83_6
  - aws-c-cal=0.9.0=hada3f3f_0
  - aws-c-common=0.12.2=hb9d3cd8_0
  - aws-c-compression=0.3.1=hc2d532b_4
  - aws-c-event-stream=0.5.4=h9312af0_8
  - aws-c-http=0.10.1=hc373b34_0
  - aws-c-io=0.19.0=h756d8c7_1
  - aws-c-mqtt=0.13.0=h034c9a0_2
  - aws-c-s3=0.7.17=h73c4702_1
  - aws-c-sdkutils=0.2.3=hc2d532b_4
  - aws-checksums=0.2.7=hc2d532b_0
  - aws-crt-cpp=0.32.5=h5e5e39d_2
  - aws-sdk-cpp=1.11.510=h7cc6b5f_7
  - azure-core-cpp=1.14.0=h5cfcd09_0
  - azure-identity-cpp=1.10.0=h113e628_0
  - azure-storage-blobs-cpp=12.13.0=h3cf044e_1
  - azure-storage-common-cpp=12.8.0=h736e048_1
  - azure-storage-files-datalake-cpp=12.12.0=ha633028_1
  - blosc=1.21.6=he440d0b_1
  - bokeh=3.7.2=pyhd8ed1ab_1
  - branca=0.8.1=pyhd8ed1ab_0
  - brotli=1.1.0=hb9d3cd8_2
  - brotli-bin=1.1.0=hb9d3cd8_2
  - brotli-python=1.1.0=py313h46c70d0_2
  - bzip2=1.0.8=h4bc722e_7
  - c-ares=1.34.5=hb9d3cd8_0
  - ca-certificates=2025.4.26=hbd8a1cb_0
  - certifi=2025.4.26=pyhd8ed1ab_0
  - cffi=1.17.1=py313hfab6e84_0
  - cftime=1.6.4=py313ha014f3b_1
  - charset-normalizer=3.4.2=pyhd8ed1ab_0
  - click=8.1.8=pyh707e725_0
  - click-plugins=1.1.1=pyhd8ed1ab_1
  - cligj=0.7.2=pyhd8ed1ab_2
  - cloudpickle=3.1.1=pyhd8ed1ab_0
  - contourpy=1.3.2=py313h33d0bda_0
  - cycler=0.12.1=pyhd8ed1ab_1
  - cytoolz=1.0.1=py313h536fd9c_0
  - dask=2025.2.0=pyhd8ed1ab_0
  - dask-core=2025.2.0=pyhd8ed1ab_0
  - distributed=2025.2.0=pyhd8ed1ab_0
  - fiona=1.10.1=py313hab4ff3b_3
  - folium=0.19.5=pyhd8ed1ab_0
  - fonttools=4.57.0=py313h8060acc_0
  - freetype=2.13.3=ha770c72_1
  - freexl=2.0.0=h9dce30a_2
  - fsspec=2025.3.2=pyhd8ed1ab_0
  - geopandas=1.0.1=pyhd8ed1ab_3
  - geopandas-base=1.0.1=pyha770c72_3
  - geos=3.13.1=h97f6797_0
  - geotiff=1.7.4=h239500f_2
  - gflags=2.2.2=h5888daf_1005
  - giflib=5.2.2=hd590300_0
  - glog=0.7.1=hbabe93e_0
  - h2=4.2.0=pyhd8ed1ab_0
  - hdf4=4.2.15=h2a13503_7
  - hdf5=1.14.6=nompi_h2d575fe_101
  - hpack=4.1.0=pyhd8ed1ab_0
  - hyperframe=6.1.0=pyhd8ed1ab_0
  - icu=75.1=he02047a_0
  - idna=3.10=pyhd8ed1ab_1
  - importlib-metadata=8.6.1=pyha770c72_0
  - jinja2=3.1.6=pyhd8ed1ab_0
  - joblib=1.5.0=pyhd8ed1ab_0
  - json-c=0.18=h6688a6e_0
  - keyutils=1.6.1=h166bdaf_0
  - kiwisolver=1.4.7=py313h33d0bda_0
  - krb5=1.21.3=h659f571_0
  - lcms2=2.17=h717163a_0
  - ld_impl_linux-64=2.43=h712a8e2_4
  - lerc=4.0.0=h0aef613_1
  - libabseil=20250127.1=cxx17_hbbce691_0
  - libaec=1.1.3=h59595ed_0
  - libarchive=3.7.7=h75ea233_4
  - libarrow=20.0.0=hebdba27_2_cpu
  - libarrow-acero=20.0.0=hcb10f89_2_cpu
  - libarrow-dataset=20.0.0=hcb10f89_2_cpu
  - libarrow-substrait=20.0.0=h1bed206_2_cpu
  - libblas=3.9.0=31_h59b9bed_openblas
  - libbrotlicommon=1.1.0=hb9d3cd8_2
  - libbrotlidec=1.1.0=hb9d3cd8_2
  - libbrotlienc=1.1.0=hb9d3cd8_2
  - libcblas=3.9.0=31_he106b2a_openblas
  - libcrc32c=1.1.2=h9c3ff4c_0
  - libcurl=8.13.0=h332b0f4_0
  - libdeflate=1.23=h86f0d12_0
  - libedit=3.1.20250104=pl5321h7949ede_0
  - libev=4.33=hd590300_2
  - libevent=2.1.12=hf998b51_1
  - libexpat=2.7.0=h5888daf_0
  - libffi=3.4.6=h2dba641_1
  - libfreetype=2.13.3=ha770c72_1
  - libfreetype6=2.13.3=h48d6fc4_1
  - libgcc=15.1.0=h767d61c_2
  - libgcc-ng=15.1.0=h69a702a_2
  - libgdal-core=3.10.3=hc58de80_6
  - libgfortran=15.1.0=h69a702a_2
  - libgfortran5=15.1.0=hcea5267_2
  - libgomp=15.1.0=h767d61c_2
  - libgoogle-cloud=2.36.0=hc4361e1_1
  - libgoogle-cloud-storage=2.36.0=h0121fbd_1
  - libgrpc=1.71.0=h8e591d7_1
  - libiconv=1.18=h4ce23a2_1
  - libjpeg-turbo=3.1.0=hb9d3cd8_0
  - libkml=1.3.0=hf539b9f_1021
  - liblapack=3.9.0=31_h7ac8fdf_openblas
  - liblzma=5.8.1=hb9d3cd8_1
  - libmpdec=4.0.0=h4bc722e_0
  - libnetcdf=4.9.2=nompi_h0134ee8_117
  - libnghttp2=1.64.0=h161d5f1_0
  - libnsl=2.0.1=hd590300_0
  - libopenblas=0.3.29=pthreads_h94d23a6_0
  - libopentelemetry-cpp=1.20.0=hd1b1c89_0
  - libopentelemetry-cpp-headers=1.20.0=ha770c72_0
  - libparquet=20.0.0=h081d1f1_2_cpu
  - libpng=1.6.47=h943b412_0
  - libprotobuf=5.29.3=h501fc15_1
  - libre2-11=2024.07.02=hba17884_3
  - librttopo=1.1.0=hd718a1a_18
  - libspatialite=5.1.0=he17ca71_14
  - libsqlite=3.49.2=hee588c1_0
  - libssh2=1.11.1=hcf80075_0
  - libstdcxx=15.1.0=h8f9b012_2
  - libstdcxx-ng=15.1.0=h4852527_2
  - libthrift=0.21.0=h0e7cc3e_0
  - libtiff=4.7.0=hd9ff511_4
  - libutf8proc=2.10.0=h4c51ac1_0
  - libuuid=2.38.1=h0b41bf4_0
  - libwebp-base=1.5.0=h851e524_0
  - libxcb=1.17.0=h8a09558_0
  - libxml2=2.13.8=h4bc477f_0
  - libzip=1.11.2=h6991a6a_0
  - libzlib=1.3.1=hb9d3cd8_2
  - locket=1.0.0=pyhd8ed1ab_0
  - lz4=4.4.4=py313h8756d67_0
  - lz4-c=1.10.0=h5888daf_1
  - lzo=2.10=hd590300_1001
  - mapclassify=2.8.1=pyhd8ed1ab_1
  - markupsafe=3.0.2=py313h8060acc_1
  - matplotlib-base=3.10.3=py313h129903b_0
  - minizip=4.0.10=h05a5f5f_0
  - msgpack-python=1.1.0=py313h33d0bda_0
  - munkres=1.1.4=pyh9f0ad1d_0
  - narwhals=1.38.2=pyhe01879c_0
  - ncurses=6.5=h2d0b736_3
  - netcdf4=1.7.2=nompi_py313h6d1955d_102
  - networkx=3.4.2=pyh267e887_2
  - nlohmann_json=3.12.0=h3f2d84a_0
  - numpy=2.2.5=py313h17eae1a_0
  - openjpeg=2.5.3=h5fbd93e_0
  - openssl=3.5.0=h7b32b05_1
  - orc=2.1.2=h17f744e_0
  - packaging=25.0=pyh29332c3_1
  - pandas=2.2.3=py313ha87cce1_3
  - partd=1.4.2=pyhd8ed1ab_0
  - pcre2=10.45=hc749103_0
  - pillow=11.2.1=py313h8db990d_0
  - pip=25.1.1=pyh145f28c_0
  - proj=9.6.0=h0054346_1
  - prometheus-cpp=1.3.0=ha5d0236_0
  - psutil=7.0.0=py313h536fd9c_0
  - pthread-stubs=0.4=hb9d3cd8_1002
  - pyarrow=20.0.0=py313h78bf25f_0
  - pyarrow-core=20.0.0=py313he5f92c8_0_cpu
  - pycparser=2.22=pyh29332c3_1
  - pyogrio=0.11.0=py313hab4ff3b_0
  - pyparsing=3.2.3=pyhd8ed1ab_1
  - pyproj=3.7.1=py313hcd509b5_1
  - pysocks=1.7.1=pyha55dd90_7
  - python=3.13.3=hf636f53_101_cp313
  - python-dateutil=2.9.0.post0=pyhff2d567_1
  - python-tzdata=2025.2=pyhd8ed1ab_0
  - python_abi=3.13=7_cp313
  - pytz=2025.2=pyhd8ed1ab_0
  - pyyaml=6.0.2=py313h8060acc_2
  - qhull=2020.2=h434a139_5
  - re2=2024.07.02=h9925aae_3
  - readline=8.2=h8c095d6_2
  - requests=2.32.3=pyhd8ed1ab_1
  - s2n=1.5.18=h763c568_1
  - scikit-learn=1.6.1=py313h8ef605b_0
  - scipy=1.15.2=py313h86fcf2b_0
  - setuptools=80.1.0=pyhff2d567_0
  - shapely=2.0.7=py313h576e190_1
  - six=1.17.0=pyhd8ed1ab_0
  - snappy=1.2.1=h8bd8927_1
  - sortedcontainers=2.4.0=pyhd8ed1ab_1
  - sqlite=3.49.2=h9eae976_0
  - tblib=3.1.0=pyhd8ed1ab_0
  - threadpoolctl=3.6.0=pyhecae5ae_0
  - tk=8.6.13=noxft_h4845f30_101
  - toolz=1.0.0=pyhd8ed1ab_1
  - tornado=6.4.2=py313h536fd9c_0
  - tzdata=2025b=h78e105d_0
  - uriparser=0.9.8=hac33072_0
  - urllib3=2.4.0=pyhd8ed1ab_0
  - xarray=2025.1.2=pyhd8ed1ab_0
  - xerces-c=3.2.5=h988505b_2
  - xorg-libxau=1.0.12=hb9d3cd8_0
  - xorg-libxdmcp=1.1.5=hb9d3cd8_0
  - xyzservices=2025.4.0=pyhd8ed1ab_0
  - yaml=0.2.5=h7f98852_2
  - zict=3.0.0=pyhd8ed1ab_1
  - zipp=3.21.0=pyhd8ed1ab_1
  - zlib=1.3.1=hb9d3cd8_2
  - zstandard=0.23.0=py313h536fd9c_2
  - zstd=1.5.7=hb8e6e7a_2
prefix: /home/kdm/local/mambaforge/envs/freshwater_user
#+end_example

**** User environment
The code below produces [[./environment.yml]] when this file is exported. If that file exists, then ~mamba env create -f environment.yml~ and ~mamba activate freshwater~ will install all the python packages used in this document.

#+NAME: conda_env 
#+BEGIN_SRC bash :cmdline -i :results verbatim :eval no-export :exports both
conda env export --name freshwater_user | cat | tee environment.yml
#+END_SRC

#+RESULTS: conda_env
#+begin_example
name: freshwater_user
channels:
  - conda-forge
  - nodefaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=2_gnu
  - aiofiles=22.1.0=pyhd8ed1ab_0
  - aiosqlite=0.20.0=pyhd8ed1ab_0
  - alsa-lib=1.2.8=h166bdaf_0
  - anyio=3.7.1=pyhd8ed1ab_0
  - argon2-cffi=23.1.0=pyhd8ed1ab_0
  - argon2-cffi-bindings=21.2.0=py37h540881e_2
  - arrow=1.2.3=pyhd8ed1ab_0
  - attr=2.5.1=h166bdaf_1
  - attrs=23.1.0=pyh71513ae_1
  - babel=2.14.0=pyhd8ed1ab_0
  - backcall=0.2.0=pyh9f0ad1d_0
  - backports=1.0=pyhd8ed1ab_4
  - backports.functools_lru_cache=2.0.0=pyhd8ed1ab_0
  - beautifulsoup4=4.12.3=pyha770c72_0
  - bleach=6.1.0=pyhd8ed1ab_0
  - blosc=1.21.4=h0f2a231_0
  - bokeh=2.4.3=pyhd8ed1ab_3
  - boost-cpp=1.78.0=h5adbc97_2
  - brotli=1.1.0=hb9d3cd8_2
  - brotli-bin=1.1.0=hb9d3cd8_2
  - brotli-python=1.0.9=py37hd23a5d3_7
  - bzip2=1.0.8=h7f98852_4
  - c-ares=1.19.1=hd590300_0
  - ca-certificates=2025.4.26=hbd8a1cb_0
  - cached-property=1.5.2=hd8ed1ab_1
  - cached_property=1.5.2=pyha770c72_1
  - cairo=1.16.0=ha61ee94_1014
  - certifi=2024.8.30=pyhd8ed1ab_0
  - cffi=1.15.1=py37h43b0acd_1
  - cfitsio=4.1.0=hd9d235c_0
  - cftime=1.6.2=py37hc105733_0
  - charset-normalizer=3.4.0=pyhd8ed1ab_0
  - click=7.1.2=pyh9f0ad1d_0
  - click-plugins=1.1.1=py_0
  - cligj=0.7.2=pyhd8ed1ab_1
  - cloudpickle=2.2.1=pyhd8ed1ab_0
  - comm=0.2.2=pyhd8ed1ab_0
  - curl=7.86.0=h7bff187_1
  - cycler=0.11.0=pyhd8ed1ab_0
  - cytoolz=0.12.0=py37h540881e_0
  - dask=2.15.0=py_0
  - dask-core=2.15.0=py_0
  - dbus=1.13.6=h5008d03_3
  - debugpy=1.6.3=py37hd23a5d3_0
  - decorator=5.1.1=pyhd8ed1ab_0
  - defusedxml=0.7.1=pyhd8ed1ab_0
  - distributed=2.30.1=py37h89c1867_0
  - entrypoints=0.4=pyhd8ed1ab_0
  - exceptiongroup=1.2.2=pyhd8ed1ab_0
  - expat=2.5.0=hcb278e6_1
  - fftw=3.3.10=nompi_hf1063bd_110
  - fiona=1.8.21=py37hced6a7c_2
  - font-ttf-dejavu-sans-mono=2.37=hab24e00_0
  - font-ttf-inconsolata=3.000=h77eed37_0
  - font-ttf-source-code-pro=2.038=h77eed37_0
  - font-ttf-ubuntu=0.83=hab24e00_0
  - fontconfig=2.14.2=h14ed4e7_0
  - fonts-conda-ecosystem=1=0
  - fonts-conda-forge=1=0
  - fonttools=4.38.0=py37h540881e_0
  - fqdn=1.5.1=pyhd8ed1ab_0
  - freetype=2.12.1=hca18f0e_1
  - freexl=1.0.6=h166bdaf_1
  - fsspec=2023.1.0=pyhd8ed1ab_0
  - gdal=3.5.0=py37h80a644e_3
  - geopandas=0.7.0=py_1
  - geos=3.10.3=h27087fc_0
  - geotiff=1.7.1=h509b78c_1
  - gettext=0.21.1=h27087fc_0
  - giflib=5.2.1=h0b41bf4_3
  - glib=2.76.4=hfc55251_0
  - glib-tools=2.76.4=hfc55251_0
  - gst-plugins-base=1.21.3=h4243ec0_1
  - gstreamer=1.21.3=h25f0c4b_1
  - gstreamer-orc=0.4.41=h17648ed_0
  - hdf4=4.2.15=h9772cbc_5
  - hdf5=1.12.1=nompi_h2386368_104
  - heapdict=1.0.1=py_0
  - icu=70.1=h27087fc_0
  - idna=3.10=pyhd8ed1ab_0
  - importlib-metadata=4.11.4=py37h89c1867_0
  - importlib_metadata=4.11.4=hd8ed1ab_0
  - importlib_resources=6.0.0=pyhd8ed1ab_0
  - ipykernel=6.16.2=pyh210e3f2_0
  - ipython=7.33.0=py37h89c1867_0
  - ipython_genutils=0.2.0=pyhd8ed1ab_1
  - ipywidgets=8.1.5=pyhd8ed1ab_0
  - isoduration=20.11.0=pyhd8ed1ab_0
  - jack=1.9.22=h11f4161_0
  - jedi=0.19.1=pyhd8ed1ab_0
  - jinja2=3.1.2=pyhd8ed1ab_1
  - jpeg=9e=h0b41bf4_3
  - json-c=0.16=hc379101_0
  - json5=0.9.25=pyhd8ed1ab_0
  - jsonpointer=2.0=py_0
  - jsonschema=4.17.3=pyhd8ed1ab_0
  - jsonschema-with-format-nongpl=4.17.3=pyhd8ed1ab_0
  - jupyter=1.1.1=pyhd8ed1ab_0
  - jupyter_client=7.3.4=pyhd8ed1ab_0
  - jupyter_console=6.5.1=pyhd8ed1ab_0
  - jupyter_core=4.11.1=py37h89c1867_0
  - jupyter_events=0.6.3=pyhd8ed1ab_1
  - jupyter_server=1.23.4=pyhd8ed1ab_0
  - jupyter_server_fileid=0.9.2=pyhd8ed1ab_0
  - jupyter_server_ydoc=0.8.0=pyhd8ed1ab_0
  - jupyter_ydoc=0.2.4=pyhd8ed1ab_0
  - jupyterlab=3.6.8=pyhd8ed1ab_0
  - jupyterlab_pygments=0.3.0=pyhd8ed1ab_0
  - jupyterlab_server=2.24.0=pyhd8ed1ab_0
  - jupyterlab_widgets=3.0.13=pyhd8ed1ab_0
  - kealib=1.4.15=hfe1a663_0
  - keyutils=1.6.1=h166bdaf_0
  - kiwisolver=1.4.4=py37h7cecad7_0
  - krb5=1.19.3=h3790be6_0
  - lame=3.100=h166bdaf_1003
  - lcms2=2.14=h6ed2654_0
  - ld_impl_linux-64=2.40=h41732ed_0
  - lerc=4.0.0=h27087fc_0
  - libblas=3.9.0=17_linux64_openblas
  - libbrotlicommon=1.1.0=hb9d3cd8_2
  - libbrotlidec=1.1.0=hb9d3cd8_2
  - libbrotlienc=1.1.0=hb9d3cd8_2
  - libcap=2.66=ha37c62d_0
  - libcblas=3.9.0=17_linux64_openblas
  - libclang=15.0.7=default_h127d8a8_5
  - libclang13=15.0.7=default_h5d6823c_5
  - libcups=2.3.3=h3e49a29_2
  - libcurl=7.86.0=h7bff187_1
  - libdap4=3.20.6=hd7c4107_2
  - libdb=6.2.32=h9c3ff4c_0
  - libdeflate=1.14=h166bdaf_0
  - libedit=3.1.20191231=he28a2e2_2
  - libev=4.33=h516909a_1
  - libevent=2.1.10=h9b69904_4
  - libexpat=2.5.0=hcb278e6_1
  - libffi=3.4.2=h7f98852_5
  - libflac=1.4.3=h59595ed_0
  - libgcc=15.1.0=h767d61c_2
  - libgcc-ng=15.1.0=h69a702a_2
  - libgcrypt=1.11.1=ha770c72_0
  - libgcrypt-devel=1.11.1=hb9d3cd8_0
  - libgcrypt-lib=1.11.1=hb9d3cd8_0
  - libgcrypt-tools=1.11.1=hb9d3cd8_0
  - libgdal=3.5.0=he21a14a_3
  - libgfortran-ng=13.1.0=h69a702a_0
  - libgfortran5=13.1.0=h15d22d2_0
  - libglib=2.76.4=hebfc3b9_0
  - libgomp=15.1.0=h767d61c_2
  - libgpg-error=1.55=h3f2d84a_0
  - libiconv=1.17=h166bdaf_0
  - libkml=1.3.0=h37653c0_1015
  - liblapack=3.9.0=17_linux64_openblas
  - libllvm15=15.0.7=hadd5161_1
  - libltdl=2.4.3a=h5888daf_0
  - libnetcdf=4.8.1=nompi_h329d8a1_102
  - libnghttp2=1.51.0=hdcd2b5c_0
  - libnsl=2.0.0=h7f98852_0
  - libogg=1.3.5=hd0c01bc_1
  - libopenblas=0.3.23=pthreads_h80387f5_0
  - libopus=1.5.2=hd0c01bc_0
  - libpng=1.6.39=h753d276_0
  - libpq=14.5=h72a31a5_3
  - librttopo=1.1.0=h40fdbc5_10
  - libsndfile=1.2.2=hc60ed4a_1
  - libsodium=1.0.18=h36c2ea0_1
  - libspatialindex=1.9.3=h9c3ff4c_4
  - libspatialite=5.0.1=h3baac0b_16
  - libsqlite=3.42.0=h2797004_0
  - libssh2=1.10.0=haa6b8db_3
  - libstdcxx=15.1.0=h8f9b012_2
  - libstdcxx-ng=13.1.0=hfd8a6a1_0
  - libsystemd0=252=h2a991cd_0
  - libtiff=4.4.0=h82bc61c_5
  - libtool=2.5.4=h5888daf_0
  - libudev1=253=h0b41bf4_0
  - libuuid=2.38.1=h0b41bf4_0
  - libvorbis=1.3.7=h9c3ff4c_0
  - libwebp-base=1.3.1=hd590300_0
  - libxcb=1.13=h7f98852_1004
  - libxkbcommon=1.5.0=h79f4944_1
  - libxml2=2.10.3=hca2bb57_4
  - libzip=1.9.2=hc869a4a_1
  - libzlib=1.2.13=hd590300_5
  - locket=1.0.0=pyhd8ed1ab_0
  - lz4-c=1.9.4=hcb278e6_0
  - markupsafe=2.1.1=py37h540881e_1
  - matplotlib=3.5.3=py37h89c1867_2
  - matplotlib-base=3.5.3=py37hf395dca_2
  - matplotlib-inline=0.1.7=pyhd8ed1ab_0
  - mistune=3.0.2=pyhd8ed1ab_0
  - mpg123=1.32.9=hc50e24c_0
  - msgpack-python=1.0.4=py37h7cecad7_0
  - munch=2.5.0=py_0
  - munkres=1.1.4=pyh9f0ad1d_0
  - mysql-common=8.0.32=h14678bc_0
  - mysql-libs=8.0.32=h54cf53e_0
  - nbclassic=1.1.0=pyhd8ed1ab_0
  - nbclient=0.7.0=pyhd8ed1ab_0
  - nbconvert-core=7.6.0=pyhd8ed1ab_0
  - nbformat=5.8.0=pyhd8ed1ab_0
  - ncurses=6.4=hcb278e6_0
  - nest-asyncio=1.6.0=pyhd8ed1ab_0
  - netcdf4=1.6.0=nompi_py37h26dc395_100
  - notebook=6.5.7=pyha770c72_0
  - notebook-shim=0.2.4=pyhd8ed1ab_0
  - nspr=4.35=h27087fc_0
  - nss=3.89=he45b914_0
  - numpy=1.21.6=py37h976b520_0
  - openjpeg=2.5.0=h7d73246_1
  - openssl=1.1.1w=hd590300_0
  - packaging=23.1=pyhd8ed1ab_0
  - pandas=1.3.5=py37he8f5f7f_0
  - pandocfilters=1.5.0=pyhd8ed1ab_0
  - parso=0.8.4=pyhd8ed1ab_0
  - partd=1.4.0=pyhd8ed1ab_0
  - patsy=0.5.6=pyhd8ed1ab_0
  - pcre=8.45=h9c3ff4c_0
  - pcre2=10.40=hc3806b6_0
  - pexpect=4.9.0=pyhd8ed1ab_0
  - pickleshare=0.7.5=py_1003
  - pillow=9.2.0=py37h850a105_2
  - pip=23.2=pyhd8ed1ab_0
  - pixman=0.40.0=h36c2ea0_0
  - pkgutil-resolve-name=1.3.10=pyhd8ed1ab_1
  - ply=3.11=pyhd8ed1ab_2
  - poppler=22.04.0=h0733791_3
  - poppler-data=0.4.12=hd8ed1ab_0
  - postgresql=14.5=h5bbe9e2_3
  - proj=9.0.0=h93bde94_1
  - prometheus_client=0.17.1=pyhd8ed1ab_0
  - prompt-toolkit=3.0.48=pyha770c72_0
  - prompt_toolkit=3.0.48=hd8ed1ab_1
  - psutil=5.9.3=py37h540881e_0
  - pthread-stubs=0.4=h36c2ea0_1001
  - ptyprocess=0.7.0=pyhd3deb0d_0
  - pulseaudio=16.1=h4ab2085_1
  - pycparser=2.21=pyhd8ed1ab_0
  - pygments=2.17.2=pyhd8ed1ab_0
  - pyparsing=3.1.4=pyhd8ed1ab_0
  - pyproj=3.2.1=py37h2040241_6
  - pyqt=5.15.7=py37hf30b843_1
  - pyqt5-sip=12.11.0=py37hd23a5d3_1
  - pyrsistent=0.18.1=py37h540881e_1
  - pysocks=1.7.1=py37h89c1867_5
  - python=3.7.12=hb7a2778_100_cpython
  - python-dateutil=2.8.2=pyhd8ed1ab_0
  - python-fastjsonschema=2.20.0=pyhd8ed1ab_0
  - python-json-logger=2.0.7=pyhd8ed1ab_0
  - python_abi=3.7=3_cp37m
  - pytz=2023.3=pyhd8ed1ab_0
  - pyyaml=6.0=py37h540881e_4
  - pyzmq=24.0.1=py37h0c0c2a8_0
  - qt-main=5.15.6=h7acdfc8_2
  - readline=8.2=h8228510_1
  - requests=2.32.2=pyhd8ed1ab_0
  - rfc3339-validator=0.1.4=pyhd8ed1ab_0
  - rfc3986-validator=0.1.1=pyh9f0ad1d_0
  - rtree=1.0.1=py37h0b55af0_0
  - scipy=1.7.3=py37hf2a6cf1_0
  - seaborn=0.10.1=py_0
  - send2trash=1.8.3=pyh0d859eb_0
  - setuptools=59.8.0=py37h89c1867_1
  - shapely=1.8.2=py37hfa59772_2
  - sip=6.7.2=py37hd23a5d3_0
  - six=1.16.0=pyh6c4a22f_0
  - snappy=1.1.10=h9fff704_0
  - sniffio=1.3.1=pyhd8ed1ab_0
  - sortedcontainers=2.4.0=pyhd8ed1ab_0
  - soupsieve=2.3.2.post1=pyhd8ed1ab_0
  - sqlite=3.42.0=h2c6b66d_0
  - statsmodels=0.13.2=py37hda87dfa_0
  - tabulate=0.9.0=pyhd8ed1ab_1
  - tblib=1.7.0=pyhd8ed1ab_0
  - terminado=0.17.1=pyh41d4057_0
  - tiledb=2.9.5=h1e4a385_0
  - tinycss2=1.4.0=pyhd8ed1ab_0
  - tk=8.6.12=h27826a3_0
  - toml=0.10.2=pyhd8ed1ab_0
  - tomli=2.0.2=pyhd8ed1ab_0
  - toolz=0.12.0=pyhd8ed1ab_0
  - tornado=6.1=py37h540881e_3
  - traitlets=5.9.0=pyhd8ed1ab_0
  - typing-extensions=4.7.1=hd8ed1ab_0
  - typing_extensions=4.7.1=pyha770c72_0
  - tzcode=2023c=h0b41bf4_0
  - tzdata=2023c=h71feb2d_0
  - unicodedata2=14.0.0=py37h540881e_1
  - uri-template=1.3.0=pyhd8ed1ab_0
  - urllib3=2.2.1=pyhd8ed1ab_0
  - wcwidth=0.2.10=pyhd8ed1ab_0
  - webcolors=24.8.0=pyhd8ed1ab_0
  - webencodings=0.5.1=pyhd8ed1ab_2
  - websocket-client=1.6.1=pyhd8ed1ab_0
  - wheel=0.40.0=pyhd8ed1ab_1
  - widgetsnbextension=4.0.13=pyhd8ed1ab_0
  - xarray=0.20.2=pyhd8ed1ab_0
  - xcb-util=0.4.0=h516909a_0
  - xcb-util-image=0.4.0=h166bdaf_0
  - xcb-util-keysyms=0.4.0=h516909a_0
  - xcb-util-renderutil=0.3.9=h166bdaf_0
  - xcb-util-wm=0.4.1=h516909a_0
  - xerces-c=3.2.4=h55805fa_1
  - xkeyboard-config=2.38=h0b41bf4_0
  - xorg-kbproto=1.0.7=h7f98852_1002
  - xorg-libice=1.1.1=hd590300_0
  - xorg-libsm=1.2.4=h7391055_0
  - xorg-libx11=1.8.4=h0b41bf4_0
  - xorg-libxau=1.0.11=hd590300_0
  - xorg-libxdmcp=1.1.3=h7f98852_0
  - xorg-libxext=1.3.4=h0b41bf4_2
  - xorg-libxrender=0.9.10=h7f98852_1003
  - xorg-renderproto=0.11.1=h7f98852_1002
  - xorg-xextproto=7.3.0=h0b41bf4_1003
  - xorg-xproto=7.0.31=h7f98852_1007
  - xz=5.2.6=h166bdaf_0
  - y-py=0.5.4=py37hbd0741f_0
  - yaml=0.2.5=h7f98852_2
  - ypy-websocket=0.8.2=pyhd8ed1ab_0
  - zeromq=4.3.5=h59595ed_1
  - zict=2.2.0=pyhd8ed1ab_0
  - zipp=3.15.0=pyhd8ed1ab_0
  - zlib=1.2.13=hd590300_5
  - zstd=1.5.2=hfc55251_7
prefix: /home/kdm/local/mambaforge/envs/freshwater
#+end_example

* LaTeX setup                                           :noexport:
#+NAME: copernicus-latex-setup
#+BEGIN_SRC emacs-lisp :results none :eval no-export
(add-to-list 'org-latex-classes
               `("copernicus"
                 "\\documentclass{copernicus}
               [NO-DEFAULT-PACKAGES]
               [NO-PACKAGES]
               [EXTRA]"
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}"))
               )

(setq-local org-latex-title-command "")
#+END_SRC


